{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simplification_Baselines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zAgDRY4Qh88"
      },
      "source": [
        "To evaluate simplification quality 2 baselines will be used:\n",
        "\n",
        "* Simple trunctuation baseline: leave only a certain number of the first words of a sentence\n",
        "* GPT generation (finetuned russian gpt-3 model from Sber)\n",
        "\n",
        "As the test set I will use the dev part of the Russian dataset collected via Toloka"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZjjBgC3RHTu"
      },
      "source": [
        "# Trunctuation Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgPg72OqpZQH"
      },
      "source": [
        "##Loading data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFbDvfYM1UHj"
      },
      "source": [
        "# dependencies\n",
        "! pip install textstat\n",
        "! pip install --upgrade language_tool_python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpBsUsh3WiXY",
        "outputId": "5400b871-ff86-486b-b466-49b8cb636e6c"
      },
      "source": [
        "import nltk\n",
        "import textstat\n",
        "import language_tool_python\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "import pandas as pd\n",
        "import codecs\n",
        "from collections import OrderedDict\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFQxYnghRutn"
      },
      "source": [
        "# test_data2 = pd.read_csv('/content/drive/MyDrive/SImplification_models/hidden_test_sents.csv')\n",
        "# test_data = pd.read_csv('/content/drive/MyDrive/SImplification_models/public_test_sents.csv')#, error_bad_lines=False, engine='python')\n",
        "# full_test = pd.concat((test_data, test_data2))\n",
        "# test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaaeMuodY7VH"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/dialogue-evaluation/RuSimpleSentEval/main/dev_sents.csv\n",
        "test_data = pd.read_csv('/content/dev_sents.csv')\n",
        "test_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXUe52_WwU6m"
      },
      "source": [
        "First look at the test data (which is actually a dev part from the contest)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "hcq1MI32WOTC",
        "outputId": "0ccc12ff-83e1-423d-aeea-3ec49385184f"
      },
      "source": [
        "test_data['trunctuation_bs'] = test_data['INPUT:source'].apply(lambda x: ' '.join(x.split()[:int(len(x.split())*0.6)])+'.')\n",
        "test_data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>INPUT:source</th>\n",
              "      <th>OUTPUT:output</th>\n",
              "      <th>trunctuation_bs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>686</td>\n",
              "      <td>В Китае передача идёт в основном в кругу семьи, внутрибольничная передача в данной стране для инфекции не характерна.</td>\n",
              "      <td>В Китае обычно заражение происходит от родственников, а не из-за посещения больницы.</td>\n",
              "      <td>В Китае передача идёт в основном в кругу семьи, внутрибольничная.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1073</th>\n",
              "      <td>3229</td>\n",
              "      <td>За столетия потрясений численность этнических вавилонян в Южной Месопотамии сократилась, большинство населения там составляли халдеи.</td>\n",
              "      <td>За последние несколько столетий сократилось население вавилонян в Южной Месопотамии</td>\n",
              "      <td>За столетия потрясений численность этнических вавилонян в Южной Месопотамии.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391</th>\n",
              "      <td>4178</td>\n",
              "      <td>Красный Крест сообщил, что не может начать работу в Карабахе из-за нарушений перемирия.</td>\n",
              "      <td>Работа красного креста не возможра в аарабахе по причине нарушения перемирия.</td>\n",
              "      <td>Красный Крест сообщил, что не может начать.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3146</th>\n",
              "      <td>9234</td>\n",
              "      <td>Туристическая индустрия Ирана серьёзно пострадала в результате ирано-иракской войны, однако в настоящее время возрождается.</td>\n",
              "      <td>Туриндустрия Ирана пострадала в результате ирано-иракской войны, но сейчас возрождается.</td>\n",
              "      <td>Туристическая индустрия Ирана серьёзно пострадала в результате ирано-иракской.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>2478</td>\n",
              "      <td>Гениальнейшим поэтом Польши и одновременно одним из великих мировых поэтов является Адам Мицкевич, признанный вождь польского романтизма.</td>\n",
              "      <td>Адам Мицкевич - всемирно известный польский поэт.\\r\\n</td>\n",
              "      <td>Гениальнейшим поэтом Польши и одновременно одним из великих мировых поэтов.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                                                                                                                               INPUT:source                                                                             OUTPUT:output                                                                 trunctuation_bs\n",
              "225          686                      В Китае передача идёт в основном в кругу семьи, внутрибольничная передача в данной стране для инфекции не характерна.      В Китае обычно заражение происходит от родственников, а не из-за посещения больницы.               В Китае передача идёт в основном в кругу семьи, внутрибольничная.\n",
              "1073        3229      За столетия потрясений численность этнических вавилонян в Южной Месопотамии сократилась, большинство населения там составляли халдеи.       За последние несколько столетий сократилось население вавилонян в Южной Месопотамии    За столетия потрясений численность этнических вавилонян в Южной Месопотамии.\n",
              "1391        4178                                                    Красный Крест сообщил, что не может начать работу в Карабахе из-за нарушений перемирия.             Работа красного креста не возможра в аарабахе по причине нарушения перемирия.                                     Красный Крест сообщил, что не может начать.\n",
              "3146        9234                Туристическая индустрия Ирана серьёзно пострадала в результате ирано-иракской войны, однако в настоящее время возрождается.  Туриндустрия Ирана пострадала в результате ирано-иракской войны, но сейчас возрождается.  Туристическая индустрия Ирана серьёзно пострадала в результате ирано-иракской.\n",
              "844         2478  Гениальнейшим поэтом Польши и одновременно одним из великих мировых поэтов является Адам Мицкевич, признанный вождь польского романтизма.                                     Адам Мицкевич - всемирно известный польский поэт.\\r\\n     Гениальнейшим поэтом Польши и одновременно одним из великих мировых поэтов."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTGdTFZOXBdH"
      },
      "source": [
        "# Second baseline will be automatically generated by GPT-3\n",
        "\n",
        "I follow the procedure described in Sber repo\n",
        "# Finetune RuGPTs in megatron without deepspeed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu1OzWZ6zqQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948a7390-37fe-4429-a828-a1b2e956d8d8"
      },
      "source": [
        "!pip3 install transformers==3.5.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/34/fb092588df61bf33f113ade030d1cbe74fb73a0353648f8dd938a223dce7/transformers-3.5.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 5.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/ac/f5ba028f0f097d855e1541301e946d4672eb0f30b6e25cb2369075f916d2/tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 15.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (20.9)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.12.4)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.0) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.0) (56.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2.10)\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozJOYbK-11pk",
        "outputId": "674d6393-5227-48ff-8346-fcab84a73b97"
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M46Pk6DJ19Jk"
      },
      "source": [
        "!sh setup.sh\n",
        "!git clone  https://github.com/sberbank-ai/ru-gpts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SimLOj1xL46A"
      },
      "source": [
        "File: /usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py\n",
        "\n",
        "> `if version.parse(torch.__version__) <= version.parse(\"1.4.1\") or version.parse(torch.__version__) > version.parse(\"1.7.0\"):`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8di4sCoS0Pyw"
      },
      "source": [
        "## Download files\n",
        "\n",
        "Here we already need the translated data to tune a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96qG_A1n0CiF"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1dB3X-Wx8qU_5nDG_pxAmLvo5H_sgnHrE\n",
        "! gdown https://drive.google.com/uc?id=1bJo8TagTGKa0uyppQRqsHrKHyYO5tcZc\n",
        "! gdown https://drive.google.com/uc?id=11lqipq6ggrgCk8bVxQ4-uuPVMCKN5ebU\n",
        "\n",
        "import pandas as pd\n",
        "df_dev_google = pd.read_csv('/content/wiki_dev_cleaned_translated_sd.csv')\n",
        "df_test_google = pd.read_csv('/content/wiki_test_cleaned_translated_sd.csv')\n",
        "df_train_google = pd.read_csv('/content/wiki_train_cleaned_translated_sd.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqW38Hni64xH"
      },
      "source": [
        "## Prepare data for parallel\n",
        "We use custom implementation of distributed dataset. For training and evaluating we should specify file `file.list` with list of paths to txt files. All files from `file.list` will be splitted between aviable GPUs. The logic of splitting is described by the following code:\n",
        "\n",
        "```python\n",
        "shard_size = len(files) // world_size\n",
        "shard_start = rank * shard_size\n",
        "shard_end = (rank + 1) * shard_size\n",
        "files = files[shard_start:shard_end]\n",
        "```\n",
        "\n",
        "For more details please see full code of dataset: `src.dataset_rugpt3.RuGpt3TextDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42JOCwCj4H3e"
      },
      "source": [
        "with open('train.txt', 'w+') as f:\n",
        "  for i,j in list(zip(df_train_google.target_x.values, df_train_google.target_y.values)):\n",
        "    f.write('<s>'+i+'\\n'+j+'\\n') # +'<\\s>'\n",
        "\n",
        "with open('valid.txt', 'w+') as f:\n",
        "  for i,j in list(zip(df_dev_google.target_x.values, df_dev_google.target_y.values)):\n",
        "    f.write('<s>'+i+'\\n'+j+'\\n') # +'<\\s>'\n",
        "\n",
        "!echo /content/train.txt > train.list\n",
        "!echo /content/valid.txt > valid.list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EF0JepF0S41"
      },
      "source": [
        "## Train\n",
        "Load model from Huggingface and finetune on essays.\n",
        "\n",
        "This will take arount ten minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3c6GmXqMSM8"
      },
      "source": [
        "! rm -r /content/model\n",
        "! rm -r /content/model_hf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHluAlFh0SJo",
        "outputId": "d29715c5-2a7f-4a0a-8b02-116e05a91b83"
      },
      "source": [
        "!export PYTHONPATH=${PYTHONPATH}:${HOME}/ru-gpts\n",
        "\n",
        "!python ru-gpts/pretrain_gpt3.py \\\n",
        "  --train-data-path \"/content/train.list\" \\\n",
        "  --test-data-path \"/content/valid.list\" \\\n",
        "  --max-files-per-process 100 \\\n",
        "  --logging-dir=\"log\" \\\n",
        "  --save model \\\n",
        "  --load-huggingface sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
        "  --save-interval 1000 \\\n",
        "  --log-interval 100 \\\n",
        "  --eval-interval 1000 \\\n",
        "  --eval-iters 100 \\\n",
        "  --model-parallel-size 1 \\\n",
        "  --num-layers 12 \\\n",
        "  --hidden-size 768 \\\n",
        "  --num-attention-heads 12 \\\n",
        "  --batch-size 1 \\\n",
        "  --seq-length 512 \\\n",
        "  --max-position-embeddings 2048 \\\n",
        "  --train-iters 2000 \\\n",
        "  --resume-dataloader \\\n",
        "  --distributed-backend \"nccl\" \\\n",
        "  --lr 0.00015 \\\n",
        "  --lr-decay-style \"cosine\" \\\n",
        "  --lr-decay-iters 3200 \\\n",
        "  --clip-grad 0.5 \\\n",
        "  --warmup .004\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:44:11.667377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "using world size: 1 and model-parallel size: 1 \n",
            " > using dynamic loss scaling\n",
            "> initializing model parallel with size 1\n",
            "Pretrain GPT3 model\n",
            "arguments:\n",
            "  attention_dropout ............ 0.1\n",
            "  num_attention_heads .......... 12\n",
            "  hidden_size .................. 768\n",
            "  intermediate_size ............ None\n",
            "  num_layers ................... 12\n",
            "  layernorm_epsilon ............ 1e-05\n",
            "  hidden_dropout ............... 0.1\n",
            "  max_position_embeddings ...... 2048\n",
            "  vocab_size ................... 30522\n",
            "  deep_init .................... False\n",
            "  make_vocab_size_divisible_by . 8\n",
            "  cpu_optimizer ................ False\n",
            "  cpu_torch_adam ............... False\n",
            "  sparse_mode .................. all\n",
            "  fp16 ......................... False\n",
            "  fp32_embedding ............... False\n",
            "  fp32_layernorm ............... False\n",
            "  fp32_tokentypes .............. False\n",
            "  fp32_allreduce ............... False\n",
            "  hysteresis ................... 2\n",
            "  loss_scale ................... None\n",
            "  loss_scale_window ............ 1000\n",
            "  min_scale .................... 1\n",
            "  batch_size ................... 1\n",
            "  weight_decay ................. 0.01\n",
            "  checkpoint_activations ....... False\n",
            "  checkpoint_num_layers ........ 1\n",
            "  deepspeed_activation_checkpointing  False\n",
            "  clip_grad .................... 0.5\n",
            "  train_iters .................. 2000\n",
            "  log_interval ................. 100\n",
            "  logging_dir .................. log\n",
            "  exit_interval ................ None\n",
            "  seed ......................... 1234\n",
            "  reset_position_ids ........... False\n",
            "  reset_attention_mask ......... False\n",
            "  lr_decay_iters ............... 3200\n",
            "  lr_decay_style ............... cosine\n",
            "  lr ........................... 0.00015\n",
            "  min_lr ....................... 1e-06\n",
            "  warmup ....................... 0.004\n",
            "  save ......................... model\n",
            "  save_interval ................ 1000\n",
            "  no_save_optim ................ False\n",
            "  no_save_rng .................. False\n",
            "  load ......................... None\n",
            "  no_load_optim ................ False\n",
            "  log_memory ................... False\n",
            "  no_load_rng .................. False\n",
            "  load_huggingface ............. sberbank-ai/rugpt3small_based_on_gpt2\n",
            "  export_huggingface ........... None\n",
            "  huggingface_double_pos_embeddings  False\n",
            "  load_tag ..................... \n",
            "  cache_prefix ................. _\n",
            "  finetune ..................... False\n",
            "  resume_dataloader ............ True\n",
            "  distributed_backend .......... nccl\n",
            "  local_rank ................... None\n",
            "  eval_batch_size .............. None\n",
            "  eval_iters ................... 100\n",
            "  eval_interval ................ 1000\n",
            "  eval_seq_length .............. None\n",
            "  eval_max_preds_per_seq ....... None\n",
            "  overlapping_eval ............. 32\n",
            "  cloze_eval ................... False\n",
            "  eval_hf ...................... False\n",
            "  load_openai .................. False\n",
            "  temperature .................. 1.0\n",
            "  top_p ........................ 0.0\n",
            "  top_k ........................ 0\n",
            "  out_seq_length ............... 256\n",
            "  tg_token_name ................ token.txt\n",
            "  model_parallel_size .......... 1\n",
            "  shuffle ...................... False\n",
            "  train_data ................... None\n",
            "  use_npy_data_loader .......... False\n",
            "  train_data_path .............. /content/train.list\n",
            "  val_data_path ................ \n",
            "  test_data_path ............... /content/valid.list\n",
            "  input_data_sizes_file ........ sizes.txt\n",
            "  delim ........................ ,\n",
            "  text_key ..................... sentence\n",
            "  eval_text_key ................ None\n",
            "  valid_data ................... None\n",
            "  split ........................ 1000,1,1\n",
            "  test_data .................... None\n",
            "  overwrite_cache .............. False\n",
            "  lazy_loader .................. False\n",
            "  loose_json ................... False\n",
            "  presplit_sentences ........... False\n",
            "  num_workers .................. 2\n",
            "  tokenizer_path ............... None\n",
            "  cache_dir .................... None\n",
            "  use_tfrecords ................ False\n",
            "  seq_length ................... 512\n",
            "  max_files_per_process ........ 100\n",
            "  max_preds_per_seq ............ None\n",
            "  cuda ......................... True\n",
            "  rank ......................... 0\n",
            "  world_size ................... 1\n",
            "  dynamic_loss_scale ........... True\n",
            "> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
            "Load tokenizer from sberbank-ai/rugpt3small_based_on_gpt2\n",
            "Load RuGPT3 Dataset from /content/train.list, 100 files per process\n",
            "WARNING:src.dataset_rugpt3:R0/1: Loading dataset /content/train.list\n",
            "WARNING:src.dataset_rugpt3:R0/1: Check filelist /content/train.list with root dir /content\n",
            "WARNING:src.dataset_rugpt3:R0/1: Shard [0, 1]\n",
            "WARNING:src.dataset_rugpt3:R0/1: Loaded 0/1 files\n",
            "WARNING:src.dataset_rugpt3:R0/1: Loaded 32201 examples, 16486912 tokens\n",
            "Load RuGPT3 Dataset from /content/valid.list, 100 files per process\n",
            "WARNING:src.dataset_rugpt3:R0/1: Loading dataset /content/valid.list\n",
            "WARNING:src.dataset_rugpt3:R0/1: Check filelist /content/valid.list with root dir /content\n",
            "WARNING:src.dataset_rugpt3:R0/1: Shard [0, 1]\n",
            "  0% 0/1 [00:00<?, ?it/s]WARNING:src.dataset_rugpt3:R0/1: Loaded 0/1 files\n",
            "100% 1/1 [00:00<00:00, 95.88it/s]\n",
            "WARNING:src.dataset_rugpt3:R0/1: Loaded 100 examples, 51200 tokens\n",
            "> padded vocab (size: 50257) with 7 dummy tokens (new size: 50264)\n",
            "> end-of-document token: 0\n",
            "building GPT3 model ...\n",
            "Load huggingface model from sberbank-ai/rugpt3small_based_on_gpt2 \n",
            "Loaded huggingface model <class 'src.model.gpt3_modeling.GPT3Model'>\n",
            " > number of parameters on model parallel rank 0: 125231616\n",
            "Optimizer = FusedAdam\n",
            "learning rate decaying cosine\n",
            "Resume train set from iteration 0\n",
            "--Start training loop--\n",
            " iteration      100/    2000 | elapsed time per iteration (ms): 364.0 | learning rate 1.497E-04 | lm loss 2.4713 | perplexity 11.8376 |\n",
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:375: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:383: FutureWarning: torch.cuda.max_memory_cached has been renamed to torch.cuda.max_memory_reserved\n",
            "  FutureWarning)\n",
            "after 100 iterations memory (MB) | allocated: 1927.36083984375 | max allocated: 3471.7802734375 | cached: 4120.0 | max cached: 4120.0\n",
            "time (ms) | forward: 113.61 | backward: 223.20 | allreduce: 22.84 | optimizer: 26.19 | data loader: 0.25\n",
            " iteration      200/    2000 | elapsed time per iteration (ms): 365.3 | learning rate 1.487E-04 | lm loss 2.6057 | perplexity 13.5402 |\n",
            "time (ms) | forward: 114.20 | backward: 223.98 | allreduce: 22.83 | optimizer: 26.12 | data loader: 0.22\n",
            " iteration      300/    2000 | elapsed time per iteration (ms): 365.2 | learning rate 1.470E-04 | lm loss 2.5117 | perplexity 12.3260 |\n",
            "time (ms) | forward: 114.03 | backward: 224.23 | allreduce: 22.82 | optimizer: 26.08 | data loader: 0.22\n",
            " iteration      400/    2000 | elapsed time per iteration (ms): 364.9 | learning rate 1.446E-04 | lm loss 2.5688 | perplexity 13.0501 |\n",
            "time (ms) | forward: 113.95 | backward: 223.96 | allreduce: 22.79 | optimizer: 26.08 | data loader: 0.22\n",
            " iteration      500/    2000 | elapsed time per iteration (ms): 365.0 | learning rate 1.416E-04 | lm loss 2.5924 | perplexity 13.3620 |\n",
            "time (ms) | forward: 113.96 | backward: 224.06 | allreduce: 22.81 | optimizer: 26.08 | data loader: 0.25\n",
            " iteration      600/    2000 | elapsed time per iteration (ms): 365.1 | learning rate 1.379E-04 | lm loss 2.5177 | perplexity 12.4002 |\n",
            "time (ms) | forward: 114.02 | backward: 224.02 | allreduce: 22.84 | optimizer: 26.09 | data loader: 0.23\n",
            " iteration      700/    2000 | elapsed time per iteration (ms): 365.2 | learning rate 1.336E-04 | lm loss 2.5171 | perplexity 12.3926 |\n",
            "time (ms) | forward: 114.04 | backward: 224.13 | allreduce: 22.77 | optimizer: 26.08 | data loader: 0.23\n",
            " iteration      800/    2000 | elapsed time per iteration (ms): 365.3 | learning rate 1.287E-04 | lm loss 2.4661 | perplexity 11.7761 |\n",
            "time (ms) | forward: 114.09 | backward: 224.20 | allreduce: 22.80 | optimizer: 26.08 | data loader: 0.22\n",
            " iteration      900/    2000 | elapsed time per iteration (ms): 365.4 | learning rate 1.233E-04 | lm loss 2.4514 | perplexity 11.6040 |\n",
            "time (ms) | forward: 114.00 | backward: 224.40 | allreduce: 22.81 | optimizer: 26.07 | data loader: 0.24\n",
            " iteration     1000/    2000 | elapsed time per iteration (ms): 365.3 | learning rate 1.174E-04 | lm loss 2.4829 | perplexity 11.9760 |\n",
            "time (ms) | forward: 114.01 | backward: 224.28 | allreduce: 22.77 | optimizer: 26.08 | data loader: 0.21\n",
            "global rank 0 is saving checkpoint at iteration    1000 to model/iter_0001000/mp_rank_00/model_optim_rng.pt\n",
            "  successfully saved model/iter_0001000/mp_rank_00/model_optim_rng.pt\n",
            " iteration     1100/    2000 | elapsed time per iteration (ms): 437.3 | learning rate 1.112E-04 | lm loss 2.4063 | perplexity 11.0932 |\n",
            "time (ms) | forward: 114.65 | backward: 224.98 | allreduce: 22.70 | optimizer: 26.08 | data loader: 0.24\n",
            " iteration     1200/    2000 | elapsed time per iteration (ms): 365.4 | learning rate 1.046E-04 | lm loss 2.4018 | perplexity 11.0430 |\n",
            "time (ms) | forward: 114.03 | backward: 224.36 | allreduce: 22.78 | optimizer: 26.09 | data loader: 0.22\n",
            " iteration     1300/    2000 | elapsed time per iteration (ms): 365.3 | learning rate 9.767E-05 | lm loss 2.4416 | perplexity 11.4918 |\n",
            "time (ms) | forward: 114.04 | backward: 224.33 | allreduce: 22.77 | optimizer: 26.08 | data loader: 0.21\n",
            " iteration     1400/    2000 | elapsed time per iteration (ms): 365.5 | learning rate 9.055E-05 | lm loss 2.3669 | perplexity 10.6646 |\n",
            "time (ms) | forward: 114.13 | backward: 224.39 | allreduce: 22.84 | optimizer: 26.08 | data loader: 0.23\n",
            " iteration     1500/    2000 | elapsed time per iteration (ms): 365.1 | learning rate 8.329E-05 | lm loss 2.4403 | perplexity 11.4763 |\n",
            "time (ms) | forward: 114.11 | backward: 223.93 | allreduce: 22.76 | optimizer: 26.10 | data loader: 0.23\n",
            " iteration     1600/    2000 | elapsed time per iteration (ms): 365.2 | learning rate 7.594E-05 | lm loss 2.4464 | perplexity 11.5464 |\n",
            "time (ms) | forward: 114.02 | backward: 224.24 | allreduce: 22.79 | optimizer: 26.07 | data loader: 0.24\n",
            " iteration     1700/    2000 | elapsed time per iteration (ms): 365.3 | learning rate 6.859E-05 | lm loss 2.3405 | perplexity 10.3860 |\n",
            "time (ms) | forward: 114.08 | backward: 224.17 | allreduce: 22.80 | optimizer: 26.08 | data loader: 0.23\n",
            " iteration     1800/    2000 | elapsed time per iteration (ms): 365.4 | learning rate 6.129E-05 | lm loss 2.3259 | perplexity 10.2354 |\n",
            "time (ms) | forward: 114.14 | backward: 224.18 | allreduce: 22.79 | optimizer: 26.12 | data loader: 0.24\n",
            " iteration     1900/    2000 | elapsed time per iteration (ms): 365.8 | learning rate 5.413E-05 | lm loss 2.3778 | perplexity 10.7815 |\n",
            "time (ms) | forward: 114.16 | backward: 224.50 | allreduce: 22.91 | optimizer: 26.10 | data loader: 0.26\n",
            " iteration     2000/    2000 | elapsed time per iteration (ms): 365.4 | learning rate 4.717E-05 | lm loss 2.3271 | perplexity 10.2483 |\n",
            "time (ms) | forward: 114.14 | backward: 224.25 | allreduce: 22.87 | optimizer: 26.10 | data loader: 0.23\n",
            "global rank 0 is saving checkpoint at iteration    2000 to model/iter_0002000/mp_rank_00/model_optim_rng.pt\n",
            "  successfully saved model/iter_0002000/mp_rank_00/model_optim_rng.pt\n",
            "global rank 0 is saving checkpoint at iteration    2000 to model/iter_0002000/mp_rank_00/model_optim_rng.pt\n",
            "  successfully saved model/iter_0002000/mp_rank_00/model_optim_rng.pt\n",
            "Evaluating iter 100/100\n",
            "-----------------------------------------------------------------------------------------\n",
            " validation loss at the end of training for test data | LM loss: 2.5496 | LM PPL: 12.802\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALvcD5SE8RtP"
      },
      "source": [
        "At the end of training output should be something like this:\n",
        "\n",
        "\"-----------------------------------------------------------------------------------------\n",
        "\n",
        " validation loss at the end of training for test data | LM loss: 2.7927 | LM PPL: 16.325\n",
        " \n",
        "-----------------------------------------------------------------------------------------\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAoOxKMB--pa"
      },
      "source": [
        "# ! cp -r /content/model /content/drive/MyDrive/SImplification_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HmKilrb8lQm"
      },
      "source": [
        "## Generate\n",
        "\n",
        "Load pretrained model from dir and generate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAH-WpCG8lmG"
      },
      "source": [
        "!export PYTHONPATH=${PYTHONPATH}:${HOME}/ru-gpts\n",
        "\n",
        "!python ru-gpts/generate_samples.py \\\n",
        "  --load /content/drive/MyDrive/SImplification_models/model \\\n",
        "  --model-parallel-size 1 \\\n",
        "  --num-layers 12 \\\n",
        "  --hidden-size 768 \\\n",
        "  --num-attention-heads 12 \\\n",
        "  --batch-size 1 \\\n",
        "  --seq-length 50 \\\n",
        "  --max-position-embeddings 2048 \\\n",
        "  --distributed-backend \"nccl\" \\\n",
        "  --tokenizer-path sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
        "  --no-load-optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCapfDfeBq0x"
      },
      "source": [
        "### Convert checkpoint to Huggingface format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK2yzulB5GWG"
      },
      "source": [
        "# /content/model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JnhIyqd-Eeo"
      },
      "source": [
        "!export PYTHONPATH=${PYTHONPATH}:${HOME}/ru-gpts\n",
        "\n",
        "!python ru-gpts/convert2huggingface.py \\\n",
        "  --load model \\\n",
        "  --model-parallel-size 1 \\\n",
        "  --num-layers 12 \\\n",
        "  --hidden-size 768 \\\n",
        "  --num-attention-heads 12 \\\n",
        "  --max-position-embeddings 2048 \\\n",
        "  --tokenizer-path sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
        "  --no-load-optim \\\n",
        "  --export-huggingface /content/drive/MyDrive/SImplification_models/model_hf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIfhv7KvDKQi"
      },
      "source": [
        "!ls model_hf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRlEwlPdE0L8"
      },
      "source": [
        "#### Test load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x1zLGCiEwkh",
        "outputId": "907acd65-3b00-455d-97f9-d2e6cf471494"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import re\n",
        "\n",
        "def create_model_and_tok(\n",
        "        model_name=\"/content/drive/MyDrive/SImplification_models/model_hf\" #/content/drive/MyDrive/SImplification_models/\n",
        "):\n",
        "    print('loading from {}'.format(model_name))\n",
        "    gpt_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    gpt_tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    gpt_model.cuda()\n",
        "    gpt_model.eval()\n",
        "    gpt_tokenizer.padding_side = \"left\"\n",
        "    gpt_tokenizer.pad_token = '[PAD]'\n",
        "    gpt_tokenizer.encoder['[PAD]'] = 50256\n",
        "    gpt_model.config.pad_token_id = gpt_model.config.eos_token_id\n",
        "    return gpt_model, gpt_tokenizer\n",
        "\n",
        "\n",
        "def batch_generator(\n",
        "        list_of_sentences,\n",
        "        size=16\n",
        "):\n",
        "    num_batch = len(list_of_sentences)//size\n",
        "    for index in range(num_batch):\n",
        "        yield list_of_sentences[index*size:(index+1)*size]\n",
        "    yield list_of_sentences[num_batch*size:]\n",
        "\n",
        "\n",
        "def get_outputs(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        list_of_sentences,\n",
        "        seq_len=11, \n",
        "        batch_size=16\n",
        "):\n",
        "    result = []\n",
        "    for batch in batch_generator(list_of_sentences, batch_size):\n",
        "        max_length = len(max(list_of_sentences, key=lambda x: x.split()).split()) + 1\n",
        "        encodings_dict = tokenizer.batch_encode_plus(batch, max_length=max_length, pad_to_max_length=True, add_special_tokens=False)\n",
        "        input_ids = torch.tensor(encodings_dict['input_ids']).cuda()\n",
        "        attn_mask = torch.tensor(encodings_dict['attention_mask']).cuda()\n",
        "\n",
        "        outputs = model.generate(input_ids,\n",
        "                                 attention_mask=attn_mask,\n",
        "                                 do_sample=True,\n",
        "                                 max_length=40, #1000+ max_length,\n",
        "                                 top_k=10,\n",
        "                                 top_p=0.95,\n",
        "                                 repetition_penalty=5.0,\n",
        "                                 num_return_sequences=1)\n",
        "                                 # no_repeat_ngram_size=3)\n",
        "\n",
        "        outputs = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "        outputs = [text[:re.search(r'<\\\\?s?>?', text).start()].strip() if  re.search(r'<\\\\?s?>?', text) is not None else text.strip() for text  in outputs]\n",
        "        result.extend(outputs)\n",
        "    return result\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    prompt_text = [\n",
        "        \"Британская транспортная комиссия (BTC) была создана послевоенным лейбористским правительством Клемента Эттли в рамках его программы национализации для надзора за железными дорогами, каналами и автомобильными грузовыми перевозками в Великобритании (в Северной Ирландии было отдельное транспортное управление Ольстера).\",\n",
        "        \"Отношения Фицджеральда с Гранцем еще больше укрепились, когда он стал ее менеджером, хотя прошло почти десять лет, прежде чем он смог записать ее на одном из своих многочисленных лейблов.\",\n",
        "        \"Они вымерли на материке, а оставшиеся популяции были ограничены 32 прибрежными островами до первого выпуска с материка в сильно огороженный и находящийся под наблюдением заповедник Карори в 2005 году.\",\n",
        "        \"Вместе с Bryozoa и Brachiopoda форониды принадлежат к лофофоратам, которые иногда рассматриваются как один тип.\"]\n",
        "\n",
        "    model, tokenizer = create_model_and_tok()\n",
        "    texts = get_outputs(model, tokenizer, prompt_text)\n",
        "    for text in texts:\n",
        "        print(text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading from /content/drive/MyDrive/SImplification_models/model_hf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Keyword arguments {'add_space_before_punct_symbol': True} not recognized.\n",
            "Keyword arguments {'add_space_before_punct_symbol': True} not recognized.\n",
            "Keyword arguments {'add_space_before_punct_symbol': True} not recognized.\n",
            "Keyword arguments {'add_space_before_punct_symbol': True} not recognized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Британская транспортная комиссия (BTC) была создана послевоенным лейбористским правительством Клемента Эттли в рамках его программы национализации, а затем преобразована из Британской транспортной комиссии\n",
            "Отношения Фицджеральда с Гранцем еще больше укрепились, когда он стал ее менеджером, хотя прошло почти десять лет, прежде чем она перешла на работу в Microsoft.\n",
            "Они вымерли на материке, а оставшиеся популяции были ограничены 32 прибрежными островами до первого выпуска с материка в сильно огороженный и густонаселенный регион Северной Америки.\n",
            "Вместе с Bryozoa и Brachiopoda форониды принадлежат к лофофоратам, которые иногда рассматриваются как этологи.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Idw0FxcVLk"
      },
      "source": [
        "# Look at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "jbRGfZREa3i2",
        "outputId": "b1ecbf54-4ac9-4563-f98f-b88fc9aa3c82"
      },
      "source": [
        "model, tokenizer = create_model_and_tok()\n",
        "texts = get_outputs(model, tokenizer, test_data['INPUT:source'], batch_size=32)\n",
        "test_data['gpt_bs'] = texts\n",
        "test_data.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>INPUT:source</th>\n",
              "      <th>OUTPUT:output</th>\n",
              "      <th>trunctuation_bs</th>\n",
              "      <th>gpt_bs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2595</th>\n",
              "      <td>7703</td>\n",
              "      <td>Рамзан Кадыров назвал возрождение многонационального сообщества республики одной из приоритетных задач нового руководства республики.</td>\n",
              "      <td>Рамзан Кадыров считает, что главная задача руководства - возродить многонациональное общество республики.</td>\n",
              "      <td>Рамзан Кадыров назвал возрождение многонационального сообщества республики одной.</td>\n",
              "      <td>Рамзан Кадыров назвал возрождение многонационального сообщества республики одной из приоритетных задач.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3175</th>\n",
              "      <td>9354</td>\n",
              "      <td>Улучшение оксигенации лёгких, наблюдаемое при интенсификации дыхания в разрежённом воздухе горных курортов, способствует торможению роста и размножения микобактерий.</td>\n",
              "      <td>Улучшение обогащения лёгких кислородом, которое наблюдается при усилении функций дыхания в разрежённом воздухе горных курортов, способствует также размножению и росту микобактерий.</td>\n",
              "      <td>Улучшение оксигенации лёгких, наблюдаемое при интенсификации дыхания в разрежённом воздухе.</td>\n",
              "      <td>Улучшение оксигенации лёгких, наблюдаемое при интенсификации окиснения урана (AO), является важным механизмом очистки и удаления отходов в легких.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>2391</td>\n",
              "      <td>Вторично одичавшие кошки часто живут уединённо и охотятся в одиночку, но иногда образуют небольшие колонии из нескольких самок с котятами.</td>\n",
              "      <td>Как правило, вторично одичавшие кошки и живут и охотятся в одиночку, но бывает, что иногда они образуют отдельные поселения, в которые входят несколько самок и их котята.</td>\n",
              "      <td>Вторично одичавшие кошки часто живут уединённо и охотятся в одиночку, но иногда.</td>\n",
              "      <td>Вторично одичавшие кошки часто живут уединённо и охотятся в дикой природе.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                                                                                                                                                           INPUT:source                                                                                                                                                                         OUTPUT:output                                                                              trunctuation_bs                                                                                                                                              gpt_bs\n",
              "2595        7703                                  Рамзан Кадыров назвал возрождение многонационального сообщества республики одной из приоритетных задач нового руководства республики.                                                                             Рамзан Кадыров считает, что главная задача руководства - возродить многонациональное общество республики.            Рамзан Кадыров назвал возрождение многонационального сообщества республики одной.                                             Рамзан Кадыров назвал возрождение многонационального сообщества республики одной из приоритетных задач.\n",
              "3175        9354  Улучшение оксигенации лёгких, наблюдаемое при интенсификации дыхания в разрежённом воздухе горных курортов, способствует торможению роста и размножения микобактерий.  Улучшение обогащения лёгких кислородом, которое наблюдается при усилении функций дыхания в разрежённом воздухе горных курортов, способствует также размножению и росту микобактерий.  Улучшение оксигенации лёгких, наблюдаемое при интенсификации дыхания в разрежённом воздухе.  Улучшение оксигенации лёгких, наблюдаемое при интенсификации окиснения урана (AO), является важным механизмом очистки и удаления отходов в легких.\n",
              "808         2391                             Вторично одичавшие кошки часто живут уединённо и охотятся в одиночку, но иногда образуют небольшие колонии из нескольких самок с котятами.           Как правило, вторично одичавшие кошки и живут и охотятся в одиночку, но бывает, что иногда они образуют отдельные поселения, в которые входят несколько самок и их котята.              Вторично одичавшие кошки часто живут уединённо и охотятся в одиночку, но иногда.                                                                          Вторично одичавшие кошки часто живут уединённо и охотятся в дикой природе."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98hCUeqncxRQ"
      },
      "source": [
        "## SAVING BASELINES...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uE1mPGqT0Je"
      },
      "source": [
        "#! gdown https://drive.google.com/uc?id=1IVz3XC8Rm7hQCyx3xCcABjhaENrKABvF\n",
        "test_data = pd.read_csv('/content/test_baselines.csv', sep='\\t')\n",
        "# EXPERIMENT\n",
        "#test_data = pd.read_csv('/content/test_data_new.csv', sep='\\t')\n",
        "test_data['INPUT:source'] = test_data['INPUT:source'].apply(lambda x: re.sub(r'[\\t\\n\\r\\f\\v]+', \"\",x))\n",
        "test_data['OUTPUT:output'] = test_data['OUTPUT:output'].apply(lambda x: re.sub(r'[\\t\\n\\r\\f\\v]+', \"\",x))\n",
        "test_data.to_csv('test_data_new.csv', index=False, sep='\\t')\n",
        "test_data = pd.read_csv('/content/test_data_new.csv', sep='\\t')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrQhN1AVJgUp"
      },
      "source": [
        "# Environment setup and Necessary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1HXuFS3Jv_A"
      },
      "source": [
        "! git clone https://github.com/feralvam/easse\n",
        "! git clone https://github.com/Andoree/sent_simplification.git\n",
        "%cp /content/sent_simplification/sari.py /content/easse/easse\n",
        "\n",
        "%cd easse\n",
        "! pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCCvfK5uJx1j",
        "outputId": "6614882d-3bb1-4192-bd34-8b5d8baa54ce"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN1zBWJOJ0xk"
      },
      "source": [
        "! mkdir prepared_data\n",
        "! mkdir preds"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR88v8W_gLYQ"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv9rV1Y0J834"
      },
      "source": [
        "### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpc_78mmJ9BO"
      },
      "source": [
        "# function retrieved from easse code\n",
        "import numpy as np\n",
        "from typing import List\n",
        "import sacrebleu\n",
        "import easse.utils.preprocessing as utils_prep\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "def corpus_bleu(\n",
        "    sys_sents: List[str],\n",
        "    refs_sents: List[List[str]],\n",
        "    smooth_method: str = 'exp',\n",
        "    smooth_value: float = None,\n",
        "    force: bool = True,\n",
        "    lowercase: bool = False,\n",
        "    tokenizer: str = '13a',\n",
        "    use_effective_order: bool = False,\n",
        "):\n",
        "\n",
        "    sys_sents = [utils_prep.normalize(sent, lowercase, tokenizer) for sent in sys_sents]\n",
        "    refs_sents = [[utils_prep.normalize(sent, lowercase, tokenizer) for sent in ref_sents] for ref_sents in refs_sents]\n",
        "\n",
        "    return sacrebleu.corpus_bleu(\n",
        "        sys_sents,\n",
        "        refs_sents,\n",
        "        smooth_method,\n",
        "        smooth_value,\n",
        "        force,\n",
        "        lowercase=False,\n",
        "        tokenize='none',\n",
        "        use_effective_order=use_effective_order,\n",
        "    ).score\n",
        "\n",
        "\n",
        "def sentence_bleu(\n",
        "    sys_sent: str,\n",
        "    ref_sents: List[str],\n",
        "    smooth_method: str = 'floor',\n",
        "    smooth_value: float = None,\n",
        "    lowercase: bool = False,\n",
        "    tokenizer: str = '13a',\n",
        "    use_effective_order: bool = True,\n",
        "):\n",
        "\n",
        "    return corpus_bleu(\n",
        "        [sys_sent],\n",
        "        [[ref] for ref in ref_sents],\n",
        "        smooth_method,\n",
        "        smooth_value,\n",
        "        force=True,\n",
        "        lowercase=lowercase,\n",
        "        tokenizer=tokenizer,\n",
        "        use_effective_order=use_effective_order,\n",
        "    )\n",
        "\n",
        "\n",
        "def corpus_averaged_sentence_bleu(\n",
        "    sys_sents: List[str],\n",
        "    refs_sents: List[List[str]],\n",
        "    smooth_method: str = 'floor',\n",
        "    smooth_value: float = None,\n",
        "    lowercase: bool = False,\n",
        "    tokenizer: str = '13a',\n",
        "    use_effective_order: bool = True,\n",
        "):\n",
        "\n",
        "    scores = []\n",
        "    for sys_sent, *ref_sents in zip(sys_sents, *refs_sents):\n",
        "        scores.append(\n",
        "            sentence_bleu(\n",
        "                sys_sent,\n",
        "                ref_sents,\n",
        "                smooth_method,\n",
        "                smooth_value,\n",
        "                lowercase=lowercase,\n",
        "                tokenizer=tokenizer,\n",
        "                use_effective_order=use_effective_order,\n",
        "            )\n",
        "        )\n",
        "    return np.mean(scores)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO5je9XBKDl2"
      },
      "source": [
        "### Flesch Kincaid Grade Level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUMqwCdvKLDU"
      },
      "source": [
        "# https://github.com/infoculture/plainrussian\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from math import sqrt\n",
        "import csv\n",
        "\n",
        "\n",
        "from numpy import mean, arange\n",
        "\n",
        "\n",
        "# Russian sounds and characters\n",
        "RU_CONSONANTS_LOW = [u'к', u'п', u'с', u'т', u'ф', u'х', u'ц', u'ч', u'ш', u'щ']\n",
        "RU_CONSONANTS_HIGH = [u'б', u'в', u'г', u'д', u'ж', u'з']\n",
        "RU_CONSONANTS_SONOR = [u'л', u'м', u'н', u'р']\n",
        "RU_CONSONANTS_YET = [u'й']\n",
        "\n",
        "RU_CONSONANTS = RU_CONSONANTS_HIGH + RU_CONSONANTS_LOW + RU_CONSONANTS_SONOR + RU_CONSONANTS_YET\n",
        "RU_VOWELS = [u'а', u'е', u'и', u'у', u'о', u'я', u'ё', u'э', u'ю', u'я', u'ы']\n",
        "RU_MARKS = [u'ь', u'ъ']\n",
        "SENTENCE_SPLITTERS = [u'.', u'?', u'!']\n",
        "RU_LETTERS = RU_CONSONANTS + RU_MARKS + RU_VOWELS\n",
        "SPACES = [u' ', u'\\t']\n",
        "\n",
        "# List of prepared texts\n",
        "\n",
        "GRADE_TEXT = {\n",
        "    1: u'1 - 3-й класс (возраст примерно: 6-8 лет)',\n",
        "    2: u'1 - 3-й класс (возраст примерно: 6-8 лет)',\n",
        "    3: u'1 - 3-й класс (возраст примерно: 6-8 лет)',\n",
        "    4: u'4 - 6-й класс (возраст примерно: 9-11 лет)',\n",
        "    5: u'4 - 6-й класс (возраст примерно: 9-11 лет)',\n",
        "    6: u'4 - 6-й класс (возраст примерно: 9-11 лет)',\n",
        "    7: u'7 - 9-й класс (возраст примерно: 12-14 лет)',\n",
        "    8: u'7 - 9-й класс (возраст примерно: 12-14 лет)',\n",
        "    9: u'7 - 9-й класс (возраст примерно: 12-14 лет)',\n",
        "    10: u'10 - 11-й класс (возраст примерно: 15-16 лет)',\n",
        "    11: u'10 - 11-й класс (возраст примерно: 15-16 лет)',\n",
        "    12: u'1 - 3 курсы ВУЗа (возраст примерно: 17-19 лет)',\n",
        "    13: u'1 - 3 курсы ВУЗа (возраст примерно: 17-19 лет)',\n",
        "    14: u'1 - 3 курсы ВУЗа (возраст примерно: 17-19 лет)',\n",
        "    15: u'4 - 6 курсы ВУЗа (возраст примерно: 20-22 лет)',\n",
        "    16: u'4 - 6 курсы ВУЗа (возраст примерно: 20-22 лет)',\n",
        "    17: u'4 - 6 курсы ВУЗа (возраст примерно: 20-22 лет)',\n",
        "}\n",
        "\n",
        "POST_GRADE_TEXT_18_24 = u'Аспирантура, второе высшее образование, phD'\n",
        "\n",
        "\n",
        "def calc_SMOG(n_psyl, n_sent):\n",
        "    \"\"\"Метрика SMOG для английского языка\"\"\"\n",
        "    n = 1.0430 * sqrt((float(30.0) / n_sent) * n_psyl) + 3.1291\n",
        "    return n\n",
        "\n",
        "def calc_Gunning_fog(n_psyl, n_words, n_sent):\n",
        "    \"\"\"Метрика Gunning fog для английского языка\"\"\"\n",
        "    n = 0.4 * ((float(n_words)/ n_sent) + 100 * (float(n_psyl) / n_words))\n",
        "    return n\n",
        "\n",
        "def calc_Dale_Chale(n_psyl, n_words, n_sent):\n",
        "    \"\"\"Метрика Dale Chale для английского языка\"\"\"\n",
        "    n = 0.1579 * (100.0 * n_psyl / n_words) + 0.0496 * (float(n_words) / n_sent)\n",
        "    return n\n",
        "\n",
        "def calc_Flesh_Kincaid(n_syllabes, n_words, n_sent):\n",
        "    \"\"\"Метрика Flesh Kincaid для английского языка\"\"\"\n",
        "    n = 206.835 - 1.015 * (float(n_words) / n_sent) - 84.6 * (float(n_syllabes) / n_words)\n",
        "    return n\n",
        "\n",
        "\n",
        "def calc_Flesh_Kincaid_rus(n_syllabes, n_words, n_sent):\n",
        "    \"\"\"Метрика Flesh Kincaid для русского языка\"\"\"\n",
        "    n = 220.755 - 1.315 * (float(n_words) / n_sent) - 50.1 * (float(n_syllabes) / n_words)\n",
        "    return n\n",
        "\n",
        "def calc_Flesh_Kincaid_Grade_rus(n_syllabes, n_words, n_sent):\n",
        "    \"\"\"Метрика Flesh Kincaid Grade для русского языка\"\"\"\n",
        "#    n = 0.59 * (float(n_words) / n_sent) + 6.2 * (float(n_syllabes) / n_words) - 16.59\n",
        "    n = 0.49 * (float(n_words) / n_sent) + 7.3 * (float(n_syllabes) / n_words) - 16.59\n",
        "    return n\n",
        "\n",
        "\n",
        "\n",
        "def calc_Flesh_Kincaid_Grade_rus_adapted(n_syllabes, n_words, n_sent, X, Y, Z):\n",
        "    \"\"\"Метрика Flesh Kincaid Grade для русского языка с параметрами\"\"\"\n",
        "#    n = 0.59 * (float(n_words) / n_sent) + 6.2 * (float(n_syllabes) / n_words) - 16.59\n",
        "    if n_words == 0 or n_sent == 0: return 0\n",
        "    n = X * (float(n_words) / n_sent) + Y * (float(n_syllabes) / n_words) - Z\n",
        "    return n\n",
        "\n",
        "\n",
        "#X_GRADE = 0.186\n",
        "#Y_GRADE = 7.21\n",
        "#Z_GRADE = 15.443\n",
        "\n",
        "# Flesh Kinkaid Grade константы. Подробнее http://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests\n",
        "FLG_X_GRADE = 0.318\n",
        "FLG_Y_GRADE = 14.2\n",
        "FLG_Z_GRADE = 30.5\n",
        "\n",
        "def calc_Flesh_Kincaid_Grade_rus_flex(n_syllabes, n_words, n_sent):\n",
        "    \"\"\"Метрика Flesh Kincaid Grade для русского языка с константными параметрами\"\"\"\n",
        "    if n_words == 0 or n_sent == 0: return 0\n",
        "    n = FLG_X_GRADE * (float(n_words) / n_sent) + FLG_Y_GRADE * (float(n_syllabes) / n_words) - FLG_Z_GRADE\n",
        "    return n\n",
        "\n",
        "\n",
        "# Coleman Liau константы. Подробнее http://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index\n",
        "\n",
        "CLI_X_GRADE = 0.055\n",
        "CLI_Y_GRADE = 0.35\n",
        "CLI_Z_GRADE = 20.33\n",
        "\n",
        "\n",
        "def calc_Coleman_Liau_index_adapted(n_letters, n_words, n_sent, x, y, z):\n",
        "    \"\"\" Метрика Coleman Liau для русского языка с адаптированными параметрами \"\"\"\n",
        "    if n_words == 0: return 0\n",
        "    n = x * (n_letters * (100.0 / n_words)) - y * (n_sent * (100.0 / n_words)) - z\n",
        "    return n\n",
        "\n",
        "def calc_Coleman_Liau_index(n_letters, n_words, n_sent):\n",
        "    \"\"\" Метрика Coleman Liau для русского языка с константными параметрами \"\"\"\n",
        "    if n_words == 0: return 0\n",
        "    n = CLI_X_GRADE * (n_letters * (100.0 / n_words)) - CLI_Y_GRADE * (n_sent * (100.0 / n_words)) - CLI_Z_GRADE\n",
        "    return n\n",
        "\n",
        "\n",
        "# Константы SMOG Index http://en.wikipedia.org/wiki/SMOG\n",
        "SMOG_X_GRADE = 1.1\n",
        "SMOG_Y_GRADE = 64.6\n",
        "SMOG_Z_GRADE = 0.05\n",
        "\n",
        "def calc_SMOG_index(n_psyl, n_sent):\n",
        "    \"\"\"Метрика SMOG для русского языка с константными параментрами\"\"\"\n",
        "    n = SMOG_X_GRADE * sqrt((float(SMOG_Y_GRADE) / n_sent) * n_psyl) + SMOG_Z_GRADE\n",
        "    return n\n",
        "\n",
        "def calc_SMOG_index_adapted(n_psyl, n_sent, x, y, z):\n",
        "    \"\"\"Метрика SMOG для русского языка адаптированная с коэффициентами\"\"\"\n",
        "    n = x * sqrt((float(y) / n_sent) * n_psyl) + z\n",
        "    return n\n",
        "\n",
        "DC_X_GRADE = 0.552\n",
        "DC_Y_GRADE = 0.273\n",
        "\n",
        "def calc_Dale_Chale_index(n_psyl, n_words, n_sent):\n",
        "    \"\"\"Метрика Dale Chale для русского языка с константным параметрами\"\"\"\n",
        "    n = DC_X_GRADE * (100.0 * n_psyl / n_words) + DC_Y_GRADE * (float(n_words) / n_sent)\n",
        "    return n\n",
        "\n",
        "\n",
        "def calc_Dale_Chale_adapted(n_psyl, n_words, n_sent, x, y):\n",
        "    \"\"\"Метрика Dale Chale для русского языка с адаптированными параметрами\"\"\"\n",
        "    n = x * (100.0 * n_psyl / n_words) + y * (float(n_words) / n_sent)\n",
        "    return n\n",
        "\n",
        "ARI_X_GRADE = 6.26\n",
        "ARI_Y_GRADE = 0.2805\n",
        "ARI_Z_GRADE = 31.04\n",
        "\n",
        "\n",
        "def calc_ARI_index_adapted(n_letters, n_words, n_sent, x, y, z):\n",
        "    \"\"\" Метрика Automated Readability Index (ARI) для русского языка с адаптированными параметрами \"\"\"\n",
        "    if n_words == 0 or n_sent == 0: return 0\n",
        "    n = x * (float(n_letters) / n_words) + y * (float(n_words) / n_sent) - z\n",
        "    return n\n",
        "\n",
        "def calc_ARI_index(n_letters, n_words, n_sent):\n",
        "    \"\"\" Метрика Automated Readability Index (ARI) для русского языка с константными параметрами \"\"\"\n",
        "    if n_words == 0 or n_sent == 0: return 0\n",
        "    n = ARI_X_GRADE * (float(n_letters) / n_words) + ARI_Y_GRADE * (float(n_words) / n_sent) - ARI_Z_GRADE\n",
        "    return n\n",
        "\n",
        "\n",
        "def load_words(filename):\n",
        "    \"\"\"Load words from filename\"\"\"\n",
        "    words = []\n",
        "    f = open(filename, 'r')\n",
        "    for l in f:\n",
        "        words.append(l.strip().decode('utf8'))\n",
        "    f.close()\n",
        "    return words\n",
        "\n",
        "#FAM_WORDS = load_words('1norm50000.txt')\n",
        "\n",
        "bad_chars = '(){}<>\"\\'!?,.:;'\n",
        "\n",
        "\n",
        "def calc_text_metrics(filename, verbose=True):\n",
        "    \"\"\"Расчет метрик\"\"\"\n",
        "    f = open(filename, 'r')\n",
        "    text = f.read().decode('utf8')    \n",
        "    f.close()\n",
        "    return calc_readability_metrics(text, verbose)\n",
        "\n",
        "\n",
        "# Number of syllabes for long words\n",
        "COMPLEX_SYL_FACTOR = 4\n",
        "\n",
        "def calc_readability_metrics(text, verbose=True):\n",
        "    sentences = 0\n",
        "    chars = 0\n",
        "    spaces = 0\n",
        "    letters = 0\n",
        "    syllabes = 0\n",
        "    words = 0\n",
        "    complex_words = 0\n",
        "    simple_words = 0\n",
        "    wsyllabes = {}\n",
        "\n",
        "    wordStart = False\n",
        "    for l in text.splitlines():\n",
        "        chars += len(l)\n",
        "#        l = l.decode('utf8')\n",
        "        for ch in l:\n",
        "            if ch in SENTENCE_SPLITTERS:\n",
        "                sentences += 1\n",
        "            if ch in SPACES:\n",
        "                spaces += 1\n",
        "\n",
        "        for w in l.split():\n",
        "            has_syl = False\n",
        "            wsyl = 0\n",
        "#            if len(w) > 1: words += 1\n",
        "            for ch in w:\n",
        "                if ch in RU_LETTERS:\n",
        "                    letters += 1\n",
        "                if ch in RU_VOWELS:\n",
        "                    syllabes += 1\n",
        "                    has_syl = True\n",
        "                    wsyl += 1\n",
        "            if wsyl > COMPLEX_SYL_FACTOR:\n",
        "                complex_words += 1\n",
        "            elif wsyl < COMPLEX_SYL_FACTOR+1 and wsyl > 0:\n",
        "                simple_words += 1\n",
        "            if has_syl:\n",
        "                words += 1\n",
        "                v = wsyllabes.get(str(wsyl), 0)\n",
        "                wsyllabes[str(wsyl)] = v + 1\n",
        "    metrics = {'c_share': float(complex_words) * 100 / words if words > 0 else 0,\n",
        "               'avg_slen' : float(words) / sentences if sentences > 0 else 0,\n",
        "               'avg_syl' : float(syllabes) / words if words > 0 else 0,\n",
        "               'n_syllabes': syllabes,\n",
        "               'n_words' : words,\n",
        "               'n_sentences': sentences,\n",
        "               'n_complex_words': complex_words,\n",
        "               'n_simple_words' : simple_words,\n",
        "               'chars': chars,\n",
        "               'letters' : letters,\n",
        "               'spaces' : spaces,\n",
        "               'index_fk_rus': calc_Flesh_Kincaid_Grade_rus_flex(syllabes, words, sentences),\n",
        "               'index_cl_rus' : calc_Coleman_Liau_index(letters, words, sentences),\n",
        "               'index_dc_rus' : calc_Dale_Chale_index(complex_words, words, sentences),\n",
        "               'index_SMOG_rus' : calc_SMOG_index(complex_words, sentences),\n",
        "               'index_ari_rus' : calc_ARI_index(letters, words, sentences),\n",
        "#               'index_fk_rus': calc_Flesh_Kincaid_Grade_rus(syllabes, words, sentences),\n",
        "               'wsyllabes' : wsyllabes\n",
        "    }\n",
        "    del text\n",
        "    return metrics"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3B8SzQyKKbA"
      },
      "source": [
        "### Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwyN8eCQKdUB"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# shape should be [1, something (768, ex)]\n",
        "\n",
        "# import numpy as np\n",
        "# def cs(a, b):\n",
        "#   return (a @ b.T)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "\n",
        "def calc_cos_sim(df, model,tok, x, y, column_name):\n",
        "    Cos_sim= []\n",
        "    for index, row in df.iterrows():\n",
        "        \n",
        "        # original\n",
        "          sentence_A = tok.encode(row[x], padding='max_length', max_length=50, truncation=True, return_tensors='pt')\n",
        "          sentence_A = sentence_A.to(device)\n",
        "          output = model(sentence_A)\n",
        "          sent_emb = output[-1][0]\n",
        "          emb_source = sent_emb.mean(axis=1)\n",
        "          emb_source = emb_source.cpu().detach().numpy()\n",
        "\n",
        "          sentence_B = tok.encode(row[y], padding='max_length', max_length=50, truncation=True, return_tensors='pt')\n",
        "          sentence_B = sentence_B.to(device)\n",
        "          output = model(sentence_B)\n",
        "          sent_emb = output[-1][0]\n",
        "          emb_target= sent_emb.mean(axis=1)\n",
        "          emb_target = emb_target.cpu().detach().numpy()\n",
        "\n",
        "          cos_val = cosine_similarity(emb_source.reshape(emb_source.shape[0], -1), emb_target.reshape(emb_target.shape[0], -1))[0][0]\n",
        "          Cos_sim.append(cos_val)\n",
        "    df[column_name] = Cos_sim"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwx7JK5uKknh"
      },
      "source": [
        "### Grammar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOBVhMFiKjSD"
      },
      "source": [
        "def get_mistakes_summary(df_test, x):\n",
        "    test = list(df_test[x].values)\n",
        "    matches = []\n",
        "    for i in test:\n",
        "      matches.extend(tool.check(i))\n",
        "\n",
        "    categories = set([i.category for i in matches])\n",
        "\n",
        "    categories = {i:0 for i in categories}\n",
        "\n",
        "    for i in matches:\n",
        "      categories[i.category]+=1\n",
        "\n",
        "    return categories"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0uVmKReJZFQ",
        "outputId": "b52f1cc9-69d2-4155-f09a-dec830d5b207"
      },
      "source": [
        "! python /content/sent_simplification/refs_to_easse_format.py \\\n",
        "--input_path /content/test_data_new.csv \\\n",
        "--output_dataset_name test_ref_data \\\n",
        "--src_column \"INPUT:source\" \\\n",
        "--trg_column \"OUTPUT:output\" \\\n",
        "--output_dir /content/prepared_data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "3406\n",
            "3406\n",
            "Overall number of references: 3406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr-wVWqwJZ-U"
      },
      "source": [
        "## Trunctuation baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbbJYqvHKi8s"
      },
      "source": [
        "SARI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMP_AS36K1G7"
      },
      "source": [
        "sentences = [i for i in test_data.trunctuation_bs.values]\n",
        "\n",
        "lt = list()\n",
        "st = set()\n",
        "for i in sentences:\n",
        "  if i not in st:\n",
        "    lt.append(i)\n",
        "    st.add(i)\n",
        "\n",
        "with open('/content/model_prediction__tb.hyp', 'w') as f:\n",
        "  for i in lt:\n",
        "    f.write(i+'\\n')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkXacouILQvI",
        "outputId": "0668ef27-7b9b-48c1-8a32-392e26acb008"
      },
      "source": [
        "! easse evaluate \\\n",
        "--test_set custom \\\n",
        "--metrics sari \\\n",
        "--refs_sents_paths /content/prepared_data/test_ref_data.ref.0,/content/prepared_data/test_ref_data.ref.1,/content/prepared_data/test_ref_data.ref.2,/content/prepared_data/test_ref_data.ref.3,/content/prepared_data/test_ref_data.ref.4 \\\n",
        "--orig_sents_path /content/prepared_data/test_ref_data.src \\\n",
        "--sys_sents_path /content/model_prediction__tb.hyp -q"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sari': 29.097, 'quality_estimation': {'Compression ratio': 0.584, 'Sentence splits': 0.992, 'Levenshtein similarity': 0.736, 'Exact copies': 0.0, 'Additions proportion': 0.0, 'Deletions proportion': 0.395, 'Lexical complexity score': 10.447}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UekxrleFLvSB"
      },
      "source": [
        "### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eqL2aNgLxZP",
        "outputId": "33ebb2cd-193c-4c10-bb5c-28b591cdbee7"
      },
      "source": [
        "# make lists of src, dst\n",
        "src_column, trg_column = \"trunctuation_bs\", \"OUTPUT:output\"\n",
        "data_dict = OrderedDict()\n",
        "for ind, row in test_data.iterrows():\n",
        "        source_sentence = row[src_column]\n",
        "        reference_sentence = row[trg_column]\n",
        "        if data_dict.get(source_sentence) is None:\n",
        "            data_dict[source_sentence] = []\n",
        "        data_dict[source_sentence].append(reference_sentence)\n",
        "max_num_reference_sentences = max([len(x) for x in data_dict.values()])\n",
        "\n",
        "src, dst = [i for i in data_dict.keys()], [i for i in data_dict.values()]\n",
        "for i, j in enumerate(src):\n",
        "   if len(dst[i]) < max_num_reference_sentences:\n",
        "    dst[i] = dst[i] + [dst[i][0]]*(max_num_reference_sentences - len(dst[i]))\n",
        "\n",
        "refs = []\n",
        "for j in range(len(dst[1])):\n",
        "  ref = []\n",
        "  for i in dst:\n",
        "    ref.append(i[j])\n",
        "  refs.append(ref)\n",
        "\n",
        "corpus_bleu(src, refs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.769443856834286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ5yxRhHMOza"
      },
      "source": [
        "### Flesh-Kincaid Grade level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biK8toBCMR6K",
        "outputId": "fa2535b7-7ddf-4cbc-cc61-deef7c63f0d7"
      },
      "source": [
        "calc_readability_metrics(' '.join(list(test_data[\"trunctuation_bs\"].values)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'avg_slen': 9.263492063492064,\n",
              " 'avg_syl': 3.024985980434918,\n",
              " 'c_share': 17.135023989033584,\n",
              " 'chars': 276350,\n",
              " 'index_SMOG_rus': 11.188806752656046,\n",
              " 'index_ari_rus': 15.801619692667394,\n",
              " 'index_cl_rus': 14.763557230980126,\n",
              " 'index_dc_rus': 11.987466575279871,\n",
              " 'index_fk_rus': 15.40059139836631,\n",
              " 'letters': 226856,\n",
              " 'n_complex_words': 5500,\n",
              " 'n_sentences': 3465,\n",
              " 'n_simple_words': 26598,\n",
              " 'n_syllabes': 97096,\n",
              " 'n_words': 32098,\n",
              " 'spaces': 34985,\n",
              " 'wsyllabes': {'1': 5557,\n",
              "  '10': 17,\n",
              "  '11': 6,\n",
              "  '2': 7469,\n",
              "  '3': 7945,\n",
              "  '4': 5627,\n",
              "  '5': 3508,\n",
              "  '6': 1443,\n",
              "  '7': 405,\n",
              "  '8': 100,\n",
              "  '9': 21}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiKz6oC2MdPY"
      },
      "source": [
        "### Cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlsqaO0YM_of"
      },
      "source": [
        "\n",
        "```\n",
        "if version.parse(torch.__version__) <= version.parse(\"1.4.1\") or version.parse(torch.__version__) > version.parse(\"1.7.0\"):\n",
        "    SAVE_STATE_WARNING = \"\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F58sNr_JMg3c"
      },
      "source": [
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaModel, AutoConfig, AutoTokenizer, AutoModelForMaskedLM\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "config = AutoConfig.from_pretrained(\"DeepPavlov/rubert-base-cased\") # \"roberta-base\" 'xlm-mlm-100-1280' 'xlm-roberta-base' 'bert-base-multilingual-cased'\n",
        "config.output_hidden_states = True\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"DeepPavlov/rubert-base-cased\", config=config)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8eRtgKYNsIa",
        "outputId": "bd700a5f-0417-4d6f-a6c7-4bad4df70d0a"
      },
      "source": [
        "calc_cos_sim(test_data, model, tok, 'INPUT:source', \"trunctuation_bs\", 'cos_sim_tb')\n",
        "test_data.cos_sim_tb.mean()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9537958732893099"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHyx1aYPMhAO"
      },
      "source": [
        "### Grammar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH2SNNTyNU--",
        "outputId": "a1cf2dfd-3b30-43d8-b58a-c181d2aa684f"
      },
      "source": [
        "tool = language_tool_python.LanguageTool('ru')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading LanguageTool: 100%|██████████| 190M/190M [00:47<00:00, 3.98MB/s]\n",
            "Unzipping /tmp/tmp3ou51l93.zip to /root/.cache/language_tool_python.\n",
            "Downloaded https://www.languagetool.org/download/LanguageTool-5.2.zip to /root/.cache/language_tool_python.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVP0n1fuNW_z",
        "outputId": "ba31d99c-aa70-4871-b367-3c84eb852411"
      },
      "source": [
        "errors = get_mistakes_summary(test_data, 'trunctuation_bs')\n",
        "errors"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GRAMMAR': 50,\n",
              " 'LOGIC': 22,\n",
              " 'PUNCTUATION': 43,\n",
              " 'STYLE': 203,\n",
              " 'TYPOGRAPHY': 487,\n",
              " 'TYPOS': 441}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvgW-DdfJdDo"
      },
      "source": [
        "## GPT baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ-8xRbfNccT"
      },
      "source": [
        "### SARI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Tw5aeKJed4"
      },
      "source": [
        "sentences = [i for i in test_data.gpt_bs.values]\n",
        "\n",
        "lt = list()\n",
        "st = set()\n",
        "for i in sentences:\n",
        "  if i not in st:\n",
        "    lt.append(i)\n",
        "    st.add(i)\n",
        "\n",
        "with open('/content/model_prediction__gpt.hyp', 'w') as f:\n",
        "  for i in lt:\n",
        "    f.write(i+'\\n')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-OeCpPnN-Bq",
        "outputId": "42dcd70f-1cb5-4d0a-85cf-4f69932e54be"
      },
      "source": [
        "! easse evaluate \\\n",
        "--test_set custom \\\n",
        "--metrics sari \\\n",
        "--refs_sents_paths /content/prepared_data/test_ref_data.ref.0,/content/prepared_data/test_ref_data.ref.1,/content/prepared_data/test_ref_data.ref.2,/content/prepared_data/test_ref_data.ref.3,/content/prepared_data/test_ref_data.ref.4 \\\n",
        "--orig_sents_path /content/prepared_data/test_ref_data.src \\\n",
        "--sys_sents_path /content/model_prediction__gpt.hyp -q"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sari': 32.487, 'quality_estimation': {'Compression ratio': 0.958, 'Sentence splits': 1.011, 'Levenshtein similarity': 0.372, 'Exact copies': 0.0, 'Additions proportion': 0.745, 'Deletions proportion': 0.795, 'Lexical complexity score': 10.215}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPeF7-1vNeZc"
      },
      "source": [
        "### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOTwHtRXNd4I",
        "outputId": "93a0b60b-ffec-4880-e54e-b33e978b54e9"
      },
      "source": [
        "# make lists of src, dst\n",
        "src_column, trg_column = \"gpt_bs\", \"OUTPUT:output\"\n",
        "data_dict = OrderedDict()\n",
        "for ind, row in test_data.iterrows():\n",
        "        source_sentence = row[src_column]\n",
        "        reference_sentence = row[trg_column]\n",
        "        if data_dict.get(source_sentence) is None:\n",
        "            data_dict[source_sentence] = []\n",
        "        data_dict[source_sentence].append(reference_sentence)\n",
        "max_num_reference_sentences = max([len(x) for x in data_dict.values()])\n",
        "\n",
        "src, dst = [i for i in data_dict.keys()], [i for i in data_dict.values()]\n",
        "for i, j in enumerate(src):\n",
        "   if len(dst[i]) < max_num_reference_sentences:\n",
        "    dst[i] = dst[i] + [dst[i][0]]*(max_num_reference_sentences - len(dst[i]))\n",
        "\n",
        "refs = []\n",
        "for j in range(len(dst[1])):\n",
        "  ref = []\n",
        "  for i in dst:\n",
        "    ref.append(i[j])\n",
        "  refs.append(ref)\n",
        "\n",
        "corpus_bleu(src, refs)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.01418601237403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwZY7fBkNi-O"
      },
      "source": [
        "### FKLG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcGZM56CNjHO",
        "outputId": "02f6e5fa-9cab-489d-f05d-4bc6344c2774"
      },
      "source": [
        "calc_readability_metrics(' '.join(list(test_data[\"gpt_bs\"].values)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'avg_slen': 15.020669577874818,\n",
              " 'avg_syl': 2.9009419334832156,\n",
              " 'c_share': 14.880998527017598,\n",
              " 'chars': 425445,\n",
              " 'index_SMOG_rus': 13.268118084885156,\n",
              " 'index_ari_rus': 15.606770178792509,\n",
              " 'index_cl_rus': 14.621682300953559,\n",
              " 'index_dc_rus': 12.31495398167354,\n",
              " 'index_fk_rus': 15.469948381225855,\n",
              " 'letters': 349744,\n",
              " 'n_complex_words': 7678,\n",
              " 'n_sentences': 3435,\n",
              " 'n_simple_words': 43918,\n",
              " 'n_syllabes': 149677,\n",
              " 'n_words': 51596,\n",
              " 'spaces': 56599,\n",
              " 'wsyllabes': {'1': 9903,\n",
              "  '10': 15,\n",
              "  '11': 6,\n",
              "  '12': 1,\n",
              "  '13': 1,\n",
              "  '2': 12861,\n",
              "  '3': 12665,\n",
              "  '4': 8489,\n",
              "  '5': 4920,\n",
              "  '6': 2069,\n",
              "  '7': 512,\n",
              "  '8': 124,\n",
              "  '9': 30}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUIP13zkNgBr"
      },
      "source": [
        "### Cosine similariry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X80Vt4mgNlWc",
        "outputId": "82b68dc8-d4a5-4930-8087-684460e1be15"
      },
      "source": [
        "calc_cos_sim(test_data, model, tok, 'INPUT:source', \"gpt_bs\", 'cos_sim_gpt')\n",
        "test_data.cos_sim_gpt.mean()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9447574653628288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjuLcskoNleN"
      },
      "source": [
        "### Grammar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGuCvxHXNm1U",
        "outputId": "f5e4cfb3-558b-470e-c66d-8e35b56c1f8e"
      },
      "source": [
        "errors = get_mistakes_summary(test_data, 'gpt_bs')\n",
        "errors"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CASING': 2,\n",
              " 'GRAMMAR': 46,\n",
              " 'LOGIC': 23,\n",
              " 'MISC': 3,\n",
              " 'PUNCTUATION': 54,\n",
              " 'STYLE': 4,\n",
              " 'TYPOGRAPHY': 76,\n",
              " 'TYPOS': 697}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}