{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simplification_model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdLEB9tl608G"
      },
      "source": [
        "# Models Finetuning\n",
        "\n",
        "In this notebook several models will be finetuned to perform sentence simplification in Russian. All the models will be tuned with the parametres offered at RuSimpleSentEval competition. The main objective is not to achieve the best performance but rather compare different models trained with and without translated data. In every case training will last 5 epochs. Overall, there are five models:\n",
        "\n",
        "* Model trained on origibal WikiLarge data to perform task for English\n",
        "* Model trained on pairs: original english - simplified russian sentence. So, it learns both translate and simplify at the same time.\n",
        "* Model trained only on the translated to Russian data.\n",
        "* Model trained firstly on the original data and then on the translated corpus\n",
        "\n",
        "All the models will be evaluated and compared \n",
        "\n",
        "The first trial of training was quite unsuccessful. So, it was decided to change the approach 1) filter the data 2) use russian corpus Paraphraser\n",
        "\n",
        "The following models were trained:\n",
        "* Model trained on filtered translated data\n",
        "* Model trained on filtered english data + filtered translated data\n",
        "* Model trained on Paraphraser\n",
        "* Model trained on Paraphraser + filtered translated data\n",
        "\n",
        "P.S: this notebook is heavily based on competition https://github.com/dialogue-evaluation/RuSimpleSentEval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsBwXlp4rSVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e20033-d03c-4878-8dea-224080898308"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i32ckGda9oaO"
      },
      "source": [
        "### Necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ZzPlC152qt"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIi2XjuYcMMz"
      },
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fairseq/models/mbart/mbart.cc25.v2.tar.gz\n",
        "! tar -xzvf /content/mbart.cc25.v2.tar.gz\n",
        "! apt-get install cmake build-essential pkg-config libgoogle-perftools-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j87XOhecayN"
      },
      "source": [
        "!git clone https://github.com/google/sentencepiece.git \n",
        "%cd sentencepiece\n",
        "!mkdir build"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TfHtcvLgOo3"
      },
      "source": [
        "%cd build\n",
        "!cmake ..\n",
        "!make\n",
        "!make install\n",
        "!ldconfig -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7drZkrlhKRI"
      },
      "source": [
        "# from sentencepiece git\n",
        "# !git clone https://github.com/google/sentencepiece.git \n",
        "# %cd sentencepiece\n",
        "# %mkdir build\n",
        "# %cd build\n",
        "# !cmake ..\n",
        "# !make -j $(nproc)\n",
        "# !sudo make install\n",
        "# !sudo ldconfig -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttHTJJDlNQeN",
        "outputId": "bed61d8b-7d71-41e8-8713-c86c860ae36e"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y97dbn4glP8"
      },
      "source": [
        "# !git clone https://github.com/pytorch/fairseq\n",
        "# !cd fairseq\n",
        "# %pip install --editable ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-bGJgZxEjs3"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd /content/fairseq/\n",
        "!python -m pip install --editable .\n",
        "%cd /content\n",
        "\n",
        "! echo $PYTHONPATH\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
        "\n",
        "! echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHDYjuNw-W6y"
      },
      "source": [
        "### Loading data..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYRmUm-2K3Jw"
      },
      "source": [
        "I will use original WikiLarge, Google translation and Paraphraser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u75RYDUVsy95"
      },
      "source": [
        "! mkdir data\n",
        "! gdown https://drive.google.com/uc?id=1bJo8TagTGKa0uyppQRqsHrKHyYO5tcZc\n",
        "! gdown https://drive.google.com/uc?id=11lqipq6ggrgCk8bVxQ4-uuPVMCKN5ebU\n",
        "! gdown https://drive.google.com/uc?id=1dB3X-Wx8qU_5nDG_pxAmLvo5H_sgnHrE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX4irYkJGL5V"
      },
      "source": [
        "% cd /content/fairseq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuPMtHlewRly"
      },
      "source": [
        "data_train = pd.read_csv('/content/wiki_train_cleaned_translated_sd.csv')\n",
        "data_dev = pd.read_csv('/content/wiki_dev_cleaned_translated_sd.csv')\n",
        "data_test  = pd.read_csv('/content/wiki_test_cleaned_translated_sd.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pvmB6gYLNsg"
      },
      "source": [
        "As a test set I use the dev part of a russian dataset collected for RuSimpleSentEval competition: https://github.com/dialogue-evaluation/RuSimpleSentEval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "331tC8esFacR"
      },
      "source": [
        "######\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/MT_sentence_simpl/wiki_test_dev_eng.csv', sep='\\t')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oo6zb0TLjP0"
      },
      "source": [
        "I get rid of the sentences where the simplified versions coincide with the original sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAVUpiAPNTBm"
      },
      "source": [
        "data_train = data_train[data_train.target_x!=data_train.target_y]\n",
        "data_dev = data_dev[data_dev.target_x!=data_dev.target_y]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS1jK-CaCnl6"
      },
      "source": [
        "Also, I filter data based on the simplification lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ra-U7hsCp66"
      },
      "source": [
        "dat_train = data_train[(data_train['target_y'].apply(lambda x: len(x.split(' ')))/data_train['target_x'].apply(lambda x: len(x.split(' '))))<0.8]\n",
        "\n",
        "data_train = dat_train[:82000]\n",
        "data_dev = dat_train[82000:]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Q2T2gausux"
      },
      "source": [
        "For additional model pretraining I use Paraphraser corpus that has proven to be quite effective"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4IxN7i6YD-L"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1JaNqhyZf-3Fybs3iTo90__4eEN4CmhMl\n",
        "import json\n",
        "from sklearn.utils import shuffle\n",
        "with open('/content/ParaPhraserPlus.json', 'r') as f:\n",
        "  data = json.loads(f.read())\n",
        "\n",
        "import random\n",
        "src, dst = [], []\n",
        "for i in data.keys():\n",
        "  src.append(data[i]['headlines'][0])\n",
        "  dst.append(data[i]['headlines'][1])\n",
        "data = pd.DataFrame(list(zip(src, dst)), columns=['src','dst'])\n",
        "# random.shuffle(data)\n",
        "data.head(3)\n",
        "data = shuffle(data)\n",
        "data.drop_duplicates(subset=['dst'], inplace=True)\n",
        "data_new = data.sample(241000)\n",
        "data_train = data_new[:240000]\n",
        "data_dev = data_new[240000:]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbJCkcM46uWP"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0dc0watrBos"
      },
      "source": [
        "! mkdir /content/fairseq/data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYep--fFwsu7"
      },
      "source": [
        "### process WikiLarge\n",
        "\n",
        "with open('/content/fairseq/data/test.en', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.en', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.en', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.ru', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.ru', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.ru', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_y']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqEIc6NkI2lr"
      },
      "source": [
        "### process WikiLarge but with Russian test\n",
        "with open('/content/fairseq/data/test.src', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['INPUT:source']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.src', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['OUTPUT:output']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKOzlK2NKUp7",
        "outputId": "a36b9ed7-0fc0-430a-ffe7-460456f1bcc7"
      },
      "source": [
        "! echo $DATA_DIR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B73jkfOwuq5w"
      },
      "source": [
        "SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "DATA_DIR=\"/content/fairseq/data\"\n",
        "SRC=\"en\"\n",
        "TGT=\"ru\" #en\n",
        "\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$SRC > $DATA_DIR/train.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$TGT > $DATA_DIR/train.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$SRC > $DATA_DIR/dev.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$TGT > $DATA_DIR/dev.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$SRC > $DATA_DIR/test.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$TGT > $DATA_DIR/test.spm.$TGT &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohGRcSLh-lEi"
      },
      "source": [
        "\n",
        "PREPROCESSED_DATA_DIR=\"/content/fairseq/data\"\n",
        "DICT=\"/content/mbart.cc25.v2/dict.txt\"\n",
        "!fairseq-preprocess \\\n",
        "  --source-lang en \\\n",
        "  --target-lang ru \\\n",
        "  --trainpref /content/fairseq/data/train.spm \\\n",
        "  --validpref /content/fairseq/data/dev.spm \\\n",
        "  --testpref /content/fairseq/data/test.spm \\\n",
        "  --destdir /content/fairseq/data \\\n",
        "  --thresholdtgt 0 \\\n",
        "  --thresholdsrc 0 \\\n",
        "  --srcdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --tgtdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --workers 70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFmmrMKh6h8W"
      },
      "source": [
        "Second training with ru-ru"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qb_lVxxrFTo"
      },
      "source": [
        "! rm -r /content/fairseq/data"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kbxXrLyq9uQ"
      },
      "source": [
        "! mkdir /content/fairseq/data"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBZhRLrquGYL"
      },
      "source": [
        "### process translated WikiLarge\n",
        "with open('/content/fairseq/data/test.src', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.src', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_y']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQNDcdvIFy2y"
      },
      "source": [
        "#### process translated WikiLarge + russian dev set as test\n",
        "with open('/content/fairseq/data/test.src', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['INPUT:source']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.src', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['OUTPUT:output']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_y']+'\\n')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwvsggN3v-iG"
      },
      "source": [
        "#### process paraphraser\n",
        "with open('/content/fairseq/data/test.src', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['INPUT:source']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.src', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['OUTPUT:output']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['dst']+'\\n')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjc4EA7eeF3"
      },
      "source": [
        "SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "DATA_DIR=\"/content/fairseq/data\"\n",
        "SRC=\"src\"\n",
        "TGT=\"dst\"\n",
        "\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$SRC > $DATA_DIR/train.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$TGT > $DATA_DIR/train.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$SRC > $DATA_DIR/dev.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$TGT > $DATA_DIR/dev.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$SRC > $DATA_DIR/test.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$TGT > $DATA_DIR/test.spm.$TGT &"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ytIfDcp4Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d88606e-148f-448f-8611-7415d5f864d7"
      },
      "source": [
        "\n",
        "PREPROCESSED_DATA_DIR=\"/content/fairseq/data\"\n",
        "DICT=\"/content/mbart.cc25.v2/dict.txt\"\n",
        "!fairseq-preprocess \\\n",
        "  --source-lang src \\\n",
        "  --target-lang dst \\\n",
        "  --trainpref /content/fairseq/data/train.spm \\\n",
        "  --validpref /content/fairseq/data/dev.spm \\\n",
        "  --testpref /content/fairseq/data/test.spm \\\n",
        "  --destdir /content/fairseq/data \\\n",
        "  --thresholdtgt 0 \\\n",
        "  --thresholdsrc 0 \\\n",
        "  --srcdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --tgtdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --workers 70"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-27 13:17:50 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/content/fairseq/data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='src', srcdict='/content/mbart.cc25.v2/dict.txt', suppress_crashes=False, target_lang='dst', task='translation', tensorboard_logdir=None, testpref='/content/fairseq/data/test.spm', tgtdict='/content/mbart.cc25.v2/dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/fairseq/data/train.spm', use_plasma_view=False, user_dir=None, validpref='/content/fairseq/data/dev.spm', wandb_project=None, workers=70)\n",
            "2021-04-27 13:17:52 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-04-27 13:18:11 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/train.spm.src: 82000 sents, 3727445 tokens, 0.0% replaced by <unk>\n",
            "2021-04-27 13:18:11 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-04-27 13:18:23 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/dev.spm.src: 20066 sents, 925386 tokens, 0.0% replaced by <unk>\n",
            "2021-04-27 13:18:23 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-04-27 13:18:34 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/test.spm.src: 3406 sents, 118537 tokens, 0.0% replaced by <unk>\n",
            "2021-04-27 13:18:34 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-04-27 13:18:50 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/train.spm.dst: 82000 sents, 1814871 tokens, 0.0% replaced by <unk>\n",
            "2021-04-27 13:18:50 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-04-27 13:19:02 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/dev.spm.dst: 20066 sents, 480746 tokens, 0.0% replaced by <unk>\n",
            "2021-04-27 13:19:02 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-04-27 13:19:12 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/test.spm.dst: 3406 sents, 82186 tokens, 0.0% replaced by <unk>\n",
            "2021-04-27 13:19:12 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/fairseq/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhVQUNdQ-po4"
      },
      "source": [
        "The code for training was the same all the times, just \"src\" and \"dst\" parts were changed. So, I do not repeated it six times, but rather altered this one, putting the necessary data in it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SORI3cBePJ1C"
      },
      "source": [
        "# mkdir to put the checkpoints\n",
        "! mkdir /content/drive/MyDrive/checkpoints_paraphraser2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mp6ZsTv_fyd"
      },
      "source": [
        "Also, it is necessary to make the following change in /content/fairseq/fairseq/tasks/translation_from_pretrained_bart.py:\n",
        "\n",
        "```\n",
        "def __init__(self, args, src_dict, tgt_dict):\n",
        "        super().__init__(args, src_dict, tgt_dict)\n",
        "        self.args = args                  # add this line !!!!!\n",
        "        self.langs = args.langs.split(\",\")\n",
        "        for d in [src_dict, tgt_dict]:\n",
        "            for l in self.langs:\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRVvpjsWALRa"
      },
      "source": [
        "The next two cells should install apex for faster training, but some error occured:("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a58XNSANLm9f",
        "outputId": "52ce95a3-8ee2-47f0-987e-153932d457fb"
      },
      "source": [
        "# %%writefile setup.sh\n",
        "\n",
        "# export CUDA_HOME=/usr/local/cuda-10.1\n",
        "# git clone https://github.com/NVIDIA/apex\n",
        "# pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10POwmcuLqvQ"
      },
      "source": [
        "# !sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq-CRreJAYBT"
      },
      "source": [
        "# Training-------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WNBS1mHCV6O"
      },
      "source": [
        "# those are just some variations in parameters that I tried\n",
        "# > train_log.txt &\n",
        "#  --update-freq 1\n",
        "#  --ddp-backend no_c10d\n",
        "# --max-tokens 1024\n",
        "# --batch-size 4 2\n",
        "# --max-epoch 25\n",
        "# --fp16 \\?????\n",
        "# --update-freq? increase????\n",
        "# --update-freq 2??? 5??\n",
        "# 3\n",
        "# --max-tokens 300\n",
        "#  --ddp-backend no_c10d \\\n",
        "# --fp16 \\\n",
        "# --memory-efficient-fp16 \\\n",
        "# --save-interval-updates 5000 \\\n",
        "# /content/mbart.cc25.v2/model.pt\n",
        "# --max-epoch 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PVUoYwjp6uA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a23369-8392-4f6b-8941-9d03b8c89510"
      },
      "source": [
        "!fairseq-train /content/fairseq/data \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --arch mbart_large --layernorm-embedding \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
        "  --optimizer adam --adam-eps 1e-06 --adam-betas '(0.9, 0.98)' \\\n",
        "  --lr-scheduler polynomial_decay --lr 3e-05 --warmup-updates 2500 --total-num-update 54725  \\\n",
        "  --dropout 0.3 --attention-dropout 0.1 --weight-decay 0.0 \\\n",
        "  --max-tokens 1024 --update-freq 5 \\\n",
        "  --source-lang src --target-lang dst \\\n",
        "  --batch-size 16 \\\n",
        "  --memory-efficient-fp16 \\\n",
        "  --validate-interval 1 \\\n",
        "  --patience 3 \\\n",
        "  --max-epoch 10 \\\n",
        "  --save-interval 5 --keep-last-epochs 10 --keep-best-checkpoints 2 \\\n",
        "  --ddp-backend no_c10d \\\n",
        "  --seed 42 --log-format simple --log-interval 500 \\\n",
        "  --restore-file /content/drive/MyDrive/checkpoints_en_en/checkpoint_last.pt \\\n",
        "  --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler \\\n",
        "  --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN \\\n",
        "  --scoring bleu \\\n",
        "  --save-dir /content/drive/MyDrive/checkpoints_en-ru"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-27 13:19:18 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 500, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1024, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [5], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints_en-ru', 'restore_file': '/content/drive/MyDrive/checkpoints_en_en/checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 10, 'keep_best_checkpoints': 2, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='mbart_large', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/drive/MyDrive/checkpoints_en_en/checkpoint_last.pt', save_dir='/content/drive/MyDrive/checkpoints_en-ru', save_interval=5, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='src', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='dst', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': Namespace(_name='translation_from_pretrained_bart', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/drive/MyDrive/checkpoints_en_en/checkpoint_last.pt', save_dir='/content/drive/MyDrive/checkpoints_en-ru', save_interval=5, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='src', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='dst', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 2500, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 54725.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}\n",
            "2021-04-27 13:19:19 | INFO | fairseq.tasks.translation | [src] dictionary: 250001 types\n",
            "2021-04-27 13:19:19 | INFO | fairseq.tasks.translation | [dst] dictionary: 250001 types\n",
            "2021-04-27 13:19:43 | INFO | fairseq_cli.train | BARTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=1024, out_features=250027, bias=False)\n",
            "  )\n",
            "  (classification_heads): ModuleDict()\n",
            ")\n",
            "2021-04-27 13:19:43 | INFO | fairseq_cli.train | task: TranslationFromPretrainedBARTTask\n",
            "2021-04-27 13:19:43 | INFO | fairseq_cli.train | model: BARTModel\n",
            "2021-04-27 13:19:43 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-04-27 13:19:43 | INFO | fairseq_cli.train | num. shared model params: 610,851,840 (num. trained: 610,851,840)\n",
            "2021-04-27 13:19:43 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-04-27 13:19:43 | INFO | fairseq.data.data_utils | loaded 20,066 examples from: /content/fairseq/data/valid.src-dst.src\n",
            "2021-04-27 13:19:43 | INFO | fairseq.data.data_utils | loaded 20,066 examples from: /content/fairseq/data/valid.src-dst.dst\n",
            "2021-04-27 13:19:43 | INFO | fairseq.tasks.translation | /content/fairseq/data valid src-dst 20066 examples\n",
            "2021-04-27 13:19:55 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2021-04-27 13:19:55 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2021-04-27 13:19:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-04-27 13:19:55 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    \n",
            "2021-04-27 13:19:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-04-27 13:19:55 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-04-27 13:19:55 | INFO | fairseq_cli.train | max tokens per device = 1024 and max sentences per device = 16\n",
            "2021-04-27 13:19:55 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/checkpoints_en_en/checkpoint_last.pt\n",
            "2021-04-27 13:21:08 | INFO | fairseq.trainer | Loaded checkpoint /content/drive/MyDrive/checkpoints_en_en/checkpoint_last.pt (epoch 6 @ 0 updates)\n",
            "2021-04-27 13:21:22 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-04-27 13:21:23 | INFO | fairseq.data.data_utils | loaded 82,000 examples from: /content/fairseq/data/train.src-dst.src\n",
            "2021-04-27 13:21:23 | INFO | fairseq.data.data_utils | loaded 82,000 examples from: /content/fairseq/data/train.src-dst.dst\n",
            "2021-04-27 13:21:23 | INFO | fairseq.tasks.translation | /content/fairseq/data train src-dst 82000 examples\n",
            "2021-04-27 13:21:23 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-04-27 13:21:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/fairseq/fairseq/utils.py:364: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "2021-04-27 13:21:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "2021-04-27 13:21:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "2021-04-27 13:22:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "2021-04-27 13:27:23 | INFO | train_inner | epoch 001:    503 / 1198 loss=8.693, nll_loss=5.403, ppl=42.32, wps=2257.9, ups=1.41, wpb=1605.8, bsz=68.5, num_updates=500, lr=6e-06, gnorm=4.406, loss_scale=16, train_wall=355, gb_free=6.1, wall=448\n",
            "2021-04-27 13:31:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "2021-04-27 13:33:12 | INFO | train_inner | epoch 001:   1004 / 1198 loss=7.548, nll_loss=3.93, ppl=15.25, wps=2237.8, ups=1.43, wpb=1564, bsz=68.4, num_updates=1000, lr=1.2e-05, gnorm=2.792, loss_scale=8, train_wall=347, gb_free=6.1, wall=797\n",
            "2021-04-27 13:35:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 13:36:43 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.574 | nll_loss 2.621 | ppl 6.15 | wps 6765.3 | wpb 337 | bsz 13.5 | num_updates 1194\n",
            "2021-04-27 13:36:43 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-04-27 13:36:43 | INFO | train | epoch 001 | loss 8 | nll_loss 4.52 | ppl 22.95 | wps 2065.2 | ups 1.3 | wpb 1583.4 | bsz 68.4 | num_updates 1194 | lr 1.4328e-05 | gnorm 3.436 | loss_scale 8 | train_wall 838 | gb_free 6.1 | wall 1008\n",
            "2021-04-27 13:36:43 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-04-27 13:36:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-27 13:40:18 | INFO | train_inner | epoch 002:    306 / 1198 loss=7.243, nll_loss=3.612, ppl=12.23, wps=1867.2, ups=1.18, wpb=1588.5, bsz=68.9, num_updates=1500, lr=1.8e-05, gnorm=2.53, loss_scale=8, train_wall=349, gb_free=6.1, wall=1223\n",
            "2021-04-27 13:44:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "2021-04-27 13:46:09 | INFO | train_inner | epoch 002:    807 / 1198 loss=7.057, nll_loss=3.419, ppl=10.7, wps=2230.4, ups=1.42, wpb=1565.2, bsz=67.8, num_updates=2000, lr=2.4e-05, gnorm=2.626, loss_scale=4, train_wall=349, gb_free=6.1, wall=1574\n",
            "2021-04-27 13:50:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 13:52:00 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.365 | nll_loss 2.366 | ppl 5.16 | wps 6674.6 | wpb 337 | bsz 13.5 | num_updates 2391\n",
            "2021-04-27 13:52:00 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-04-27 13:52:00 | INFO | train | epoch 002 | loss 7.054 | nll_loss 3.415 | ppl 10.66 | wps 2065.7 | ups 1.31 | wpb 1582.9 | bsz 68.5 | num_updates 2391 | lr 2.8692e-05 | gnorm 2.504 | loss_scale 4 | train_wall 836 | gb_free 6.1 | wall 1925\n",
            "2021-04-27 13:52:00 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-04-27 13:52:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-27 13:53:17 | INFO | train_inner | epoch 003:    109 / 1198 loss=6.924, nll_loss=3.273, ppl=9.67, wps=1865.3, ups=1.17, wpb=1598.7, bsz=68.7, num_updates=2500, lr=3e-05, gnorm=2.342, loss_scale=4, train_wall=351, gb_free=6.1, wall=2002\n",
            "2021-04-27 13:59:09 | INFO | train_inner | epoch 003:    609 / 1198 loss=6.838, nll_loss=3.176, ppl=9.04, wps=2241, ups=1.42, wpb=1576.6, bsz=68.7, num_updates=3000, lr=2.97128e-05, gnorm=2.256, loss_scale=4, train_wall=350, gb_free=6.1, wall=2354\n",
            "2021-04-27 14:04:59 | INFO | train_inner | epoch 003:   1109 / 1198 loss=6.778, nll_loss=3.111, ppl=8.64, wps=2276.7, ups=1.43, wpb=1592.1, bsz=68.3, num_updates=3500, lr=2.94256e-05, gnorm=2.179, loss_scale=4, train_wall=348, gb_free=6, wall=2704\n",
            "2021-04-27 14:06:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 14:07:12 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.24 | nll_loss 2.271 | ppl 4.83 | wps 6906.6 | wpb 337 | bsz 13.5 | num_updates 3589\n",
            "2021-04-27 14:07:12 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-04-27 14:07:12 | INFO | train | epoch 003 | loss 6.807 | nll_loss 3.143 | ppl 8.83 | wps 2079 | ups 1.31 | wpb 1583.4 | bsz 68.4 | num_updates 3589 | lr 2.93744e-05 | gnorm 2.218 | loss_scale 4 | train_wall 834 | gb_free 6.1 | wall 2837\n",
            "2021-04-27 14:07:12 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2021-04-27 14:07:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-27 14:11:59 | INFO | train_inner | epoch 004:    411 / 1198 loss=6.693, nll_loss=3.012, ppl=8.07, wps=1865.8, ups=1.19, wpb=1567.6, bsz=68.5, num_updates=4000, lr=2.91383e-05, gnorm=2.119, loss_scale=4, train_wall=345, gb_free=6.1, wall=3124\n",
            "2021-04-27 14:17:48 | INFO | train_inner | epoch 004:    911 / 1198 loss=6.649, nll_loss=2.962, ppl=7.79, wps=2274.7, ups=1.43, wpb=1588.6, bsz=68.6, num_updates=4500, lr=2.88511e-05, gnorm=2.036, loss_scale=4, train_wall=347, gb_free=4.4, wall=3473\n",
            "2021-04-27 14:21:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 14:22:23 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.253 | nll_loss 2.214 | ppl 4.64 | wps 6763.6 | wpb 337 | bsz 13.5 | num_updates 4787\n",
            "2021-04-27 14:22:23 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2021-04-27 14:22:23 | INFO | train | epoch 004 | loss 6.658 | nll_loss 2.973 | ppl 7.85 | wps 2082.5 | ups 1.32 | wpb 1583.4 | bsz 68.4 | num_updates 4787 | lr 2.86863e-05 | gnorm 2.057 | loss_scale 4 | train_wall 831 | gb_free 6.1 | wall 3748\n",
            "2021-04-27 14:22:23 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2021-04-27 14:22:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-27 14:24:53 | INFO | train_inner | epoch 005:    213 / 1198 loss=6.617, nll_loss=2.926, ppl=7.6, wps=1876.5, ups=1.18, wpb=1595.7, bsz=68.3, num_updates=5000, lr=2.85639e-05, gnorm=1.988, loss_scale=4, train_wall=349, gb_free=6.1, wall=3898\n",
            "2021-04-27 14:30:42 | INFO | train_inner | epoch 005:    713 / 1198 loss=6.556, nll_loss=2.853, ppl=7.23, wps=2266.8, ups=1.44, wpb=1579.6, bsz=68.5, num_updates=5500, lr=2.82767e-05, gnorm=1.981, loss_scale=8, train_wall=346, gb_free=6.1, wall=4247\n",
            "2021-04-27 14:36:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 14:37:35 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.172 | nll_loss 2.19 | ppl 4.56 | wps 6778.4 | wpb 337 | bsz 13.5 | num_updates 5985\n",
            "2021-04-27 14:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5985 updates\n",
            "2021-04-27 14:37:35 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_en-ru/checkpoint5.pt\n",
            "2021-04-27 14:39:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_en-ru/checkpoint5.pt\n",
            "2021-04-27 14:48:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_en-ru/checkpoint5.pt (epoch 5 @ 5985 updates, score 6.172) (writing took 678.3524589659974 seconds)\n",
            "2021-04-27 14:48:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2021-04-27 14:48:54 | INFO | train | epoch 005 | loss 6.559 | nll_loss 2.858 | ppl 7.25 | wps 1192.6 | ups 0.75 | wpb 1583.4 | bsz 68.4 | num_updates 5985 | lr 2.79981e-05 | gnorm 1.97 | loss_scale 8 | train_wall 833 | gb_free 6.1 | wall 5339\n",
            "2021-04-27 14:48:54 | INFO | fairseq.trainer | begin training epoch 6\n",
            "2021-04-27 14:48:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-27 14:49:06 | INFO | train_inner | epoch 006:     15 / 1198 loss=6.551, nll_loss=2.853, ppl=7.22, wps=712.9, ups=0.45, wpb=1575.3, bsz=68.3, num_updates=6000, lr=2.79895e-05, gnorm=1.965, loss_scale=8, train_wall=349, gb_free=6.1, wall=5351\n",
            "2021-04-27 14:55:06 | INFO | train_inner | epoch 006:    515 / 1198 loss=6.488, nll_loss=2.774, ppl=6.84, wps=2173, ups=1.39, wpb=1563.4, bsz=68.2, num_updates=6500, lr=2.77022e-05, gnorm=1.951, loss_scale=8, train_wall=357, gb_free=6.1, wall=5711\n",
            "2021-04-27 15:01:13 | INFO | train_inner | epoch 006:   1015 / 1198 loss=6.476, nll_loss=2.763, ppl=6.79, wps=2178.2, ups=1.36, wpb=1598.6, bsz=68.5, num_updates=7000, lr=2.7415e-05, gnorm=1.929, loss_scale=8, train_wall=365, gb_free=5.8, wall=6078\n",
            "2021-04-27 15:03:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 15:04:41 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.15 | nll_loss 2.175 | ppl 4.52 | wps 6690.1 | wpb 337 | bsz 13.5 | num_updates 7183 | best_loss 6.15\n",
            "2021-04-27 15:04:41 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
            "2021-04-27 15:04:41 | INFO | train | epoch 006 | loss 6.483 | nll_loss 2.77 | ppl 6.82 | wps 2002.3 | ups 1.26 | wpb 1583.4 | bsz 68.4 | num_updates 7183 | lr 2.73099e-05 | gnorm 1.928 | loss_scale 8 | train_wall 866 | gb_free 6.1 | wall 6286\n",
            "2021-04-27 15:04:41 | INFO | fairseq.trainer | begin training epoch 7\n",
            "2021-04-27 15:04:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-27 15:08:35 | INFO | train_inner | epoch 007:    317 / 1198 loss=6.441, nll_loss=2.72, ppl=6.59, wps=1810.3, ups=1.13, wpb=1599.8, bsz=68.6, num_updates=7500, lr=2.71278e-05, gnorm=1.847, loss_scale=8, train_wall=364, gb_free=6, wall=6520\n",
            "2021-04-27 15:14:28 | INFO | train_inner | epoch 007:    817 / 1198 loss=6.414, nll_loss=2.689, ppl=6.45, wps=2249, ups=1.42, wpb=1587, bsz=68.7, num_updates=8000, lr=2.68406e-05, gnorm=1.854, loss_scale=8, train_wall=351, gb_free=6.1, wall=6873\n",
            "2021-04-27 15:18:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 15:20:04 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.178 | nll_loss 2.142 | ppl 4.41 | wps 6877.5 | wpb 337 | bsz 13.5 | num_updates 8381 | best_loss 6.172\n",
            "2021-04-27 15:20:04 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
            "2021-04-27 15:20:04 | INFO | train | epoch 007 | loss 6.42 | nll_loss 2.697 | ppl 6.48 | wps 2054.7 | ups 1.3 | wpb 1583.4 | bsz 68.4 | num_updates 8381 | lr 2.66217e-05 | gnorm 1.851 | loss_scale 8 | train_wall 845 | gb_free 6.1 | wall 7209\n",
            "2021-04-27 15:20:04 | INFO | fairseq.trainer | begin training epoch 8\n",
            "2021-04-27 15:20:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-27 15:21:27 | INFO | train_inner | epoch 008:    119 / 1198 loss=6.411, nll_loss=2.688, ppl=6.45, wps=1869.6, ups=1.19, wpb=1565.8, bsz=68, num_updates=8500, lr=2.65534e-05, gnorm=1.853, loss_scale=16, train_wall=344, gb_free=6.1, wall=7292\n",
            "2021-04-27 15:21:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "2021-04-27 15:25:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "2021-04-27 15:27:19 | INFO | train_inner | epoch 008:    621 / 1198 loss=6.368, nll_loss=2.635, ppl=6.21, wps=2254.6, ups=1.42, wpb=1588.8, bsz=68.5, num_updates=9000, lr=2.62662e-05, gnorm=1.854, loss_scale=4, train_wall=350, gb_free=5.6, wall=7644\n",
            "2021-04-27 15:33:09 | INFO | train_inner | epoch 008:   1121 / 1198 loss=6.366, nll_loss=2.634, ppl=6.21, wps=2262.7, ups=1.43, wpb=1584.6, bsz=68.4, num_updates=9500, lr=2.59789e-05, gnorm=1.827, loss_scale=4, train_wall=348, gb_free=6.1, wall=7994\n",
            "2021-04-27 15:34:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 15:35:16 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.148 | nll_loss 2.137 | ppl 4.4 | wps 6776.8 | wpb 337 | bsz 13.5 | num_updates 9577 | best_loss 6.148\n",
            "2021-04-27 15:35:16 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
            "2021-04-27 15:35:16 | INFO | train | epoch 008 | loss 6.367 | nll_loss 2.635 | ppl 6.21 | wps 2076.1 | ups 1.31 | wpb 1583.4 | bsz 68.4 | num_updates 9577 | lr 2.59347e-05 | gnorm 1.841 | loss_scale 4 | train_wall 833 | gb_free 5.6 | wall 8121\n",
            "2021-04-27 15:35:16 | INFO | fairseq.trainer | begin training epoch 9\n",
            "2021-04-27 15:35:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-27 15:40:10 | INFO | train_inner | epoch 009:    423 / 1198 loss=6.332, nll_loss=2.592, ppl=6.03, wps=1854.5, ups=1.19, wpb=1562.4, bsz=68, num_updates=10000, lr=2.56917e-05, gnorm=1.824, loss_scale=4, train_wall=345, gb_free=5.9, wall=8415\n",
            "2021-04-27 15:46:00 | INFO | train_inner | epoch 009:    923 / 1198 loss=6.332, nll_loss=2.594, ppl=6.04, wps=2287.1, ups=1.43, wpb=1600.4, bsz=68.7, num_updates=10500, lr=2.54045e-05, gnorm=1.802, loss_scale=4, train_wall=348, gb_free=5.3, wall=8765\n",
            "2021-04-27 15:49:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 15:50:23 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.138 | nll_loss 2.135 | ppl 4.39 | wps 6920.6 | wpb 337 | bsz 13.5 | num_updates 10775 | best_loss 6.138\n",
            "2021-04-27 15:50:23 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
            "2021-04-27 15:50:23 | INFO | train | epoch 009 | loss 6.322 | nll_loss 2.58 | ppl 5.98 | wps 2092.6 | ups 1.32 | wpb 1583.4 | bsz 68.4 | num_updates 10775 | lr 2.52465e-05 | gnorm 1.81 | loss_scale 4 | train_wall 829 | gb_free 6.1 | wall 9028\n",
            "2021-04-27 15:50:23 | INFO | fairseq.trainer | begin training epoch 10\n",
            "2021-04-27 15:50:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-27 15:53:00 | INFO | train_inner | epoch 010:    225 / 1198 loss=6.297, nll_loss=2.551, ppl=5.86, wps=1890.2, ups=1.19, wpb=1588.1, bsz=68.6, num_updates=11000, lr=2.51173e-05, gnorm=1.809, loss_scale=4, train_wall=345, gb_free=5.5, wall=9185\n",
            "2021-04-27 15:58:46 | INFO | train_inner | epoch 010:    725 / 1198 loss=6.277, nll_loss=2.526, ppl=5.76, wps=2273.4, ups=1.45, wpb=1572, bsz=68.4, num_updates=11500, lr=2.48301e-05, gnorm=1.776, loss_scale=4, train_wall=344, gb_free=6.1, wall=9531\n",
            "2021-04-27 16:04:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-27 16:05:27 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.123 | nll_loss 2.119 | ppl 4.34 | wps 6938 | wpb 337 | bsz 13.5 | num_updates 11973 | best_loss 6.123\n",
            "2021-04-27 16:05:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11973 updates\n",
            "2021-04-27 16:05:27 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_en-ru/checkpoint10.pt\n",
            "2021-04-27 16:07:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_en-ru/checkpoint10.pt\n",
            "2021-04-27 16:15:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_en-ru/checkpoint10.pt (epoch 10 @ 11973 updates, score 6.123) (writing took 630.6192374499988 seconds)\n",
            "2021-04-27 16:15:58 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
            "2021-04-27 16:15:58 | INFO | train | epoch 010 | loss 6.281 | nll_loss 2.532 | ppl 5.78 | wps 1236.1 | ups 0.78 | wpb 1583.4 | bsz 68.4 | num_updates 11973 | lr 2.45584e-05 | gnorm 1.782 | loss_scale 4 | train_wall 827 | gb_free 6.1 | wall 10562\n",
            "2021-04-27 16:15:58 | INFO | fairseq_cli.train | done training in 10474.2 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LGGmjSE_JLO"
      },
      "source": [
        "### Test to check that everything is ok and get prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpbpDtlCCY5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca147664-c980-43f0-9984-5f4cc7c6bc75"
      },
      "source": [
        "! pip install sentencepiece"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 26.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 24.9MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 18.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 15.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 13.9MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 13.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 13.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 12.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 12.3MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 12.3MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 12.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-_s-v3np7l_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05e4a56-80d4-453b-b985-dcb1e234e809"
      },
      "source": [
        "!fairseq-generate /content/fairseq/data \\\n",
        "  --path  /content/drive/MyDrive/checkpoints_en-ru/checkpoint10.pt \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --gen-subset test \\\n",
        "  --source-lang src --target-lang dst \\\n",
        "  --bpe 'sentencepiece' --sentencepiece-model /content/mbart.cc25.v2/sentence.bpe.model \\\n",
        "  --sacrebleu --remove-bpe 'sentencepiece' \\\n",
        "  --batch-size 32 --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN > model_prediction.txt & \n",
        "!cat model_prediction.txt | grep -P \"^H\" |sort -V |cut -f 3- > model_prediction_en_ru_ru_filtered.hyp\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3bcXrIBE482"
      },
      "source": [
        "!cp /content/model_prediction_en_ru_ru_filtered.hyp /content/drive/MyDrive/MT_sentence_simpl/predictions/model_prediction_en_ru_ru_filtered.hyp\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z33ymqaXA9Ci"
      },
      "source": [
        "# Also, try SARI evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imXXZKIKqXjK",
        "outputId": "cbb8dfa0-e099-4e2b-d438-d4ed8ab359a3"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxVrDxwiqXpG"
      },
      "source": [
        "! git clone https://github.com/feralvam/easse\n",
        "! git clone https://github.com/Andoree/sent_simplification.git\n",
        "%cp /content/sent_simplification/sari.py /content/easse/easse\n",
        "%cd easse\n",
        "! pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FINU32l7rajY"
      },
      "source": [
        "%cd /content\n",
        "! mkdir prepared_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch6UCNu4BF3_"
      },
      "source": [
        "Prepare data for SARI calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmTp6oQOuWTi"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/dialogue-evaluation/RuSimpleSentEval/main/dev_sents.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSqVqCnCrQJL",
        "outputId": "7521f520-3f7b-4bfb-8317-e080035a16b9"
      },
      "source": [
        "! python /content/sent_simplification/refs_to_easse_format.py \\\n",
        "--input_path /content/dev_sents.csv \\\n",
        "--output_dataset_name test_ref_data \\\n",
        "--src_column \"INPUT:source\" \\\n",
        "--trg_column \"OUTPUT:output\" \\\n",
        "--output_dir /content/prepared_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "3406\n",
            "3406\n",
            "Overall number of references: 3406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slkZYEDv-h5U"
      },
      "source": [
        "data_test = pd.read_csv('/content/dev_sents.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "Vgmj2HgE5CWQ",
        "outputId": "dd286613-e24d-4314-ff35-06d856d71ea6"
      },
      "source": [
        "data_test.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>INPUT:source</th>\n",
              "      <th>OUTPUT:output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3401</th>\n",
              "      <td>9960</td>\n",
              "      <td>Язгуля́мский язы́к (самоназвание — Yuzdami zev...</td>\n",
              "      <td>Язгулямский язык - один из языков, на котором ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3402</th>\n",
              "      <td>9961</td>\n",
              "      <td>Язгуля́мский язы́к (самоназвание — Yuzdami zev...</td>\n",
              "      <td>Язгуля́мский язы́к — один из памирских языков ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3403</th>\n",
              "      <td>9975</td>\n",
              "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
              "      <td>Японский космический аппарат Хаябуса успешно д...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3404</th>\n",
              "      <td>9976</td>\n",
              "      <td>Изображение соцветия подсолнечника на щите озн...</td>\n",
              "      <td>Соцветие подсолнечника - олицетворение сегодня...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3405</th>\n",
              "      <td>9977</td>\n",
              "      <td>Изображение соцветия подсолнечника на щите озн...</td>\n",
              "      <td>Подсолнечник, который изображён на щите, симво...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                      OUTPUT:output\n",
              "3401        9960  ...  Язгулямский язык - один из языков, на котором ...\n",
              "3402        9961  ...  Язгуля́мский язы́к — один из памирских языков ...\n",
              "3403        9975  ...  Японский космический аппарат Хаябуса успешно д...\n",
              "3404        9976  ...  Соцветие подсолнечника - олицетворение сегодня...\n",
              "3405        9977  ...  Подсолнечник, который изображён на щите, симво...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMaGo5MGrlaG",
        "outputId": "c5ef7048-eafd-4685-ef88-8b39e2a81670"
      },
      "source": [
        "! easse evaluate \\\n",
        "--test_set custom \\\n",
        "--metrics sari \\\n",
        "--refs_sents_paths /content/prepared_data/test_ref_data.ref.0,/content/prepared_data/test_ref_data.ref.1,/content/prepared_data/test_ref_data.ref.2,/content/prepared_data/test_ref_data.ref.3,/content/prepared_data/test_ref_data.ref.4 \\\n",
        "--orig_sents_path /content/prepared_data/test_ref_data.src \\\n",
        "--sys_sents_path /content/fairseq/model_prediction.hyp -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "{'sari': 32.236, 'quality_estimation': {'Compression ratio': 0.903, 'Sentence splits': 1.051, 'Levenshtein similarity': 0.35, 'Exact copies': 0.0, 'Additions proportion': 0.695, 'Deletions proportion': 0.792, 'Lexical complexity score': 9.639}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}