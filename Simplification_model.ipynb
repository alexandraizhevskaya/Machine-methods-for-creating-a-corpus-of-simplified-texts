{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simplification_model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdLEB9tl608G"
      },
      "source": [
        "# Models Finetuning\n",
        "\n",
        "In this notebook several models will be finetuned to perform sentence simplification in Russian. All the models will be tuned with the parametres offered at RuSimpleSentEval competition. The main objective is not to achieve the best performance but rather compare different models trained with and without translated data. In every case training will last 5 epochs. Overall, there are five models:\n",
        "\n",
        "* Model trained on pairs: original english - simplified russian sentence. So, it learns both translate and simplify at the same time.\n",
        "* Model trained only on the translated to Russian data.\n",
        "* Model trained firstly on the original data and then on the translated corpus\n",
        "\n",
        "All the models will be evaluated and compared \n",
        "\n",
        "The first trial of training was quite unsuccessful. So, it was decided to change the approach 1) filter the data 2) use russian corpus Paraphraser\n",
        "\n",
        "The following models were trained:\n",
        "* Model trained on filtered translated data\n",
        "* Model trained on filtered translated data and then on Paraphraser\n",
        "* Model trained on Paraphraser\n",
        "* Model trained on Paraphraser + filtered translated data\n",
        "* Model trained on Paraphraser + filtered translated data with control tokens\n",
        "\n",
        "P.S: this notebook is heavily based on competition https://github.com/dialogue-evaluation/RuSimpleSentEval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsBwXlp4rSVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ca359c-3d5b-45ef-e131-5227783aa477"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i32ckGda9oaO"
      },
      "source": [
        "### Necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ZzPlC152qt"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "# import nltk\n",
        "# nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIi2XjuYcMMz"
      },
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fairseq/models/mbart/mbart.cc25.v2.tar.gz\n",
        "! tar -xzvf /content/mbart.cc25.v2.tar.gz\n",
        "! apt-get install cmake build-essential pkg-config libgoogle-perftools-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j87XOhecayN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba93a60-58c1-4147-a345-ae861ce13d6e"
      },
      "source": [
        "!git clone https://github.com/google/sentencepiece.git \n",
        "%cd sentencepiece\n",
        "!mkdir build"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sentencepiece'...\n",
            "remote: Enumerating objects: 3706, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 3706 (delta 4), reused 1 (delta 0), pack-reused 3691\u001b[K\n",
            "Receiving objects: 100% (3706/3706), 28.59 MiB | 18.92 MiB/s, done.\n",
            "Resolving deltas: 100% (2596/2596), done.\n",
            "/content/sentencepiece\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TfHtcvLgOo3"
      },
      "source": [
        "%cd build\n",
        "!cmake ..\n",
        "!make\n",
        "!make install\n",
        "!ldconfig -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7drZkrlhKRI"
      },
      "source": [
        "# from sentencepiece git\n",
        "# !git clone https://github.com/google/sentencepiece.git \n",
        "# %cd sentencepiece\n",
        "# %mkdir build\n",
        "# %cd build\n",
        "# !cmake ..\n",
        "# !make -j $(nproc)\n",
        "# !sudo make install\n",
        "# !sudo ldconfig -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttHTJJDlNQeN",
        "outputId": "98389674-7077-4a21-8e37-15a87af847f7"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y97dbn4glP8"
      },
      "source": [
        "# !git clone https://github.com/pytorch/fairseq\n",
        "# !cd fairseq\n",
        "# %pip install --editable ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-bGJgZxEjs3"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd /content/fairseq/\n",
        "!python -m pip install --editable .\n",
        "%cd /content\n",
        "\n",
        "! echo $PYTHONPATH\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
        "\n",
        "! echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHDYjuNw-W6y"
      },
      "source": [
        "### Loading data..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYRmUm-2K3Jw"
      },
      "source": [
        "I will use original WikiLarge, Google translation and Paraphraser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u75RYDUVsy95"
      },
      "source": [
        "! mkdir data\n",
        "! gdown https://drive.google.com/uc?id=1bJo8TagTGKa0uyppQRqsHrKHyYO5tcZc\n",
        "! gdown https://drive.google.com/uc?id=11lqipq6ggrgCk8bVxQ4-uuPVMCKN5ebU\n",
        "! gdown https://drive.google.com/uc?id=1dB3X-Wx8qU_5nDG_pxAmLvo5H_sgnHrE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX4irYkJGL5V"
      },
      "source": [
        "% cd /content/fairseq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuPMtHlewRly"
      },
      "source": [
        "data_train = pd.read_csv('/content/wiki_train_cleaned_translated_sd.csv')\n",
        "data_dev = pd.read_csv('/content/wiki_dev_cleaned_translated_sd.csv')\n",
        "data_test  = pd.read_csv('/content/wiki_test_cleaned_translated_sd.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pvmB6gYLNsg"
      },
      "source": [
        "As a test set I use the dev part of a russian dataset collected for RuSimpleSentEval competition: https://github.com/dialogue-evaluation/RuSimpleSentEval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "331tC8esFacR"
      },
      "source": [
        "######\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/MT_sentence_simpl/wiki_test_dev_eng.csv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oo6zb0TLjP0"
      },
      "source": [
        "I get rid of the sentences where the simplified versions coincide with the original sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAVUpiAPNTBm"
      },
      "source": [
        "data_train = data_train[data_train.target_x!=data_train.target_y]\n",
        "data_dev = data_dev[data_dev.target_x!=data_dev.target_y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS1jK-CaCnl6"
      },
      "source": [
        "Also, I filter data based on the simplification lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ra-U7hsCp66"
      },
      "source": [
        "dat_train = data_train[(data_train['target_y'].apply(lambda x: len(x.split(' ')))/data_train['target_x'].apply(lambda x: len(x.split(' '))))<0.8]\n",
        "\n",
        "data_train = dat_train[:82000]\n",
        "data_dev = dat_train[82000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJwDYCSNLEPq",
        "outputId": "0f4b1693-c09b-44f1-c401-e44970c0c456"
      },
      "source": [
        "data_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qAiKmNVLGp8",
        "outputId": "c42941d0-2f37-447a-c261-dadea91a9df9"
      },
      "source": [
        "data_dev.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20066, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Q2T2gausux"
      },
      "source": [
        "For additional model pretraining I use Paraphraser corpus that has proven to be quite effective"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4IxN7i6YD-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6cbdc65-7cd0-4c71-8881-d80cb7b4022a"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1JaNqhyZf-3Fybs3iTo90__4eEN4CmhMl\n",
        "import json\n",
        "from sklearn.utils import shuffle\n",
        "with open('/content/ParaPhraserPlus.json', 'r') as f:\n",
        "  data = json.loads(f.read())\n",
        "\n",
        "import random\n",
        "src, dst = [], []\n",
        "for i in data.keys():\n",
        "  src.append(data[i]['headlines'][0])\n",
        "  dst.append(data[i]['headlines'][1])\n",
        "data = pd.DataFrame(list(zip(src, dst)), columns=['src','dst'])\n",
        "# random.shuffle(data)\n",
        "data.head(3)\n",
        "data = shuffle(data)\n",
        "data.drop_duplicates(subset=['dst'], inplace=True)\n",
        "data_new = data.sample(241000)\n",
        "data_train = data_new[:240000]\n",
        "data_dev = data_new[240000:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JaNqhyZf-3Fybs3iTo90__4eEN4CmhMl\n",
            "To: /content/ParaPhraserPlus.json\n",
            "1.11GB [00:08, 139MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHyBMHRxax-J"
      },
      "source": [
        "## Trial with all data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3AyaAj-aw84"
      },
      "source": [
        "data_train = pd.read_csv('/content/wiki_train_cleaned_translated_sd.csv')\n",
        "data_dev = pd.read_csv('/content/wiki_dev_cleaned_translated_sd.csv')\n",
        "data_test  = pd.read_csv('/content/wiki_test_cleaned_translated_sd.csv')\n",
        "data_train = pd.concat((data_train, data_dev, data_test))\n",
        "data_train = data_train[data_train.target_x!=data_train.target_y]\n",
        "data_train = data_train[(data_train['target_y'].apply(lambda x: len(x.split(' ')))/data_train['target_x'].apply(lambda x: len(x.split(' '))))<0.8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTuaTxmdbEC6"
      },
      "source": [
        "data_test = pd.read_csv('/content/drive/MyDrive/MT_sentence_simpl/wiki_test_dev_eng.csv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yon-17MsbLU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e234c6-dad2-4cf5-adb4-a698d8ebf356"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1JaNqhyZf-3Fybs3iTo90__4eEN4CmhMl\n",
        "import json\n",
        "from sklearn.utils import shuffle\n",
        "with open('/content/ParaPhraserPlus.json', 'r') as f:\n",
        "  data = json.loads(f.read())\n",
        "\n",
        "import random\n",
        "src, dst = [], []\n",
        "for i in data.keys():\n",
        "  src.append(data[i]['headlines'][0])\n",
        "  dst.append(data[i]['headlines'][1])\n",
        "data = pd.DataFrame(list(zip(src, dst)), columns=['target_x','target_y'])\n",
        "data = data.sample(241000)\n",
        "# random.shuffle(data)\n",
        "data.head(3)\n",
        "data.drop_duplicates(subset=['target_y'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JaNqhyZf-3Fybs3iTo90__4eEN4CmhMl\n",
            "To: /content/ParaPhraserPlus.json\n",
            "1.11GB [00:11, 93.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXQWv5CwbPve"
      },
      "source": [
        "data_train.drop(columns=['src', 'dst'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp8mwsteblZH"
      },
      "source": [
        "data_train = pd.concat((data_train, data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFKPv8hEbsAL"
      },
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0UF9oBHcLfW"
      },
      "source": [
        "data_train = shuffle(data_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ2MLIRicnAH"
      },
      "source": [
        "data_dev = data_train.sample(n=2000, random_state=42)\n",
        "data_train = data_train.drop(data_dev.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYxkYBT4cdd7",
        "outputId": "df9d6889-d8a1-45cc-bc89-f15403c6d6a6"
      },
      "source": [
        "data_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(334256, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svFN7W3yUtjL"
      },
      "source": [
        "## ACCESS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ewRUfV7UtuD",
        "outputId": "92a3e652-0982-42ff-8b51-eb061eb0074b"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1ZelXO1Toyfk7ezW50HEaAdnO5XoORa4P\n",
        "data = pd.read_csv('/content/asset_data_ru.csv')\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/MT_sentence_simpl/wiki_test_dev_eng.csv', sep='\\t')\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "data = shuffle(data)\n",
        "data_dev = data.sample(n=500, random_state=42)\n",
        "data_train = data.drop(data_dev.index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZelXO1Toyfk7ezW50HEaAdnO5XoORa4P\n",
            "To: /content/asset_data_ru.csv\n",
            "\r0.00B [00:00, ?B/s]\r4.72MB [00:00, 30.7MB/s]\r14.7MB [00:00, 69.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "LztPAO-SXRcv",
        "outputId": "18002481-d33a-4d7e-c807-cb5d61379641"
      },
      "source": [
        "data_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>target_x</th>\n",
              "      <th>target_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6300</th>\n",
              "      <td>2710</td>\n",
              "      <td>A Bulldog, also known as British Bulldog or English Bulldog, is a breed of dog which traces its ancestry to England.</td>\n",
              "      <td>A Bulldog, also known as British Bulldog or English Bulldog, is a breed of dog which originates from England.</td>\n",
              "      <td>Бульдог, также известный как британский бульдог или английский бульдог, - это порода собак, которая ведет свое происхождение от Англии.</td>\n",
              "      <td>Бульдог, также известный как британский бульдог или английский бульдог, - это порода собак, которая происходит из Англии.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>486</td>\n",
              "      <td>Mariel of Redwall is a fantasy novel by Brian Jacques, published in 1991.</td>\n",
              "      <td>Mariel of Redwall is a 1991 fantasy book by Brian Jacques.</td>\n",
              "      <td>Мариэль из Редволла - это фантастический роман Брайана Жака, опубликованный в 1991 году.</td>\n",
              "      <td>Мариэль из Редволла - это книга в жанре фэнтези Брайана Жака 1991 года.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19210</th>\n",
              "      <td>15620</td>\n",
              "      <td>The Movie and subsequent additions to the franchise.</td>\n",
              "      <td>The Movie and future additions to the franchise.</td>\n",
              "      <td>Фильм и последующие дополнения к франшизе.</td>\n",
              "      <td>Фильм и будущие дополнения к франшизе.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19504</th>\n",
              "      <td>15914</td>\n",
              "      <td>According to an interview in the UK newspaper The Sun, Heyman wrote the brand's weekly scripts and submitted them to writers for possible changes, and then Vince McMahon for final approval.</td>\n",
              "      <td>According to The Sun, Heyman wrote the brand's scripts and gave them to writers for possible changes, and then to Vince McMahon for final approval.</td>\n",
              "      <td>Согласно интервью британской газете The Sun, Хейман написал еженедельные сценарии бренда и отправил их авторам для возможных изменений, а затем Винсу МакМахону для окончательного утверждения.</td>\n",
              "      <td>Согласно The Sun, Хейман написал сценарии бренда и передал их сценаристам для возможных изменений, а затем Винсу МакМахону для окончательного утверждения.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>573</td>\n",
              "      <td>After graduation he returned to Yerevan to teach at the local Conservatory and later he was appointed artistic director of the Armenian Philarmonic Orchestra.</td>\n",
              "      <td>After graduation he returned to Yerevan to teach at the conservatory. Later he was appointed artistic director of the Armenian Philarmonic Orchestra.</td>\n",
              "      <td>После окончания школы вернулся в Ереван, чтобы преподавать в местной консерватории, а затем был назначен художественным руководителем оркестра Армянской филармонии.</td>\n",
              "      <td>После окончания школы вернулся в Ереван, чтобы преподавать в консерватории. Позже был назначен художественным руководителем Армянского филармонического оркестра.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0                                                                                                                                                                                            src                                                                                                                                                    dst                                                                                                                                                                                         target_x                                                                                                                                                           target_y\n",
              "6300         2710                                                                           A Bulldog, also known as British Bulldog or English Bulldog, is a breed of dog which traces its ancestry to England.                                          A Bulldog, also known as British Bulldog or English Bulldog, is a breed of dog which originates from England.                                                          Бульдог, также известный как британский бульдог или английский бульдог, - это порода собак, которая ведет свое происхождение от Англии.                                          Бульдог, также известный как британский бульдог или английский бульдог, - это порода собак, которая происходит из Англии.\n",
              "486           486                                                                                                                      Mariel of Redwall is a fantasy novel by Brian Jacques, published in 1991.                                                                                             Mariel of Redwall is a 1991 fantasy book by Brian Jacques.                                                                                                         Мариэль из Редволла - это фантастический роман Брайана Жака, опубликованный в 1991 году.                                                                                            Мариэль из Редволла - это книга в жанре фэнтези Брайана Жака 1991 года.\n",
              "19210       15620                                                                                                                                           The Movie and subsequent additions to the franchise.                                                                                                       The Movie and future additions to the franchise.                                                                                                                                                       Фильм и последующие дополнения к франшизе.                                                                                                                             Фильм и будущие дополнения к франшизе.\n",
              "19504       15914  According to an interview in the UK newspaper The Sun, Heyman wrote the brand's weekly scripts and submitted them to writers for possible changes, and then Vince McMahon for final approval.    According to The Sun, Heyman wrote the brand's scripts and gave them to writers for possible changes, and then to Vince McMahon for final approval.  Согласно интервью британской газете The Sun, Хейман написал еженедельные сценарии бренда и отправил их авторам для возможных изменений, а затем Винсу МакМахону для окончательного утверждения.         Согласно The Sun, Хейман написал сценарии бренда и передал их сценаристам для возможных изменений, а затем Винсу МакМахону для окончательного утверждения.\n",
              "573           573                                 After graduation he returned to Yerevan to teach at the local Conservatory and later he was appointed artistic director of the Armenian Philarmonic Orchestra.  After graduation he returned to Yerevan to teach at the conservatory. Later he was appointed artistic director of the Armenian Philarmonic Orchestra.                             После окончания школы вернулся в Ереван, чтобы преподавать в местной консерватории, а затем был назначен художественным руководителем оркестра Армянской филармонии.  После окончания школы вернулся в Ереван, чтобы преподавать в консерватории. Позже был назначен художественным руководителем Армянского филармонического оркестра."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYnt8kN6c1qR"
      },
      "source": [
        "--------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbJCkcM46uWP"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0dc0watrBos"
      },
      "source": [
        "! mkdir /content/fairseq/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYep--fFwsu7"
      },
      "source": [
        "### process WikiLarge\n",
        "\n",
        "with open('/content/fairseq/data/test.en', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.en', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.en', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.ru', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.ru', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.ru', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_y']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqEIc6NkI2lr"
      },
      "source": [
        "### process WikiLarge but with Russian test\n",
        "with open('/content/fairseq/data/test.src', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['INPUT:source']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.src', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['OUTPUT:output']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKOzlK2NKUp7",
        "outputId": "a36b9ed7-0fc0-430a-ffe7-460456f1bcc7"
      },
      "source": [
        "! echo $DATA_DIR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B73jkfOwuq5w"
      },
      "source": [
        "SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "DATA_DIR=\"/content/fairseq/data\"\n",
        "SRC=\"en\"\n",
        "TGT=\"ru\" #en\n",
        "\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$SRC > $DATA_DIR/train.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$TGT > $DATA_DIR/train.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$SRC > $DATA_DIR/dev.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$TGT > $DATA_DIR/dev.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$SRC > $DATA_DIR/test.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$TGT > $DATA_DIR/test.spm.$TGT &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohGRcSLh-lEi"
      },
      "source": [
        "\n",
        "PREPROCESSED_DATA_DIR=\"/content/fairseq/data\"\n",
        "DICT=\"/content/mbart.cc25.v2/dict.txt\"\n",
        "!fairseq-preprocess \\\n",
        "  --source-lang en \\\n",
        "  --target-lang ru \\\n",
        "  --trainpref /content/fairseq/data/train.spm \\\n",
        "  --validpref /content/fairseq/data/dev.spm \\\n",
        "  --testpref /content/fairseq/data/test.spm \\\n",
        "  --destdir /content/fairseq/data \\\n",
        "  --thresholdtgt 0 \\\n",
        "  --thresholdsrc 0 \\\n",
        "  --srcdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --tgtdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --workers 70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFmmrMKh6h8W"
      },
      "source": [
        "Second training with ru-ru"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qb_lVxxrFTo"
      },
      "source": [
        "! rm -r /content/fairseq/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kbxXrLyq9uQ"
      },
      "source": [
        "! mkdir /content/fairseq/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onD8Av1mrKLS"
      },
      "source": [
        "### process translated WikiLarge\n",
        "with open('/content/fairseq/data/test.src', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.src', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_y']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQNDcdvIFy2y"
      },
      "source": [
        "#### process translated WikiLarge + russian dev set as test\n",
        "with open('/content/fairseq/data/test.src', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['INPUT:source']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.src', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['OUTPUT:output']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_y']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwvsggN3v-iG"
      },
      "source": [
        "#### process paraphraser\n",
        "with open('/content/fairseq/data/test.src', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['INPUT:source']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.src', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['OUTPUT:output']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['dst']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjc4EA7eeF3"
      },
      "source": [
        "SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "DATA_DIR=\"/content/fairseq/data\"\n",
        "SRC=\"src\"\n",
        "TGT=\"dst\"\n",
        "\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$SRC > $DATA_DIR/train.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$TGT > $DATA_DIR/train.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$SRC > $DATA_DIR/dev.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$TGT > $DATA_DIR/dev.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$SRC > $DATA_DIR/test.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$TGT > $DATA_DIR/test.spm.$TGT &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ytIfDcp4Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c4963c4-6b99-4963-e3fe-6056b5829a55"
      },
      "source": [
        "\n",
        "PREPROCESSED_DATA_DIR=\"/content/fairseq/data\"\n",
        "DICT=\"/content/mbart.cc25.v2/dict.txt\"\n",
        "!fairseq-preprocess \\\n",
        "  --source-lang src \\\n",
        "  --target-lang dst \\\n",
        "  --trainpref /content/fairseq/data/train.spm \\\n",
        "  --validpref /content/fairseq/data/dev.spm \\\n",
        "  --testpref /content/fairseq/data/test.spm \\\n",
        "  --destdir /content/fairseq/data \\\n",
        "  --thresholdtgt 0 \\\n",
        "  --thresholdsrc 0 \\\n",
        "  --srcdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --tgtdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --workers 70"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 19:05:01 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/content/fairseq/data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='src', srcdict='/content/mbart.cc25.v2/dict.txt', suppress_crashes=False, target_lang='dst', task='translation', tensorboard_logdir=None, testpref='/content/fairseq/data/test.spm', tgtdict='/content/mbart.cc25.v2/dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/fairseq/data/train.spm', use_plasma_view=False, user_dir=None, validpref='/content/fairseq/data/dev.spm', wandb_project=None, workers=70)\n",
            "2021-05-11 19:05:02 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-05-11 19:05:18 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/train.spm.src: 82000 sents, 3727445 tokens, 0.0% replaced by <unk>\n",
            "2021-05-11 19:05:18 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-05-11 19:05:28 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/dev.spm.src: 20066 sents, 925386 tokens, 0.0% replaced by <unk>\n",
            "2021-05-11 19:05:28 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-05-11 19:05:37 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/test.spm.src: 3406 sents, 118537 tokens, 0.0% replaced by <unk>\n",
            "2021-05-11 19:05:37 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-05-11 19:05:50 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/train.spm.dst: 82000 sents, 1814871 tokens, 0.0% replaced by <unk>\n",
            "2021-05-11 19:05:50 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-05-11 19:06:00 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/dev.spm.dst: 20066 sents, 480746 tokens, 0.0% replaced by <unk>\n",
            "2021-05-11 19:06:00 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-05-11 19:06:09 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/test.spm.dst: 3406 sents, 82186 tokens, 0.0% replaced by <unk>\n",
            "2021-05-11 19:06:09 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/fairseq/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhVQUNdQ-po4"
      },
      "source": [
        "The code for training was the same all the times, just \"src\" and \"dst\" parts were changed. So, I do not repeated it six times, but rather altered this one, putting the necessary data in it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SORI3cBePJ1C"
      },
      "source": [
        "# ! rm -r /content/drive/MyDrive/checkpoints_ru_ru_added\n",
        "! mkdir /content/drive/MyDrive/checkpoints_paraphrases_wiki_filtered_20_epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qgJPxOV2Mti"
      },
      "source": [
        "! mkdir /content/drive/MyDrive/checkpoints_ru_ru_add"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mp6ZsTv_fyd"
      },
      "source": [
        "**Also**, it is necessary to make the following change in /content/fairseq/fairseq/tasks/translation_from_pretrained_bart.py:\n",
        "\n",
        "```\n",
        "def __init__(self, args, src_dict, tgt_dict):\n",
        "        super().__init__(args, src_dict, tgt_dict)\n",
        "        self.args = args                  # add this line !!!!!\n",
        "        self.langs = args.langs.split(\",\")\n",
        "        for d in [src_dict, tgt_dict]:\n",
        "            for l in self.langs:\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRVvpjsWALRa"
      },
      "source": [
        "The next two cells should install apex for faster training, but some error occured:("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a58XNSANLm9f",
        "outputId": "52ce95a3-8ee2-47f0-987e-153932d457fb"
      },
      "source": [
        "# %%writefile setup.sh\n",
        "\n",
        "# export CUDA_HOME=/usr/local/cuda-10.1\n",
        "# git clone https://github.com/NVIDIA/apex\n",
        "# pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10POwmcuLqvQ"
      },
      "source": [
        "# !sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq-CRreJAYBT"
      },
      "source": [
        "# Training-------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WNBS1mHCV6O"
      },
      "source": [
        "# those are just some variations in parameters that I tried\n",
        "# > train_log.txt &\n",
        "#  --update-freq 1\n",
        "#  --ddp-backend no_c10d\n",
        "# --max-tokens 1024\n",
        "# --batch-size 4 2\n",
        "# --max-epoch 25\n",
        "# --fp16 \\?????\n",
        "# --update-freq? increase????\n",
        "# --update-freq 2??? 5??\n",
        "# 3\n",
        "# --max-tokens 300\n",
        "#  --ddp-backend no_c10d \\\n",
        "# --fp16 \\\n",
        "# --memory-efficient-fp16 \\\n",
        "# --save-interval-updates 5000 \\\n",
        "# /content/mbart.cc25.v2/model.pt\n",
        "# --max-epoch 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PVUoYwjp6uA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a7ea5a-9778-4927-ca54-273a3c83451a"
      },
      "source": [
        "!fairseq-train /content/fairseq/data \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --arch mbart_large --layernorm-embedding \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
        "  --optimizer adam --adam-eps 1e-06 --adam-betas '(0.9, 0.98)' \\\n",
        "  --lr-scheduler polynomial_decay --lr 3e-05 --warmup-updates 2500 --total-num-update 54725  \\\n",
        "  --dropout 0.3 --attention-dropout 0.1 --weight-decay 0.0 \\\n",
        "  --max-tokens 1024 --update-freq 5 \\\n",
        "  --source-lang src --target-lang dst \\\n",
        "  --batch-size 16 \\\n",
        "  --update-freq 4 \\\n",
        "  --memory-efficient-fp16 \\\n",
        "  --validate-interval 1 \\\n",
        "  --patience 3 \\\n",
        "  --max-epoch 5 \\\n",
        "  --save-interval 5 --keep-last-epochs 10 --keep-best-checkpoints 2 \\\n",
        "  --ddp-backend no_c10d \\\n",
        "  --seed 42 --log-format simple --log-interval 500 \\\n",
        "  --restore-file /content/mbart.cc25.v2/model.pt \\\n",
        "  --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler \\\n",
        "  --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN \\\n",
        "  --scoring bleu \\\n",
        "  --save-dir /content/drive/MyDrive/checkpoints_ru_ru_add"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 19:06:53 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 500, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1024, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [5], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints_ru_ru_add', 'restore_file': '/content/mbart.cc25.v2/model.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 10, 'keep_best_checkpoints': 2, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='mbart_large', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/mbart.cc25.v2/model.pt', save_dir='/content/drive/MyDrive/checkpoints_ru_ru_add', save_interval=5, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='src', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='dst', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': Namespace(_name='translation_from_pretrained_bart', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/mbart.cc25.v2/model.pt', save_dir='/content/drive/MyDrive/checkpoints_ru_ru_add', save_interval=5, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='src', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='dst', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 2500, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 54725.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}\n",
            "2021-05-11 19:06:54 | INFO | fairseq.tasks.translation | [src] dictionary: 250001 types\n",
            "2021-05-11 19:06:54 | INFO | fairseq.tasks.translation | [dst] dictionary: 250001 types\n",
            "2021-05-11 19:07:15 | INFO | fairseq_cli.train | BARTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=1024, out_features=250027, bias=False)\n",
            "  )\n",
            "  (classification_heads): ModuleDict()\n",
            ")\n",
            "2021-05-11 19:07:15 | INFO | fairseq_cli.train | task: TranslationFromPretrainedBARTTask\n",
            "2021-05-11 19:07:15 | INFO | fairseq_cli.train | model: BARTModel\n",
            "2021-05-11 19:07:15 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-05-11 19:07:15 | INFO | fairseq_cli.train | num. shared model params: 610,851,840 (num. trained: 610,851,840)\n",
            "2021-05-11 19:07:15 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-05-11 19:07:15 | INFO | fairseq.data.data_utils | loaded 20,066 examples from: /content/fairseq/data/valid.src-dst.src\n",
            "2021-05-11 19:07:15 | INFO | fairseq.data.data_utils | loaded 20,066 examples from: /content/fairseq/data/valid.src-dst.dst\n",
            "2021-05-11 19:07:15 | INFO | fairseq.tasks.translation | /content/fairseq/data valid src-dst 20066 examples\n",
            "2021-05-11 19:07:23 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2021-05-11 19:07:23 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2021-05-11 19:07:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-05-11 19:07:23 | INFO | fairseq.utils | rank   0: capabilities =  6.0  ; total memory = 15.899 GB ; name = Tesla P100-PCIE-16GB                    \n",
            "2021-05-11 19:07:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-05-11 19:07:23 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-05-11 19:07:23 | INFO | fairseq_cli.train | max tokens per device = 1024 and max sentences per device = 16\n",
            "2021-05-11 19:07:23 | INFO | fairseq.trainer | Preparing to load checkpoint /content/mbart.cc25.v2/model.pt\n",
            "tcmalloc: large alloc 2443411456 bytes == 0x563c843da000 @  0x7ff7e53d2b6b 0x7ff7e53f2379 0x7ff772d1a25e 0x7ff772d1b9d2 0x7ff7b0d44e7d 0x7ff7c193f120 0x7ff7c157dbd9 0x563badd5a8a8 0x563baddcdfd5 0x563baddc87ad 0x563badd5b3ea 0x563baddc93b5 0x563baddc87ad 0x563badd5b003 0x563badd5ab09 0x563badea228d 0x563bade111db 0x563badd59bb1 0x563bade4afed 0x563baddcd988 0x563baddc87ad 0x563badc9ae2c 0x563baddcabb5 0x563baddc84ae 0x563badd5b3ea 0x563baddca32a 0x563baddc84ae 0x563badd5b3ea 0x563baddca32a 0x563baddc84ae 0x563badd5b3ea\n",
            "tcmalloc: large alloc 2443411456 bytes == 0x563d16612000 @  0x7ff7e53d2b6b 0x7ff7e53f2379 0x7ff772d1a25e 0x7ff772d1b9d2 0x7ff7b0d44e7d 0x7ff7c193f120 0x7ff7c157dbd9 0x563badd5a8a8 0x563baddcdfd5 0x563baddc87ad 0x563badd5b3ea 0x563baddc93b5 0x563baddc87ad 0x563badd5b003 0x563badd5ab09 0x563badea228d 0x563bade111db 0x563badd59bb1 0x563bade4afed 0x563baddcd988 0x563baddc87ad 0x563badc9ae2c 0x563baddcabb5 0x563baddc84ae 0x563badd5b3ea 0x563baddca32a 0x563baddc84ae 0x563badd5b3ea 0x563baddca32a 0x563baddc84ae 0x563badd5b3ea\n",
            "2021-05-11 19:08:49 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster\n",
            "2021-05-11 19:08:49 | INFO | fairseq.trainer | Loaded checkpoint /content/mbart.cc25.v2/model.pt (epoch 142 @ 0 updates)\n",
            "2021-05-11 19:08:49 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-05-11 19:08:49 | INFO | fairseq.data.data_utils | loaded 82,000 examples from: /content/fairseq/data/train.src-dst.src\n",
            "2021-05-11 19:08:49 | INFO | fairseq.data.data_utils | loaded 82,000 examples from: /content/fairseq/data/train.src-dst.dst\n",
            "2021-05-11 19:08:49 | INFO | fairseq.tasks.translation | /content/fairseq/data train src-dst 82000 examples\n",
            "2021-05-11 19:08:50 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-05-11 19:08:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/fairseq/fairseq/utils.py:364: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "2021-05-11 19:08:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "2021-05-11 19:08:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "2021-05-11 19:08:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "2021-05-11 19:08:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "2021-05-11 19:08:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "2021-05-11 19:09:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0\n",
            "2021-05-11 19:09:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0\n",
            "2021-05-11 19:09:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5\n",
            "2021-05-11 19:09:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25\n",
            "2021-05-11 19:10:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125\n",
            "2021-05-11 19:13:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625\n",
            "2021-05-11 19:22:26 | INFO | train_inner | epoch 001:    511 / 1198 loss=28.895, nll_loss=16.271, ppl=79062.9, wps=996, ups=0.62, wpb=1606.9, bsz=68.6, num_updates=500, lr=6e-06, gnorm=138.268, loss_scale=0.0625, train_wall=814, gb_free=6.2, wall=903\n",
            "2021-05-11 19:35:32 | INFO | train_inner | epoch 001:   1011 / 1198 loss=12.242, nll_loss=8.931, ppl=488.16, wps=995, ups=0.64, wpb=1565, bsz=68.3, num_updates=1000, lr=1.2e-05, gnorm=6.806, loss_scale=0.0625, train_wall=784, gb_free=6.2, wall=1689\n",
            "2021-05-11 19:40:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-05-11 19:43:04 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.075 | nll_loss 3.416 | ppl 10.67 | wps 3237 | wpb 337 | bsz 13.5 | num_updates 1187\n",
            "2021-05-11 19:43:04 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-05-11 19:43:04 | INFO | train | epoch 001 | loss 18.862 | nll_loss 11.515 | ppl 2925.89 | wps 919.2 | ups 0.58 | wpb 1584 | bsz 68.4 | num_updates 1187 | lr 1.4244e-05 | gnorm 61.851 | loss_scale 0.0625 | train_wall 1895 | gb_free 6.2 | wall 2142\n",
            "2021-05-11 19:43:04 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-05-11 19:43:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-05-11 19:51:22 | INFO | train_inner | epoch 002:    313 / 1198 loss=8.606, nll_loss=4.943, ppl=30.77, wps=835.8, ups=0.53, wpb=1587.7, bsz=69, num_updates=1500, lr=1.8e-05, gnorm=3.994, loss_scale=0.0625, train_wall=793, gb_free=6.2, wall=2639\n",
            "2021-05-11 20:04:32 | INFO | train_inner | epoch 002:    813 / 1198 loss=7.733, nll_loss=4.082, ppl=16.94, wps=991.3, ups=0.63, wpb=1566.8, bsz=67.7, num_updates=2000, lr=2.4e-05, gnorm=3.441, loss_scale=0.0625, train_wall=788, gb_free=6.2, wall=3429\n",
            "2021-05-11 20:14:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-05-11 20:17:17 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.588 | nll_loss 2.612 | ppl 6.11 | wps 3256.8 | wpb 337 | bsz 13.5 | num_updates 2385\n",
            "2021-05-11 20:17:17 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-05-11 20:17:17 | INFO | train | epoch 002 | loss 7.784 | nll_loss 4.129 | ppl 17.49 | wps 924.1 | ups 0.58 | wpb 1583.4 | bsz 68.4 | num_updates 2385 | lr 2.862e-05 | gnorm 3.345 | loss_scale 0.0625 | train_wall 1894 | gb_free 6.2 | wall 4194\n",
            "2021-05-11 20:17:17 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-05-11 20:17:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-05-11 20:20:21 | INFO | train_inner | epoch 003:    115 / 1198 loss=7.366, nll_loss=3.7, ppl=12.99, wps=844.4, ups=0.53, wpb=1601.9, bsz=68.7, num_updates=2500, lr=3e-05, gnorm=2.995, loss_scale=0.0625, train_wall=793, gb_free=6.2, wall=4378\n",
            "2021-05-11 20:33:29 | INFO | train_inner | epoch 003:    615 / 1198 loss=7.24, nll_loss=3.553, ppl=11.74, wps=995.4, ups=0.63, wpb=1569.2, bsz=68.7, num_updates=3000, lr=2.97128e-05, gnorm=3.011, loss_scale=0.0625, train_wall=786, gb_free=6.2, wall=5166\n",
            "2021-05-11 20:46:45 | INFO | train_inner | epoch 003:   1115 / 1198 loss=7.165, nll_loss=3.47, ppl=11.08, wps=1002.4, ups=0.63, wpb=1595.7, bsz=68.2, num_updates=3500, lr=2.94256e-05, gnorm=3.273, loss_scale=0.125, train_wall=794, gb_free=6.2, wall=5962\n",
            "2021-05-11 20:48:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-05-11 20:51:28 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.396 | nll_loss 2.406 | ppl 5.3 | wps 3245.4 | wpb 337 | bsz 13.5 | num_updates 3583\n",
            "2021-05-11 20:51:28 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-05-11 20:51:28 | INFO | train | epoch 003 | loss 7.196 | nll_loss 3.506 | ppl 11.36 | wps 924.9 | ups 0.58 | wpb 1583.4 | bsz 68.4 | num_updates 3583 | lr 2.93779e-05 | gnorm 3.093 | loss_scale 0.125 | train_wall 1892 | gb_free 6.2 | wall 6245\n",
            "2021-05-11 20:51:28 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2021-05-11 20:51:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-05-11 21:02:28 | INFO | train_inner | epoch 004:    417 / 1198 loss=6.932, nll_loss=3.247, ppl=9.49, wps=830.7, ups=0.53, wpb=1566.6, bsz=68.5, num_updates=4000, lr=2.91383e-05, gnorm=2.722, loss_scale=0.125, train_wall=786, gb_free=6.2, wall=6905\n",
            "2021-05-11 21:15:40 | INFO | train_inner | epoch 004:    917 / 1198 loss=6.826, nll_loss=3.142, ppl=8.83, wps=1002.8, ups=0.63, wpb=1588.4, bsz=68.5, num_updates=4500, lr=2.88511e-05, gnorm=2.48, loss_scale=0.125, train_wall=790, gb_free=6.2, wall=7697\n",
            "2021-05-11 21:23:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-05-11 21:25:40 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.331 | nll_loss 2.304 | ppl 4.94 | wps 3241 | wpb 337 | bsz 13.5 | num_updates 4781\n",
            "2021-05-11 21:25:40 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2021-05-11 21:25:40 | INFO | train | epoch 004 | loss 6.848 | nll_loss 3.164 | ppl 8.96 | wps 924.4 | ups 0.58 | wpb 1583.4 | bsz 68.4 | num_updates 4781 | lr 2.86897e-05 | gnorm 2.54 | loss_scale 0.125 | train_wall 1893 | gb_free 6.2 | wall 8297\n",
            "2021-05-11 21:25:40 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2021-05-11 21:25:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-05-11 21:31:30 | INFO | train_inner | epoch 005:    219 / 1198 loss=6.765, nll_loss=3.08, ppl=8.45, wps=840.4, ups=0.53, wpb=1596.9, bsz=68.4, num_updates=5000, lr=2.85639e-05, gnorm=2.416, loss_scale=0.125, train_wall=793, gb_free=6.2, wall=8647\n",
            "2021-05-11 21:44:39 | INFO | train_inner | epoch 005:    719 / 1198 loss=6.679, nll_loss=2.983, ppl=7.9, wps=1000.9, ups=0.63, wpb=1579.5, bsz=68.6, num_updates=5500, lr=2.82767e-05, gnorm=2.288, loss_scale=0.125, train_wall=787, gb_free=5.6, wall=9436\n",
            "2021-05-11 21:57:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-05-11 21:59:51 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.23 | nll_loss 2.236 | ppl 4.71 | wps 3255.3 | wpb 337 | bsz 13.5 | num_updates 5979\n",
            "2021-05-11 21:59:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5979 updates\n",
            "2021-05-11 21:59:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru_add/checkpoint5.pt\n",
            "2021-05-11 22:01:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru_add/checkpoint5.pt\n",
            "2021-05-11 22:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_ru_ru_add/checkpoint5.pt (epoch 5 @ 5979 updates, score 6.23) (writing took 749.9884561040017 seconds)\n",
            "2021-05-11 22:12:21 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2021-05-11 22:12:22 | INFO | train | epoch 005 | loss 6.683 | nll_loss 2.989 | ppl 7.94 | wps 677.1 | ups 0.43 | wpb 1583.4 | bsz 68.4 | num_updates 5979 | lr 2.80015e-05 | gnorm 2.293 | loss_scale 0.125 | train_wall 1892 | gb_free 6.2 | wall 11099\n",
            "2021-05-11 22:12:22 | INFO | fairseq_cli.train | done training in 11012.6 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THMHq9onL9a1"
      },
      "source": [
        "#https://github.com/awesomedata/awesome-public-datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2RWc0DXB2_i"
      },
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SX03pxxrBuId",
        "outputId": "5a910c8b-a2be-4f5f-afb0-8b7abd1a1186"
      },
      "source": [
        "data_train.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>target_x</th>\n",
              "      <th>target_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>198495</th>\n",
              "      <td>198495</td>\n",
              "      <td>The Mahseer ( Tor putitora ) , an indigenous riverine fish found in the Hub River , grows up to 2m in length and provides for excellent angling .</td>\n",
              "      <td>The Mahseer ( Tor putitora ) , an indigenous riverine fish found in the Hub River , grows up to 2m in length and is fished .</td>\n",
              "      <td>Махсир (Tor putitora), местная речная рыба, обитающая в реке Хаб, вырастает до 2 м в длину и обеспечивает отличную рыбалку.</td>\n",
              "      <td>Махсир (Тор путитора), местная речная рыба, обитающая в реке Хаб, вырастает до 2 м в длину, и ее ловят.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245110</th>\n",
              "      <td>245110</td>\n",
              "      <td>A constituent country is a country that is part of a larger entity , such as a sovereign state or supranational body .</td>\n",
              "      <td>A constituent country is a country which makes up a part of a larger country , or federation .</td>\n",
              "      <td>Составляющая страна - это страна, которая является частью более крупного образования, такого как суверенное государство или наднациональный орган.</td>\n",
              "      <td>Составляющая страна - это страна, которая является частью более крупной страны или федерации.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95476</th>\n",
              "      <td>95476</td>\n",
              "      <td>Chinese in Penang , Kuala Lumpur , of Malaysia also pray to Lord Murugan during Thaipusam .</td>\n",
              "      <td>He is the son of Lord Shiva and Goddess Parvati .</td>\n",
              "      <td>Китайцы в Пенанге, Куала-Лумпур, Малайзии, также молятся Господу Муругану во время Тайпусама.</td>\n",
              "      <td>Он сын Господа Шивы и богини Парвати.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216288</th>\n",
              "      <td>216288</td>\n",
              "      <td>15 5 | - style = '' background-color : #c 0ffff '' | Argon | | Ar | | 18 | | 39.948 ( 1 ) The isotopic composition varies in terrestrial material such that a more precise atomic weight can not be given .</td>\n",
              "      <td>15 5 | - | Argon | | Ar | | 18 | | 39.948 ( 1 ) The isotopic composition varies in terrestrial material such that a more precise atomic weight can not be given .</td>\n",
              "      <td>15 5 | - style = '' background-color: #c 0ffff '' | Аргон | | Ar | | 18 | | 39.948 (1) Изотопный состав земного материала различается, поэтому более точный атомный вес дать невозможно.</td>\n",
              "      <td>15 5 | - | Аргон | | Ar | | 18 | | 39.948 (1) Изотопный состав земного материала различается, поэтому более точный атомный вес дать невозможно.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138765</th>\n",
              "      <td>138765</td>\n",
              "      <td>Old French was the Romance dialect continuum spoken in territories which span roughly the northern half of modern France and parts of modern Belgium and Switzerland from around 900 to 1300 .</td>\n",
              "      <td>Old French was the Romance dialect continuum spoken in the places of northern half of modern France and parts of modern Belgium and Switzerland from around 1000 to 1300 .</td>\n",
              "      <td>Старофранцузский язык был континуумом романского диалекта, на котором говорили на территориях, которые охватывали примерно северную половину современной Франции и части современной Бельгии и Швейцарии примерно с 900 по 1300 год.</td>\n",
              "      <td>Старофранцузский был континуумом романского диалекта, на котором говорили в местах северной половины современной Франции и некоторых частях современной Бельгии и Швейцарии примерно с 1000 по 1300 год.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29328</th>\n",
              "      <td>29328</td>\n",
              "      <td>The M6 is the longest motorway in the United Kingdom and one of the busiest .</td>\n",
              "      <td>The M6 motorway is the longest motorway in the United Kingdom .</td>\n",
              "      <td>M6 - самая длинная автомагистраль в Соединенном Королевстве и одна из самых загруженных.</td>\n",
              "      <td>Автомагистраль M6 - самая длинная автомагистраль в Соединенном Королевстве.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170674</th>\n",
              "      <td>170674</td>\n",
              "      <td>DIN 476 : international paper sizes ( now ISO 216 or DIN EN ISO 216 ) DIN 946 : Determination of coefficient of friction of bolt/nut assemblies under specified conditions .</td>\n",
              "      <td>Example of DIN standards DIN 476 : international paper sizes ( now ISO 216 or DIN EN ISO 216 ) .</td>\n",
              "      <td>DIN 476: международные форматы бумаги (теперь ISO 216 или DIN EN ISO 216) DIN 946: Определение коэффициента трения сборок болт / гайка при определенных условиях.</td>\n",
              "      <td>Пример стандартов DIN DIN 476: международные форматы бумаги (теперь ISO 216 или DIN EN ISO 216).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150709</th>\n",
              "      <td>150709</td>\n",
              "      <td>In the early 2000s , the genre name began to describe a different , slower and less dissonant style that borrowed from alternative rock .</td>\n",
              "      <td>While many types of music have screaming vocals , screamo usually has a certain kind of harsher screaming .</td>\n",
              "      <td>В начале 2000-х название жанра начало описывать другой, более медленный и менее противоречивый стиль, заимствованный из альтернативного рока.</td>\n",
              "      <td>В то время как во многих музыкальных стилях есть кричащий вокал, у скримо обычно более резкий крик.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22361</th>\n",
              "      <td>22361</td>\n",
              "      <td>They were first observed in 1869 by German physicist Johann Hittorf , and were named in 1876 by Eugen Goldstein kathodenstrahlen , or cathode rays .</td>\n",
              "      <td>A Cathode ray is a stream of electrons that are seen in vacuum tubes .</td>\n",
              "      <td>Впервые они были обнаружены в 1869 году немецким физиком Иоганном Хитторфом и в 1876 году были названы Ойгеном Гольдштейном катоденстрахленом, или катодными лучами.</td>\n",
              "      <td>Катодный луч - это поток электронов, который виден в электронных лампах.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93282</th>\n",
              "      <td>93282</td>\n",
              "      <td>Following the title 's introduction in 1975 , Harley Race became the inaugural champion on January 1 .</td>\n",
              "      <td>The title became '' Undisputed '' in January 1981 when no other United States title was recognized in other promotions governed by the National Wrestling Alliance .</td>\n",
              "      <td>После введения этого титула в 1975 году Harley Race 1 января стал первым чемпионом.</td>\n",
              "      <td>Этот титул стал «бесспорным» в январе 1981 года, когда ни один другой титул Соединенных Штатов не был признан в других акциях, проводимых Национальным борцовским альянсом.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0                                                                                                                                                                                                          src                                                                                                                                                                         dst                                                                                                                                                                                                                              target_x                                                                                                                                                                                                  target_y\n",
              "198495      198495                                                            The Mahseer ( Tor putitora ) , an indigenous riverine fish found in the Hub River , grows up to 2m in length and provides for excellent angling .                                                The Mahseer ( Tor putitora ) , an indigenous riverine fish found in the Hub River , grows up to 2m in length and is fished .                                                                                                           Махсир (Tor putitora), местная речная рыба, обитающая в реке Хаб, вырастает до 2 м в длину и обеспечивает отличную рыбалку.                                                                                                   Махсир (Тор путитора), местная речная рыба, обитающая в реке Хаб, вырастает до 2 м в длину, и ее ловят.\n",
              "245110      245110                                                                                       A constituent country is a country that is part of a larger entity , such as a sovereign state or supranational body .                                                                              A constituent country is a country which makes up a part of a larger country , or federation .                                                                                    Составляющая страна - это страна, которая является частью более крупного образования, такого как суверенное государство или наднациональный орган.                                                                                                             Составляющая страна - это страна, которая является частью более крупной страны или федерации.\n",
              "95476        95476                                                                                                                  Chinese in Penang , Kuala Lumpur , of Malaysia also pray to Lord Murugan during Thaipusam .                                                                                                                           He is the son of Lord Shiva and Goddess Parvati .                                                                                                                                         Китайцы в Пенанге, Куала-Лумпур, Малайзии, также молятся Господу Муругану во время Тайпусама.                                                                                                                                                                     Он сын Господа Шивы и богини Парвати.\n",
              "216288      216288  15 5 | - style = '' background-color : #c 0ffff '' | Argon | | Ar | | 18 | | 39.948 ( 1 ) The isotopic composition varies in terrestrial material such that a more precise atomic weight can not be given .           15 5 | - | Argon | | Ar | | 18 | | 39.948 ( 1 ) The isotopic composition varies in terrestrial material such that a more precise atomic weight can not be given .                                              15 5 | - style = '' background-color: #c 0ffff '' | Аргон | | Ar | | 18 | | 39.948 (1) Изотопный состав земного материала различается, поэтому более точный атомный вес дать невозможно.                                                           15 5 | - | Аргон | | Ar | | 18 | | 39.948 (1) Изотопный состав земного материала различается, поэтому более точный атомный вес дать невозможно.\n",
              "138765      138765               Old French was the Romance dialect continuum spoken in territories which span roughly the northern half of modern France and parts of modern Belgium and Switzerland from around 900 to 1300 .  Old French was the Romance dialect continuum spoken in the places of northern half of modern France and parts of modern Belgium and Switzerland from around 1000 to 1300 .  Старофранцузский язык был континуумом романского диалекта, на котором говорили на территориях, которые охватывали примерно северную половину современной Франции и части современной Бельгии и Швейцарии примерно с 900 по 1300 год.  Старофранцузский был континуумом романского диалекта, на котором говорили в местах северной половины современной Франции и некоторых частях современной Бельгии и Швейцарии примерно с 1000 по 1300 год.\n",
              "29328        29328                                                                                                                                The M6 is the longest motorway in the United Kingdom and one of the busiest .                                                                                                             The M6 motorway is the longest motorway in the United Kingdom .                                                                                                                                              M6 - самая длинная автомагистраль в Соединенном Королевстве и одна из самых загруженных.                                                                                                                               Автомагистраль M6 - самая длинная автомагистраль в Соединенном Королевстве.\n",
              "170674      170674                                 DIN 476 : international paper sizes ( now ISO 216 or DIN EN ISO 216 ) DIN 946 : Determination of coefficient of friction of bolt/nut assemblies under specified conditions .                                                                            Example of DIN standards DIN 476 : international paper sizes ( now ISO 216 or DIN EN ISO 216 ) .                                                                     DIN 476: международные форматы бумаги (теперь ISO 216 или DIN EN ISO 216) DIN 946: Определение коэффициента трения сборок болт / гайка при определенных условиях.                                                                                                          Пример стандартов DIN DIN 476: международные форматы бумаги (теперь ISO 216 или DIN EN ISO 216).\n",
              "150709      150709                                                                    In the early 2000s , the genre name began to describe a different , slower and less dissonant style that borrowed from alternative rock .                                                                 While many types of music have screaming vocals , screamo usually has a certain kind of harsher screaming .                                                                                         В начале 2000-х название жанра начало описывать другой, более медленный и менее противоречивый стиль, заимствованный из альтернативного рока.                                                                                                       В то время как во многих музыкальных стилях есть кричащий вокал, у скримо обычно более резкий крик.\n",
              "22361        22361                                                         They were first observed in 1869 by German physicist Johann Hittorf , and were named in 1876 by Eugen Goldstein kathodenstrahlen , or cathode rays .                                                                                                      A Cathode ray is a stream of electrons that are seen in vacuum tubes .                                                                  Впервые они были обнаружены в 1869 году немецким физиком Иоганном Хитторфом и в 1876 году были названы Ойгеном Гольдштейном катоденстрахленом, или катодными лучами.                                                                                                                                  Катодный луч - это поток электронов, который виден в электронных лампах.\n",
              "93282        93282                                                                                                       Following the title 's introduction in 1975 , Harley Race became the inaugural champion on January 1 .        The title became '' Undisputed '' in January 1981 when no other United States title was recognized in other promotions governed by the National Wrestling Alliance .                                                                                                                                                   После введения этого титула в 1975 году Harley Race 1 января стал первым чемпионом.                               Этот титул стал «бесспорным» в январе 1981 года, когда ни один другой титул Соединенных Штатов не был признан в других акциях, проводимых Национальным борцовским альянсом."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LGGmjSE_JLO"
      },
      "source": [
        "### Test to check that everything is ok and get prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpbpDtlCCY5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d2cced-b790-4a21-9554-9f0a82127d3b"
      },
      "source": [
        "! pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-_s-v3np7l_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb0845e-1386-4f65-d1d3-60ff04d02df5"
      },
      "source": [
        "!fairseq-generate /content/fairseq/data \\\n",
        "  --path /content/drive/MyDrive/checkpoints_ru_ru_add/checkpoint_best.pt \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --gen-subset test \\\n",
        "  --source-lang src --target-lang dst \\\n",
        "  --bpe 'sentencepiece' --sentencepiece-model /content/mbart.cc25.v2/sentence.bpe.model \\\n",
        "  --sacrebleu --remove-bpe 'sentencepiece' \\\n",
        "  --batch-size 32 --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN > model_prediction.txt & \n",
        "!cat model_prediction.txt | grep -P \"^H\" |sort -V |cut -f 3- > model_prediction_wiki_15ru_ru.hyp\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uTQhW_loj0E"
      },
      "source": [
        "! rm -rf /content/drive/MyDrive/checkpoints_ru_ru_add"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AveEGRSdiTUl"
      },
      "source": [
        "a = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3bcXrIBE482"
      },
      "source": [
        "!cp /content/model_prediction_wiki_20_filtered.hyp /content/drive/MyDrive/MT_sentence_simpl/predictions/model_prediction_wiki_20_filtered.hyp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z33ymqaXA9Ci"
      },
      "source": [
        "# Also, try SARI evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imXXZKIKqXjK",
        "outputId": "9ed34945-e282-4555-a55b-c26128ec9b6a"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxVrDxwiqXpG"
      },
      "source": [
        "! git clone https://github.com/feralvam/easse\n",
        "! git clone https://github.com/Andoree/sent_simplification.git\n",
        "%cp /content/sent_simplification/sari.py /content/easse/easse\n",
        "%cd easse\n",
        "! pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FINU32l7rajY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d53e5b-48f4-4e17-a304-1a07c7e5dd38"
      },
      "source": [
        "%cd /content\n",
        "! mkdir prepared_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch6UCNu4BF3_"
      },
      "source": [
        "Prepare data for SARI calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMMX34zuwYvj"
      },
      "source": [
        "!rm -r prepared_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bScRNyEuO5LG",
        "outputId": "3a9692c4-d822-452d-e8d0-a90b4ea8675c"
      },
      "source": [
        "! python /content/sent_simplification/refs_to_easse_format.py \\\n",
        "--input_path /content/drive/MyDrive/MT_sentence_simpl/wiki_test_dev_eng.csv \\\n",
        "--output_dataset_name test_ref_data \\\n",
        "--src_column \"INPUT:source\" \\\n",
        "--trg_column \"OUTPUT:output\" \\\n",
        "--output_dir /content/prepared_data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "3406\n",
            "3406\n",
            "Overall number of references: 3406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVmfSmjMmMPl"
      },
      "source": [
        "with open('/content/drive/MyDrive/MT_sentence_simpl/predictions/model_prediction_paraphraser2.hyp', 'r') as f:\n",
        "  sentences = [i.strip()+'.' for i in f.readlines()]\n",
        "\n",
        "lt = list()\n",
        "st = set()\n",
        "for i in sentences:\n",
        "  if i not in st:\n",
        "    lt.append(i)\n",
        "    st.add(i)\n",
        "\n",
        "with open('/content/model_prediction_paraphraser2.hyp', 'w') as f:\n",
        "  for i in lt:\n",
        "    f.write(i+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJzuBsZRxKbV",
        "outputId": "ad71987e-d3f1-4c15-d51f-8ca3dc9af264"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91v8RGbDy3DJ",
        "outputId": "714e9bcc-5dfa-426e-c316-9bdb2782b39c"
      },
      "source": [
        "! easse evaluate \\\n",
        "--test_set custom \\\n",
        "--metrics sari \\\n",
        "--refs_sents_paths /content/prepared_data/test_ref_data.ref.0,/content/prepared_data/test_ref_data.ref.1,/content/prepared_data/test_ref_data.ref.2,/content/prepared_data/test_ref_data.ref.3,/content/prepared_data/test_ref_data.ref.4 \\\n",
        "--orig_sents_path /content/prepared_data/test_ref_data.src \\\n",
        "--sys_sents_path /content/model_prediction_paraphraser2.hyp -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sari': 34.851, 'quality_estimation': {'Compression ratio': 0.605, 'Sentence splits': 0.984, 'Levenshtein similarity': 0.7, 'Exact copies': 0.031, 'Additions proportion': 0.043, 'Deletions proportion': 0.45, 'Lexical complexity score': 10.745}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}