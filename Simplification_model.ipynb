{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simplification_model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsBwXlp4rSVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b5cd1f-c368-4536-ec22-c690d007c9e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdLEB9tl608G"
      },
      "source": [
        "# Models Finetuning\n",
        "\n",
        "In this notebook several models will be finetuned to perform sentence simplification in Russian. All the models will be tuned with the parametres offered at RuSimpleSentEval competition. The main objective is not to achieve the best performance but rather compare different models trained with and without translated data. In every case training will last 5 epochs. Overall, there are five models:\n",
        "\n",
        "* Model trained on origibal WikiLarge data to perform task for English\n",
        "* Model trained on pairs: original english - simplified russian sentence. So, it learns both translate and simplify at the same time.\n",
        "* Model trained only on the translated to Russian data.\n",
        "* Model trained firstly on the original data and then on the translated corpus\n",
        "\n",
        "All the models will be evaluated and compared \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i32ckGda9oaO"
      },
      "source": [
        "### Necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ZzPlC152qt"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIi2XjuYcMMz"
      },
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fairseq/models/mbart/mbart.cc25.v2.tar.gz\n",
        "! tar -xzvf /content/mbart.cc25.v2.tar.gz\n",
        "! apt-get install cmake build-essential pkg-config libgoogle-perftools-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j87XOhecayN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe94b36-7082-4abf-f969-330cf6764de7"
      },
      "source": [
        "!git clone https://github.com/google/sentencepiece.git \n",
        "%cd sentencepiece\n",
        "!mkdir build"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sentencepiece'...\n",
            "remote: Enumerating objects: 3677, done.\u001b[K\n",
            "remote: Total 3677 (delta 0), reused 0 (delta 0), pack-reused 3677\u001b[K\n",
            "Receiving objects: 100% (3677/3677), 28.56 MiB | 17.55 MiB/s, done.\n",
            "Resolving deltas: 100% (2581/2581), done.\n",
            "/content/sentencepiece\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TfHtcvLgOo3"
      },
      "source": [
        "%cd build\n",
        "!cmake ..\n",
        "!make\n",
        "!make install\n",
        "!ldconfig -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7drZkrlhKRI"
      },
      "source": [
        "# from sentencepiece git\n",
        "# !git clone https://github.com/google/sentencepiece.git \n",
        "# %cd sentencepiece\n",
        "# %mkdir build\n",
        "# %cd build\n",
        "# !cmake ..\n",
        "# !make -j $(nproc)\n",
        "# !sudo make install\n",
        "# !sudo ldconfig -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttHTJJDlNQeN",
        "outputId": "fbf9f379-1d09-4f08-eca1-78e9cf658f86"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y97dbn4glP8"
      },
      "source": [
        "# !git clone https://github.com/pytorch/fairseq\n",
        "# !cd fairseq\n",
        "# %pip install --editable ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-bGJgZxEjs3"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd /content/fairseq/\n",
        "!python -m pip install --editable .\n",
        "%cd /content\n",
        "\n",
        "! echo $PYTHONPATH\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
        "\n",
        "! echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJx4ErDFoVRK",
        "outputId": "885d3b99-1229-4a7a-922e-e8ead16732b7"
      },
      "source": [
        "#  cd /content/fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCTRFTHAk4MI"
      },
      "source": [
        "# %pip install --editable ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rArBmSu5288b"
      },
      "source": [
        "# !python setup.py build develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHDYjuNw-W6y"
      },
      "source": [
        "### Loading data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u75RYDUVsy95"
      },
      "source": [
        "! mkdir data\n",
        "! gdown https://drive.google.com/uc?id=1bJo8TagTGKa0uyppQRqsHrKHyYO5tcZc\n",
        "! gdown https://drive.google.com/uc?id=11lqipq6ggrgCk8bVxQ4-uuPVMCKN5ebU\n",
        "! gdown https://drive.google.com/uc?id=1dB3X-Wx8qU_5nDG_pxAmLvo5H_sgnHrE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX4irYkJGL5V",
        "outputId": "dc38aaf3-0b3e-4241-d2c2-46cc52c0b258"
      },
      "source": [
        "% cd /content/fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuPMtHlewRly"
      },
      "source": [
        "data_train = pd.read_csv('/content/wiki_train_cleaned_translated_sd.csv')\n",
        "data_dev = pd.read_csv('/content/wiki_dev_cleaned_translated_sd.csv')\n",
        "data_test  = pd.read_csv('/content/wiki_test_cleaned_translated_sd.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbJCkcM46uWP"
      },
      "source": [
        "First training with en-ru data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYep--fFwsu7"
      },
      "source": [
        "with open('/content/fairseq/data/test.en', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.en', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.en', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.ru', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.ru', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.ru', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_y']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZepP4O77DFze"
      },
      "source": [
        "# %%bash\n",
        "# export SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "# export BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "# export DATA_DIR=\"/content/fairseq/data\"\n",
        "# export SRC=\"en\"\n",
        "# export TGT=\"en\" #ru"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKOzlK2NKUp7",
        "outputId": "a36b9ed7-0fc0-430a-ffe7-460456f1bcc7"
      },
      "source": [
        "! echo $DATA_DIR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B73jkfOwuq5w"
      },
      "source": [
        "SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "DATA_DIR=\"/content/fairseq/data\"\n",
        "SRC=\"en\"\n",
        "TGT=\"ru\" #en\n",
        "\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$SRC > $DATA_DIR/train.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$TGT > $DATA_DIR/train.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$SRC > $DATA_DIR/dev.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$TGT > $DATA_DIR/dev.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$SRC > $DATA_DIR/test.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$TGT > $DATA_DIR/test.spm.$TGT &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIwsmgCHBd1D",
        "outputId": "c0c09f09-9a82-42ee-bb51-f15aed393311"
      },
      "source": [
        "#%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohGRcSLh-lEi"
      },
      "source": [
        "\n",
        "PREPROCESSED_DATA_DIR=\"/content/fairseq/data\"\n",
        "DICT=\"/content/mbart.cc25.v2/dict.txt\"\n",
        "!fairseq-preprocess \\\n",
        "  --source-lang en \\\n",
        "  --target-lang ru \\\n",
        "  --trainpref /content/fairseq/data/train.spm \\\n",
        "  --validpref /content/fairseq/data/dev.spm \\\n",
        "  --testpref /content/fairseq/data/test.spm \\\n",
        "  --destdir /content/fairseq/data \\\n",
        "  --thresholdtgt 0 \\\n",
        "  --thresholdsrc 0 \\\n",
        "  --srcdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --tgtdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --workers 70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFmmrMKh6h8W"
      },
      "source": [
        "Second training with ru-ru"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLBIha8dfRlu"
      },
      "source": [
        "with open('/content/fairseq/data/test.src', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.src', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"a\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_y']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjc4EA7eeF3"
      },
      "source": [
        "SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "DATA_DIR=\"/content/fairseq/data\"\n",
        "SRC=\"src\"\n",
        "TGT=\"dst\"\n",
        "\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$SRC > $DATA_DIR/train.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$TGT > $DATA_DIR/train.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$SRC > $DATA_DIR/dev.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$TGT > $DATA_DIR/dev.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$SRC > $DATA_DIR/test.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$TGT > $DATA_DIR/test.spm.$TGT &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ytIfDcp4Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2cec8f-e191-4915-8bf2-d6f3a949d6e8"
      },
      "source": [
        "\n",
        "PREPROCESSED_DATA_DIR=\"/content/fairseq/data\"\n",
        "DICT=\"/content/mbart.cc25.v2/dict.txt\"\n",
        "!fairseq-preprocess \\\n",
        "  --source-lang src \\\n",
        "  --target-lang dst \\\n",
        "  --trainpref /content/fairseq/data/train.spm \\\n",
        "  --validpref /content/fairseq/data/dev.spm \\\n",
        "  --testpref /content/fairseq/data/test.spm \\\n",
        "  --destdir /content/fairseq/data \\\n",
        "  --thresholdtgt 0 \\\n",
        "  --thresholdsrc 0 \\\n",
        "  --srcdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --tgtdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --workers 70"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-19 15:37:34 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/content/fairseq/data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='src', srcdict='/content/mbart.cc25.v2/dict.txt', suppress_crashes=False, target_lang='dst', task='translation', tensorboard_logdir=None, testpref='/content/fairseq/data/test.spm', tgtdict='/content/mbart.cc25.v2/dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/fairseq/data/train.spm', use_plasma_view=False, user_dir=None, validpref='/content/fairseq/data/dev.spm', wandb_project=None, workers=70)\n",
            "2021-04-19 15:37:35 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-04-19 15:38:08 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/train.spm.src: 246978 sents, 9546901 tokens, 0.0% replaced by <unk>\n",
            "2021-04-19 15:38:08 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-04-19 15:38:18 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/dev.spm.src: 768 sents, 29739 tokens, 0.0% replaced by <unk>\n",
            "2021-04-19 15:38:18 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-04-19 15:38:27 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/test.spm.src: 365 sents, 12479 tokens, 0.0% replaced by <unk>\n",
            "2021-04-19 15:38:27 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-04-19 15:38:57 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/train.spm.dst: 246978 sents, 7464137 tokens, 0.0% replaced by <unk>\n",
            "2021-04-19 15:38:57 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-04-19 15:39:06 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/dev.spm.dst: 768 sents, 23598 tokens, 0.0% replaced by <unk>\n",
            "2021-04-19 15:39:06 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-04-19 15:39:16 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/test.spm.dst: 365 sents, 11894 tokens, 0.0% replaced by <unk>\n",
            "2021-04-19 15:39:16 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/fairseq/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhVQUNdQ-po4"
      },
      "source": [
        "The code for training was the same all the times, just \"src\" and \"dst\" parts were changes. So, I do not repeated it six times, but rather altered this one, putting the necessary data in it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SORI3cBePJ1C"
      },
      "source": [
        "# mkdir to put the checkpoints\n",
        "! mkdir /content/drive/MyDrive/checkpoints_ru_ru "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mp6ZsTv_fyd"
      },
      "source": [
        "Also, it is necessary to make the following change in /content/fairseq/fairseq/tasks/translation_from_pretrained_bart.py:\n",
        "\n",
        "```\n",
        "def __init__(self, args, src_dict, tgt_dict):\n",
        "        super().__init__(args, src_dict, tgt_dict)\n",
        "        self.args = args                  # add this line !!!!!\n",
        "        self.langs = args.langs.split(\",\")\n",
        "        for d in [src_dict, tgt_dict]:\n",
        "            for l in self.langs:\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRVvpjsWALRa"
      },
      "source": [
        "The next two cells should install apex for faster training, but some error occured:("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a58XNSANLm9f",
        "outputId": "52ce95a3-8ee2-47f0-987e-153932d457fb"
      },
      "source": [
        "# %%writefile setup.sh\n",
        "\n",
        "# export CUDA_HOME=/usr/local/cuda-10.1\n",
        "# git clone https://github.com/NVIDIA/apex\n",
        "# pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10POwmcuLqvQ"
      },
      "source": [
        "# !sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq-CRreJAYBT"
      },
      "source": [
        "### Training-------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WNBS1mHCV6O"
      },
      "source": [
        "# those are just some variations in parameters that I tried\n",
        "# > train_log.txt &\n",
        "#  --update-freq 1\n",
        "#  --ddp-backend no_c10d\n",
        "# --max-tokens 1024\n",
        "# --batch-size 4 2\n",
        "# --max-epoch 25\n",
        "# --fp16 \\?????\n",
        "# --update-freq? increase????\n",
        "# --update-freq 2??? 5??\n",
        "# 3\n",
        "# --max-tokens 300\n",
        "#  --ddp-backend no_c10d \\\n",
        "# --fp16 \\\n",
        "# --memory-efficient-fp16 \\\n",
        "# --save-interval-updates 5000 \\\n",
        "# /content/mbart.cc25.v2/model.pt\n",
        "# --max-epoch 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PVUoYwjp6uA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e931bfe3-e205-42e1-dbfd-18a0044a48ee"
      },
      "source": [
        "!fairseq-train /content/fairseq/data \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --arch mbart_large --layernorm-embedding \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
        "  --optimizer adam --adam-eps 1e-06 --adam-betas '(0.9, 0.98)' \\\n",
        "  --lr-scheduler polynomial_decay --lr 3e-05 --warmup-updates 2500 --total-num-update 54725  \\\n",
        "  --dropout 0.3 --attention-dropout 0.1 --weight-decay 0.0 \\\n",
        "  --max-tokens 1024 --update-freq 5 \\\n",
        "  --source-lang src --target-lang dst \\\n",
        "  --batch-size 16 \\\n",
        "  --memory-efficient-fp16 \\\n",
        "  --validate-interval 1 \\\n",
        "  --patience 3 \\\n",
        "  --max-epoch 5 \\\n",
        "  --save-interval 1 --keep-last-epochs 10 --keep-best-checkpoints 2 \\\n",
        "  --ddp-backend no_c10d \\\n",
        "  --seed 42 --log-format simple --log-interval 500 \\\n",
        "  --restore-file /content/mbart.cc25.v2/model.pt \\\n",
        "  --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler \\\n",
        "  --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN \\\n",
        "  --scoring bleu \\\n",
        "  --save-dir /content/drive/MyDrive/checkpoints_ru_ru"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-19 19:16:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1024, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [5], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints_ru_ru', 'restore_file': '/content/mbart.cc25.v2/model.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 10, 'keep_best_checkpoints': 2, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='mbart_large', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/mbart.cc25.v2/model.pt', save_dir='/content/drive/MyDrive/checkpoints_ru_ru', save_interval=1, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='src', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='dst', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': Namespace(_name='translation_from_pretrained_bart', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/mbart.cc25.v2/model.pt', save_dir='/content/drive/MyDrive/checkpoints_ru_ru', save_interval=1, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='src', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='dst', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 2500, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 54725.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}\n",
            "2021-04-19 19:16:24 | INFO | fairseq.tasks.translation | [src] dictionary: 250001 types\n",
            "2021-04-19 19:16:24 | INFO | fairseq.tasks.translation | [dst] dictionary: 250001 types\n",
            "2021-04-19 19:16:47 | INFO | fairseq_cli.train | BARTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=1024, out_features=250027, bias=False)\n",
            "  )\n",
            "  (classification_heads): ModuleDict()\n",
            ")\n",
            "2021-04-19 19:16:47 | INFO | fairseq_cli.train | task: TranslationFromPretrainedBARTTask\n",
            "2021-04-19 19:16:47 | INFO | fairseq_cli.train | model: BARTModel\n",
            "2021-04-19 19:16:47 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-04-19 19:16:47 | INFO | fairseq_cli.train | num. shared model params: 610,851,840 (num. trained: 610,851,840)\n",
            "2021-04-19 19:16:47 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-04-19 19:16:47 | INFO | fairseq.data.data_utils | loaded 768 examples from: /content/fairseq/data/valid.src-dst.src\n",
            "2021-04-19 19:16:47 | INFO | fairseq.data.data_utils | loaded 768 examples from: /content/fairseq/data/valid.src-dst.dst\n",
            "2021-04-19 19:16:47 | INFO | fairseq.tasks.translation | /content/fairseq/data valid src-dst 768 examples\n",
            "2021-04-19 19:17:00 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2021-04-19 19:17:00 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2021-04-19 19:17:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-04-19 19:17:00 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    \n",
            "2021-04-19 19:17:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-04-19 19:17:00 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-04-19 19:17:00 | INFO | fairseq_cli.train | max tokens per device = 1024 and max sentences per device = 16\n",
            "2021-04-19 19:17:00 | INFO | fairseq.trainer | Preparing to load checkpoint /content/mbart.cc25.v2/model.pt\n",
            "tcmalloc: large alloc 2443411456 bytes == 0x55a2d5f6e000 @  0x7f352936bb6b 0x7f352938b379 0x7f34b6cb325e 0x7f34b6cb49d2 0x7f34f4cdde7d 0x7f35058d8120 0x7f3505516bd9 0x55a1f5796c38 0x55a1f580a63d 0x55a1f5804e0d 0x55a1f579777a 0x55a1f5805a45 0x55a1f5804e0d 0x55a1f579738b 0x55a1f5796e99 0x55a1f58de70d 0x55a1f584d57b 0x55a1f5795f41 0x55a1f588799d 0x55a1f5809fe9 0x55a1f5804e0d 0x55a1f56d6e2b 0x55a1f58071e6 0x55a1f5804b0e 0x55a1f579777a 0x55a1f580686a 0x55a1f5804b0e 0x55a1f579777a 0x55a1f580686a 0x55a1f5804b0e 0x55a1f579777a\n",
            "tcmalloc: large alloc 2443411456 bytes == 0x55a368258000 @  0x7f352936bb6b 0x7f352938b379 0x7f34b6cb325e 0x7f34b6cb49d2 0x7f34f4cdde7d 0x7f35058d8120 0x7f3505516bd9 0x55a1f5796c38 0x55a1f580a63d 0x55a1f5804e0d 0x55a1f579777a 0x55a1f5805a45 0x55a1f5804e0d 0x55a1f579738b 0x55a1f5796e99 0x55a1f58de70d 0x55a1f584d57b 0x55a1f5795f41 0x55a1f588799d 0x55a1f5809fe9 0x55a1f5804e0d 0x55a1f56d6e2b 0x55a1f58071e6 0x55a1f5804b0e 0x55a1f579777a 0x55a1f580686a 0x55a1f5804b0e 0x55a1f579777a 0x55a1f580686a 0x55a1f5804b0e 0x55a1f579777a\n",
            "2021-04-19 19:18:26 | INFO | fairseq.trainer | Loaded checkpoint /content/mbart.cc25.v2/model.pt (epoch 142 @ 0 updates)\n",
            "2021-04-19 19:18:26 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-04-19 19:18:27 | INFO | fairseq.data.data_utils | loaded 246,978 examples from: /content/fairseq/data/train.src-dst.src\n",
            "2021-04-19 19:18:27 | INFO | fairseq.data.data_utils | loaded 246,978 examples from: /content/fairseq/data/train.src-dst.dst\n",
            "2021-04-19 19:18:27 | INFO | fairseq.tasks.translation | /content/fairseq/data train src-dst 246978 examples\n",
            "2021-04-19 19:18:28 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-04-19 19:18:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/fairseq/fairseq/utils.py:364: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "2021-04-19 19:18:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "2021-04-19 19:18:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "2021-04-19 19:18:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "2021-04-19 19:18:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "2021-04-19 19:18:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "2021-04-19 19:18:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0\n",
            "2021-04-19 19:18:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0\n",
            "2021-04-19 19:18:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5\n",
            "2021-04-19 19:18:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25\n",
            "2021-04-19 19:19:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125\n",
            "2021-04-19 19:19:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625\n",
            "2021-04-19 19:25:17 | INFO | train_inner | epoch 001:    511 / 3460 loss=29.544, nll_loss=16.575, ppl=97652.6, wps=2784.5, ups=1.25, wpb=2219.7, bsz=71.4, num_updates=500, lr=6e-06, gnorm=185.564, loss_scale=0.0625, train_wall=407, gb_free=6.1, wall=498\n",
            "2021-04-19 19:31:58 | INFO | train_inner | epoch 001:   1011 / 3460 loss=12.391, nll_loss=9.084, ppl=542.73, wps=2799.9, ups=1.25, wpb=2241.8, bsz=71.3, num_updates=1000, lr=1.2e-05, gnorm=8.048, loss_scale=0.0625, train_wall=398, gb_free=5.3, wall=898\n",
            "2021-04-19 19:38:36 | INFO | train_inner | epoch 001:   1511 / 3460 loss=8.308, nll_loss=4.56, ppl=23.59, wps=2775.6, ups=1.25, wpb=2211.7, bsz=71.7, num_updates=1500, lr=1.8e-05, gnorm=4.689, loss_scale=0.0625, train_wall=396, gb_free=5.8, wall=1296\n",
            "2021-04-19 19:45:16 | INFO | train_inner | epoch 001:   2011 / 3460 loss=7.463, nll_loss=3.748, ppl=13.44, wps=2801.3, ups=1.25, wpb=2238.4, bsz=71, num_updates=2000, lr=2.4e-05, gnorm=3.049, loss_scale=0.0625, train_wall=397, gb_free=5.3, wall=1696\n",
            "2021-04-19 19:51:53 | INFO | train_inner | epoch 001:   2511 / 3460 loss=7.116, nll_loss=3.39, ppl=10.49, wps=2811.2, ups=1.26, wpb=2233.8, bsz=71, num_updates=2500, lr=3e-05, gnorm=3.25, loss_scale=0.0625, train_wall=395, gb_free=5.6, wall=2093\n",
            "2021-04-19 19:58:27 | INFO | train_inner | epoch 001:   3011 / 3460 loss=7.035, nll_loss=3.295, ppl=9.81, wps=2815, ups=1.27, wpb=2217.9, bsz=71.6, num_updates=3000, lr=2.97128e-05, gnorm=2.961, loss_scale=0.0625, train_wall=392, gb_free=5.2, wall=2487\n",
            "2021-04-19 20:04:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-19 20:04:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.454 | nll_loss 2.422 | ppl 5.36 | wps 6089.5 | wpb 399.4 | bsz 12.6 | num_updates 3449\n",
            "2021-04-19 20:04:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 3449 updates\n",
            "2021-04-19 20:04:27 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint1.pt\n",
            "2021-04-19 20:06:17 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint1.pt\n",
            "2021-04-19 20:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_ru_ru/checkpoint1.pt (epoch 1 @ 3449 updates, score 6.454) (writing took 734.2482230640016 seconds)\n",
            "2021-04-19 20:16:42 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-04-19 20:16:42 | INFO | train | epoch 001 | loss 11.308 | nll_loss 6.302 | ppl 78.92 | wps 2205.8 | ups 0.99 | wpb 2227.8 | bsz 71.4 | num_updates 3449 | lr 2.94549e-05 | gnorm 30.432 | loss_scale 0.125 | train_wall 2740 | gb_free 6.1 | wall 3582\n",
            "2021-04-19 20:16:43 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-04-19 20:16:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-19 20:17:30 | INFO | train_inner | epoch 002:     51 / 3460 loss=6.9, nll_loss=3.155, ppl=8.91, wps=977.7, ups=0.44, wpb=2234.5, bsz=71.6, num_updates=3500, lr=2.94256e-05, gnorm=2.608, loss_scale=0.125, train_wall=399, gb_free=6.1, wall=3630\n",
            "2021-04-19 20:24:18 | INFO | train_inner | epoch 002:    551 / 3460 loss=6.73, nll_loss=3.008, ppl=8.04, wps=2726.7, ups=1.22, wpb=2228.5, bsz=71.4, num_updates=4000, lr=2.91383e-05, gnorm=2.252, loss_scale=0.125, train_wall=406, gb_free=6.1, wall=4039\n",
            "2021-04-19 20:30:59 | INFO | train_inner | epoch 002:   1051 / 3460 loss=6.625, nll_loss=2.901, ppl=7.47, wps=2811, ups=1.25, wpb=2253, bsz=71.3, num_updates=4500, lr=2.88511e-05, gnorm=2.686, loss_scale=0.125, train_wall=399, gb_free=4.5, wall=4439\n",
            "2021-04-19 20:37:38 | INFO | train_inner | epoch 002:   1551 / 3460 loss=6.562, nll_loss=2.839, ppl=7.15, wps=2788.9, ups=1.25, wpb=2225.6, bsz=71.6, num_updates=5000, lr=2.85639e-05, gnorm=3.35, loss_scale=0.125, train_wall=397, gb_free=4.7, wall=4838\n",
            "2021-04-19 20:44:15 | INFO | train_inner | epoch 002:   2051 / 3460 loss=6.465, nll_loss=2.732, ppl=6.64, wps=2827.1, ups=1.26, wpb=2245.5, bsz=71.7, num_updates=5500, lr=2.82767e-05, gnorm=1.844, loss_scale=0.125, train_wall=395, gb_free=5.6, wall=5235\n",
            "2021-04-19 20:50:51 | INFO | train_inner | epoch 002:   2551 / 3460 loss=6.455, nll_loss=2.731, ppl=6.64, wps=2817.4, ups=1.26, wpb=2233, bsz=71.6, num_updates=6000, lr=2.79895e-05, gnorm=1.782, loss_scale=0.125, train_wall=394, gb_free=5.5, wall=5632\n",
            "2021-04-19 20:57:24 | INFO | train_inner | epoch 002:   3051 / 3460 loss=6.43, nll_loss=2.707, ppl=6.53, wps=2795.7, ups=1.27, wpb=2193.2, bsz=71, num_updates=6500, lr=2.77022e-05, gnorm=1.77, loss_scale=0.125, train_wall=390, gb_free=4.8, wall=6024\n",
            "2021-04-19 21:02:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-19 21:02:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.193 | nll_loss 2.209 | ppl 4.63 | wps 6143 | wpb 399.4 | bsz 12.6 | num_updates 6909 | best_loss 6.193\n",
            "2021-04-19 21:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 6909 updates\n",
            "2021-04-19 21:02:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint2.pt\n",
            "2021-04-19 21:04:39 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint2.pt\n",
            "2021-04-19 21:14:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_ru_ru/checkpoint2.pt (epoch 2 @ 6909 updates, score 6.193) (writing took 714.7246688680025 seconds)\n",
            "2021-04-19 21:14:43 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-04-19 21:14:43 | INFO | train | epoch 002 | loss 6.532 | nll_loss 2.807 | ppl 7 | wps 2215 | ups 0.99 | wpb 2228.6 | bsz 71.4 | num_updates 6909 | lr 2.74673e-05 | gnorm 2.214 | loss_scale 0.25 | train_wall 2745 | gb_free 4.3 | wall 7064\n",
            "2021-04-19 21:14:44 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-04-19 21:14:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-19 21:16:02 | INFO | train_inner | epoch 003:     91 / 3460 loss=6.391, nll_loss=2.663, ppl=6.33, wps=991.2, ups=0.45, wpb=2217.5, bsz=71.3, num_updates=7000, lr=2.7415e-05, gnorm=1.689, loss_scale=0.25, train_wall=396, gb_free=5.6, wall=7143\n",
            "2021-04-19 21:22:47 | INFO | train_inner | epoch 003:    591 / 3460 loss=6.36, nll_loss=2.628, ppl=6.18, wps=2759.2, ups=1.23, wpb=2235.4, bsz=71.5, num_updates=7500, lr=2.71278e-05, gnorm=1.647, loss_scale=0.25, train_wall=403, gb_free=5.6, wall=7548\n",
            "2021-04-19 21:29:26 | INFO | train_inner | epoch 003:   1091 / 3460 loss=6.349, nll_loss=2.619, ppl=6.14, wps=2798.6, ups=1.25, wpb=2231.3, bsz=71.2, num_updates=8000, lr=2.68406e-05, gnorm=1.632, loss_scale=0.25, train_wall=396, gb_free=5.1, wall=7946\n",
            "2021-04-19 21:36:01 | INFO | train_inner | epoch 003:   1591 / 3460 loss=6.324, nll_loss=2.593, ppl=6.03, wps=2796.7, ups=1.27, wpb=2208.4, bsz=71.2, num_updates=8500, lr=2.65534e-05, gnorm=1.607, loss_scale=0.25, train_wall=393, gb_free=5.9, wall=8341\n",
            "2021-04-19 21:42:43 | INFO | train_inner | epoch 003:   2091 / 3460 loss=6.325, nll_loss=2.598, ppl=6.05, wps=2805, ups=1.24, wpb=2255.3, bsz=71.3, num_updates=9000, lr=2.62662e-05, gnorm=1.595, loss_scale=0.25, train_wall=400, gb_free=6.1, wall=8743\n",
            "2021-04-19 21:49:21 | INFO | train_inner | epoch 003:   2591 / 3460 loss=6.284, nll_loss=2.55, ppl=5.86, wps=2800, ups=1.26, wpb=2228.4, bsz=71.6, num_updates=9500, lr=2.59789e-05, gnorm=1.579, loss_scale=0.25, train_wall=396, gb_free=5.7, wall=9141\n",
            "2021-04-19 21:55:56 | INFO | train_inner | epoch 003:   3091 / 3460 loss=6.255, nll_loss=2.518, ppl=5.73, wps=2818.6, ups=1.27, wpb=2226.2, bsz=71.7, num_updates=10000, lr=2.56917e-05, gnorm=1.53, loss_scale=0.5, train_wall=393, gb_free=4.3, wall=9536\n",
            "2021-04-19 22:00:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-19 22:00:52 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.144 | nll_loss 2.144 | ppl 4.42 | wps 6023.5 | wpb 399.4 | bsz 12.6 | num_updates 10369 | best_loss 6.144\n",
            "2021-04-19 22:00:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 10369 updates\n",
            "2021-04-19 22:00:52 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint3.pt\n",
            "2021-04-19 22:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint3.pt\n",
            "2021-04-19 22:12:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_ru_ru/checkpoint3.pt (epoch 3 @ 10369 updates, score 6.144) (writing took 691.3316111499953 seconds)\n",
            "2021-04-19 22:12:23 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-04-19 22:12:23 | INFO | train | epoch 003 | loss 6.309 | nll_loss 2.576 | ppl 5.96 | wps 2228.7 | ups 1 | wpb 2228.6 | bsz 71.4 | num_updates 10369 | lr 2.54798e-05 | gnorm 1.595 | loss_scale 0.5 | train_wall 2748 | gb_free 6.1 | wall 10524\n",
            "2021-04-19 22:12:24 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2021-04-19 22:12:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-19 22:14:15 | INFO | train_inner | epoch 004:    131 / 3460 loss=6.243, nll_loss=2.506, ppl=5.68, wps=1006.6, ups=0.45, wpb=2213.8, bsz=71.3, num_updates=10500, lr=2.54045e-05, gnorm=1.533, loss_scale=0.5, train_wall=401, gb_free=5, wall=10636\n",
            "2021-04-19 22:20:59 | INFO | train_inner | epoch 004:    631 / 3460 loss=6.234, nll_loss=2.495, ppl=5.64, wps=2779.2, ups=1.24, wpb=2246.1, bsz=71.3, num_updates=11000, lr=2.51173e-05, gnorm=1.506, loss_scale=0.5, train_wall=402, gb_free=6.1, wall=11040\n",
            "2021-04-19 22:27:34 | INFO | train_inner | epoch 004:   1131 / 3460 loss=6.219, nll_loss=2.479, ppl=5.57, wps=2786.8, ups=1.27, wpb=2201.4, bsz=71.8, num_updates=11500, lr=2.48301e-05, gnorm=1.521, loss_scale=0.5, train_wall=393, gb_free=4.3, wall=11435\n",
            "2021-04-19 22:34:14 | INFO | train_inner | epoch 004:   1631 / 3460 loss=6.218, nll_loss=2.48, ppl=5.58, wps=2766.6, ups=1.25, wpb=2209.2, bsz=71.1, num_updates=12000, lr=2.45428e-05, gnorm=1.487, loss_scale=0.5, train_wall=397, gb_free=6.1, wall=11834\n",
            "2021-04-19 22:40:55 | INFO | train_inner | epoch 004:   2131 / 3460 loss=6.21, nll_loss=2.472, ppl=5.55, wps=2761.4, ups=1.25, wpb=2217, bsz=71.3, num_updates=12500, lr=2.42556e-05, gnorm=1.478, loss_scale=0.5, train_wall=399, gb_free=5.6, wall=12235\n",
            "2021-04-19 22:47:37 | INFO | train_inner | epoch 004:   2631 / 3460 loss=6.203, nll_loss=2.466, ppl=5.53, wps=2820.5, ups=1.24, wpb=2268, bsz=71.5, num_updates=13000, lr=2.39684e-05, gnorm=1.459, loss_scale=0.5, train_wall=400, gb_free=5.1, wall=12637\n",
            "2021-04-19 22:54:14 | INFO | train_inner | epoch 004:   3131 / 3460 loss=6.19, nll_loss=2.452, ppl=5.47, wps=2801.3, ups=1.26, wpb=2225.6, bsz=71.1, num_updates=13500, lr=2.36812e-05, gnorm=1.466, loss_scale=1, train_wall=395, gb_free=6.1, wall=13035\n",
            "2021-04-19 22:58:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-19 22:58:41 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.081 | nll_loss 2.081 | ppl 4.23 | wps 6027.1 | wpb 399.4 | bsz 12.6 | num_updates 13829 | best_loss 6.081\n",
            "2021-04-19 22:58:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 13829 updates\n",
            "2021-04-19 22:58:41 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint4.pt\n",
            "2021-04-19 23:00:32 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint4.pt\n",
            "2021-04-19 23:11:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_ru_ru/checkpoint4.pt (epoch 4 @ 13829 updates, score 6.081) (writing took 766.0586875859954 seconds)\n",
            "2021-04-19 23:11:27 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2021-04-19 23:11:27 | INFO | train | epoch 004 | loss 6.211 | nll_loss 2.473 | ppl 5.55 | wps 2175.8 | ups 0.98 | wpb 2228.6 | bsz 71.4 | num_updates 13829 | lr 2.34922e-05 | gnorm 1.483 | loss_scale 1 | train_wall 2757 | gb_free 5.2 | wall 14068\n",
            "2021-04-19 23:11:28 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2021-04-19 23:11:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-19 23:13:51 | INFO | train_inner | epoch 005:    171 / 3460 loss=6.189, nll_loss=2.451, ppl=5.47, wps=954.8, ups=0.42, wpb=2247.3, bsz=71.1, num_updates=14000, lr=2.3394e-05, gnorm=1.458, loss_scale=1, train_wall=403, gb_free=5.4, wall=14212\n",
            "2021-04-19 23:20:42 | INFO | train_inner | epoch 005:    671 / 3460 loss=6.147, nll_loss=2.399, ppl=5.27, wps=2714.3, ups=1.22, wpb=2230.1, bsz=71.9, num_updates=14500, lr=2.31067e-05, gnorm=1.425, loss_scale=1, train_wall=408, gb_free=5.8, wall=14622\n",
            "2021-04-19 23:27:25 | INFO | train_inner | epoch 005:   1171 / 3460 loss=6.17, nll_loss=2.428, ppl=5.38, wps=2795.3, ups=1.24, wpb=2250, bsz=71.6, num_updates=15000, lr=2.28195e-05, gnorm=1.454, loss_scale=1, train_wall=400, gb_free=6.1, wall=15025\n",
            "2021-04-19 23:34:02 | INFO | train_inner | epoch 005:   1671 / 3460 loss=6.164, nll_loss=2.423, ppl=5.36, wps=2769.9, ups=1.26, wpb=2204.1, bsz=71.4, num_updates=15500, lr=2.25323e-05, gnorm=1.449, loss_scale=1, train_wall=396, gb_free=5.6, wall=15423\n",
            "2021-04-19 23:40:41 | INFO | train_inner | epoch 005:   2171 / 3460 loss=6.148, nll_loss=2.405, ppl=5.3, wps=2797.2, ups=1.25, wpb=2230.4, bsz=71.7, num_updates=16000, lr=2.22451e-05, gnorm=1.421, loss_scale=1, train_wall=396, gb_free=5.2, wall=15821\n",
            "2021-04-19 23:47:21 | INFO | train_inner | epoch 005:   2671 / 3460 loss=6.156, nll_loss=2.416, ppl=5.34, wps=2805.1, ups=1.25, wpb=2246, bsz=71, num_updates=16500, lr=2.19579e-05, gnorm=1.439, loss_scale=2, train_wall=398, gb_free=5.8, wall=16222\n",
            "2021-04-19 23:54:03 | INFO | train_inner | epoch 005:   3171 / 3460 loss=6.134, nll_loss=2.389, ppl=5.24, wps=2755.3, ups=1.25, wpb=2212.8, bsz=71.1, num_updates=17000, lr=2.16707e-05, gnorm=1.425, loss_scale=2, train_wall=399, gb_free=6.1, wall=16623\n",
            "2021-04-19 23:57:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-19 23:57:59 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.058 | nll_loss 2.065 | ppl 4.18 | wps 5960.4 | wpb 399.4 | bsz 12.6 | num_updates 17289 | best_loss 6.058\n",
            "2021-04-19 23:57:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 17289 updates\n",
            "2021-04-19 23:57:59 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint5.pt\n",
            "2021-04-19 23:59:51 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_ru_ru/checkpoint5.pt\n",
            "2021-04-20 00:09:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_ru_ru/checkpoint5.pt (epoch 5 @ 17289 updates, score 6.058) (writing took 695.9921837199945 seconds)\n",
            "2021-04-20 00:09:35 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2021-04-20 00:09:35 | INFO | train | epoch 005 | loss 6.15 | nll_loss 2.406 | ppl 5.3 | wps 2211.1 | ups 0.99 | wpb 2228.6 | bsz 71.4 | num_updates 17289 | lr 2.15046e-05 | gnorm 1.434 | loss_scale 2 | train_wall 2770 | gb_free 6.1 | wall 17555\n",
            "2021-04-20 00:09:35 | INFO | fairseq_cli.train | done training in 17467.3 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LGGmjSE_JLO"
      },
      "source": [
        "### Test to check that everything is ok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpbpDtlCCY5j"
      },
      "source": [
        "! pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-_s-v3np7l_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77353e11-f944-4d1b-af00-bc3120eeac81"
      },
      "source": [
        "!fairseq-generate /content/fairseq/data \\\n",
        "  --path  /content/drive/MyDrive/checkpoints_ru_ru/checkpoint_best.pt \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --gen-subset test \\\n",
        "  --source-lang src --target-lang dst \\\n",
        "  --bpe 'sentencepiece' --sentencepiece-model /content/mbart.cc25.v2/sentence.bpe.model \\\n",
        "  --sacrebleu --remove-bpe 'sentencepiece' \\\n",
        "  --batch-size 32 --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN > model_prediction.txt & \n",
        "!cat model_prediction.txt | grep -P \"^H\" |sort -V |cut -f 3- > model_prediction.hyp\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHpj3g6J_QHP"
      },
      "source": [
        "# !fairseq-generate /content/fairseq/data \\\n",
        "#   --path /content/drive/MyDrive/checkpoint5.pt \\\n",
        "#   --task translation_from_pretrained_bart \\\n",
        "#   --gen-subset test \\\n",
        "#   --source-lang en --target-lang ru \\\n",
        "#   --bpe 'sentencepiece' --sentencepiece-model /content/mbart.cc25.v2/sentence.bpe.model \\\n",
        "#   --sacrebleu --remove-bpe 'sentencepiece' \\\n",
        "#   --batch-size 4 --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN > model_prediction.txt & \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z33ymqaXA9Ci"
      },
      "source": [
        "### try SARI evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imXXZKIKqXjK",
        "outputId": "cbb8dfa0-e099-4e2b-d438-d4ed8ab359a3"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxVrDxwiqXpG"
      },
      "source": [
        "! git clone https://github.com/feralvam/easse\n",
        "! git clone https://github.com/Andoree/sent_simplification.git\n",
        "%cp /content/sent_simplification/sari.py /content/easse/easse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeW4Ord1qXsa"
      },
      "source": [
        "%cd easse\n",
        "! pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHw-4D8SrYLW",
        "outputId": "7d93492a-d0cf-43d5-cf55-f29d517e43d2"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/easse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FINU32l7rajY"
      },
      "source": [
        "%cd /content\n",
        "! mkdir prepared_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch6UCNu4BF3_"
      },
      "source": [
        "Prepare data for SARI calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmTp6oQOuWTi"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/dialogue-evaluation/RuSimpleSentEval/main/dev_sents.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSqVqCnCrQJL",
        "outputId": "7521f520-3f7b-4bfb-8317-e080035a16b9"
      },
      "source": [
        "! python /content/sent_simplification/refs_to_easse_format.py \\\n",
        "--input_path /content/dev_sents.csv \\\n",
        "--output_dataset_name test_ref_data \\\n",
        "--src_column \"INPUT:source\" \\\n",
        "--trg_column \"OUTPUT:output\" \\\n",
        "--output_dir /content/prepared_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "3406\n",
            "3406\n",
            "Overall number of references: 3406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slkZYEDv-h5U"
      },
      "source": [
        "data_test = pd.read_csv('/content/dev_sents.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flV0g9enwZct",
        "outputId": "e27b2958-2131-44c7-91df-2ef910e25c33"
      },
      "source": [
        "data_test['OUTPUT:output'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3406,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "Vgmj2HgE5CWQ",
        "outputId": "dd286613-e24d-4314-ff35-06d856d71ea6"
      },
      "source": [
        "data_test.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>INPUT:source</th>\n",
              "      <th>OUTPUT:output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3401</th>\n",
              "      <td>9960</td>\n",
              "      <td>  (  Yuzdami zev...</td>\n",
              "      <td>  -   ,   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3402</th>\n",
              "      <td>9961</td>\n",
              "      <td>  (  Yuzdami zev...</td>\n",
              "      <td>       ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3403</th>\n",
              "      <td>9975</td>\n",
              "      <td>     ...</td>\n",
              "      <td>     ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3404</th>\n",
              "      <td>9976</td>\n",
              "      <td>     ...</td>\n",
              "      <td>  -  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3405</th>\n",
              "      <td>9977</td>\n",
              "      <td>     ...</td>\n",
              "      <td>,    , ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                      OUTPUT:output\n",
              "3401        9960  ...    -   ,   ...\n",
              "3402        9961  ...         ...\n",
              "3403        9975  ...       ...\n",
              "3404        9976  ...    -  ...\n",
              "3405        9977  ...  ,    , ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trRBHz730_U8",
        "outputId": "5b36b6dc-c0fd-4be8-f88d-4d15ccbb4490"
      },
      "source": [
        "list1, list2 = [], []\n",
        "\n",
        "with open('/content/fairseq/data/test.src', \"r\") as f:\n",
        "    for i in f:\n",
        "      list1.append(i)\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"r\") as f:\n",
        "    for i in f:\n",
        "      list2.append(i)\n",
        "\n",
        "\n",
        "len(list1), len(list2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3406, 3406)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu_eOTpB4BEV"
      },
      "source": [
        "data_test  = pd.read_csv('/content/dev_sents.csv')\n",
        "! rm -r /content/fairseq/data\n",
        "! mkdir /content/fairseq/data\n",
        "\n",
        "# file1 = open('/content/fairseq/data/test.src', \"w\")\n",
        "# file2 = open('/content/fairseq/data/test.dst', \"w\")\n",
        "\n",
        "# for i, row in data_test.iterrows():\n",
        "#     file1.write(row['INPUT:source'] + '\\n')\n",
        "#     file2.write(row['OUTPUT:output'] + '\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.src', \"w\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(row['INPUT:source']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.dst', \"w\") as f:\n",
        "  for i, row in data_test.iterrows():\n",
        "    f.write(re.sub(r'(\\s){1,5}', \"\",row['OUTPUT:output'])+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VMo4VBdwSlH"
      },
      "source": [
        "data_test  = pd.read_csv('/content/dev_sents.csv')\n",
        "# ! rm -r /content/fairseq/data\n",
        "# ! mkdir /content/fairseq/data\n",
        "\n",
        "# with open('/content/fairseq/data/test.src', \"w\") as f:\n",
        "#   for i, row in data_test.iterrows():\n",
        "#     f.write(row['INPUT:source']+'\\n')\n",
        "\n",
        "# with open('/content/fairseq/data/test.dst', \"w\") as f:\n",
        "#   for i, row in data_test.iterrows():\n",
        "#     f.write(row['OUTPUT:output']+'\\n')\n",
        "    \n",
        "with open('/content/fairseq/data/train.src', \"w\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.src', \"w\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_x']+'\\n')\n",
        "\n",
        "\n",
        "with open('/content/fairseq/data/train.dst', \"w\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['target_y']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.dst', \"w\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['target_y']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X22OjAnwxe7"
      },
      "source": [
        "SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "DATA_DIR=\"/content/fairseq/data\"\n",
        "SRC=\"src\"\n",
        "TGT=\"dst\"\n",
        "\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$SRC > $DATA_DIR/train.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$TGT > $DATA_DIR/train.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$SRC > $DATA_DIR/dev.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$TGT > $DATA_DIR/dev.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$SRC > $DATA_DIR/test.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$TGT > $DATA_DIR/test.spm.$TGT &\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zZVGK4dw08l",
        "outputId": "d053984d-52da-4783-c157-24ee1b7b3baa"
      },
      "source": [
        "PREPROCESSED_DATA_DIR=\"/content/fairseq/data\"\n",
        "DICT=\"/content/mbart.cc25.v2/dict.txt\"\n",
        "!fairseq-preprocess \\\n",
        "  --source-lang src \\\n",
        "  --target-lang dst \\\n",
        "  --trainpref /content/fairseq/data/train.spm \\\n",
        "  --validpref /content/fairseq/data/dev.spm \\\n",
        "  --testpref /content/fairseq/data/test.spm \\\n",
        "  --destdir /content/fairseq/data \\\n",
        "  --thresholdtgt 0 \\\n",
        "  --thresholdsrc 0 \\\n",
        "  --srcdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --tgtdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --workers 70\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-20 02:08:50 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/content/fairseq/data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='src', srcdict='/content/mbart.cc25.v2/dict.txt', suppress_crashes=False, target_lang='dst', task='translation', tensorboard_logdir=None, testpref='/content/fairseq/data/test.spm', tgtdict='/content/mbart.cc25.v2/dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/fairseq/data/train.spm', use_plasma_view=False, user_dir=None, validpref='/content/fairseq/data/dev.spm', wandb_project=None, workers=70)\n",
            "2021-04-20 02:08:51 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-04-20 02:09:24 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/train.spm.src: 246978 sents, 9546901 tokens, 0.0% replaced by <unk>\n",
            "2021-04-20 02:09:24 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-04-20 02:09:33 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/dev.spm.src: 768 sents, 29739 tokens, 0.0% replaced by <unk>\n",
            "2021-04-20 02:09:33 | INFO | fairseq_cli.preprocess | [src] Dictionary: 250001 types\n",
            "2021-04-20 02:09:43 | INFO | fairseq_cli.preprocess | [src] /content/fairseq/data/test.spm.src: 3406 sents, 118537 tokens, 0.0% replaced by <unk>\n",
            "2021-04-20 02:09:43 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-04-20 02:10:13 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/train.spm.dst: 246978 sents, 7464137 tokens, 0.0% replaced by <unk>\n",
            "2021-04-20 02:10:13 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-04-20 02:10:22 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/dev.spm.dst: 768 sents, 23598 tokens, 0.0% replaced by <unk>\n",
            "2021-04-20 02:10:22 | INFO | fairseq_cli.preprocess | [dst] Dictionary: 250001 types\n",
            "2021-04-20 02:10:32 | INFO | fairseq_cli.preprocess | [dst] /content/fairseq/data/test.spm.dst: 3406 sents, 101378 tokens, 0.0% replaced by <unk>\n",
            "2021-04-20 02:10:32 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/fairseq/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMaGo5MGrlaG",
        "outputId": "c5ef7048-eafd-4685-ef88-8b39e2a81670"
      },
      "source": [
        "! easse evaluate \\\n",
        "--test_set custom \\\n",
        "--metrics sari \\\n",
        "--refs_sents_paths /content/prepared_data/test_ref_data.ref.0,/content/prepared_data/test_ref_data.ref.1,/content/prepared_data/test_ref_data.ref.2,/content/prepared_data/test_ref_data.ref.3,/content/prepared_data/test_ref_data.ref.4 \\\n",
        "--orig_sents_path /content/prepared_data/test_ref_data.src \\\n",
        "--sys_sents_path /content/fairseq/model_prediction.hyp -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "{'sari': 32.236, 'quality_estimation': {'Compression ratio': 0.903, 'Sentence splits': 1.051, 'Levenshtein similarity': 0.35, 'Exact copies': 0.0, 'Additions proportion': 0.695, 'Deletions proportion': 0.792, 'Lexical complexity score': 9.639}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}