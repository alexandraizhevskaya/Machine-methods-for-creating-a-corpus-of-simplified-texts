{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Translation_and_fine_tuning_mt.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Tzwt_lzjgjEn",
        "ywHlfmswgjEp",
        "oddwKgW-Zd41",
        "5GVZpRQuavRZ",
        "wuT7czBvd9Av",
        "Fp9mKt-Barfy",
        "m8wuOvwG54D-",
        "sjqSEykGX2ok"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b14e024889564d65a1ff29c57f70f9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a46d65568204ad7baaa193ed7a47914",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e36bb1f90907483eaf7a8ee3836b9a82",
              "IPY_MODEL_7405ecbc3a4d47f08de8bc8aab453b40"
            ]
          }
        },
        "3a46d65568204ad7baaa193ed7a47914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e36bb1f90907483eaf7a8ee3836b9a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27f497fb8a7d42958b9b12c8c5dccd00",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef20d2aa105d4539a34b73ac42c04107"
          }
        },
        "7405ecbc3a4d47f08de8bc8aab453b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cd04eed7550246f5950e35cad38045d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 94/? [05:37&lt;00:00,  3.60s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8db1c11f54548f0b69eb9eb85f5a08c"
          }
        },
        "27f497fb8a7d42958b9b12c8c5dccd00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef20d2aa105d4539a34b73ac42c04107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd04eed7550246f5950e35cad38045d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8db1c11f54548f0b69eb9eb85f5a08c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9fc1a4bdb0145a08980bb06f7a22ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c73c3601aab14dbf89b4a0af9486dfc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33c8242881d244b7a844530a87be0de1",
              "IPY_MODEL_d8ba8eebe19f492dbf6435ab3c2ac20e"
            ]
          }
        },
        "c73c3601aab14dbf89b4a0af9486dfc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33c8242881d244b7a844530a87be0de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d18b284dc49d4ca9b04d920d068c3e5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbd1dd46b6cb4fc9bd9417861df39b0a"
          }
        },
        "d8ba8eebe19f492dbf6435ab3c2ac20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_afd6cbad432d4df18bb5d0f4452ea845",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 94/? [04:48&lt;00:00,  3.07s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1976bad45d14421b1d766ad38756fe0"
          }
        },
        "d18b284dc49d4ca9b04d920d068c3e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbd1dd46b6cb4fc9bd9417861df39b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afd6cbad432d4df18bb5d0f4452ea845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1976bad45d14421b1d766ad38756fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc4340ebf74f401ea4334bd6e4bea1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e1fc0707fd243a29eb44e47b1523034",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_68b9ef5cdd014d3a957507a6419f275e",
              "IPY_MODEL_670a15fbc6f7469fad77f28c1040e443"
            ]
          }
        },
        "9e1fc0707fd243a29eb44e47b1523034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68b9ef5cdd014d3a957507a6419f275e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14f0f95d247f42a88f64c2951209c870",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1754318854,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1754318854,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_573846234d9545c1b2e0a34c0d905172"
          }
        },
        "670a15fbc6f7469fad77f28c1040e443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c164779ad014966b7822fd670ab4e44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.75G/1.75G [01:17&lt;00:00, 22.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_335a599b6d0e4106829fab272b9ce931"
          }
        },
        "14f0f95d247f42a88f64c2951209c870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "573846234d9545c1b2e0a34c0d905172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c164779ad014966b7822fd670ab4e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "335a599b6d0e4106829fab272b9ce931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmjwvjsanxgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42e1f1d-142c-433a-ed42-5995fe3475e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GpSq_usCcoW"
      },
      "source": [
        "Here I will finetune MT models and then evaluate quality of translation with BLEU and METEOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ihEp_Yv3Im8"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2m_-8lIkEpD"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s1A1UtJk9-B"
      },
      "source": [
        "!git clone https://github.com/google/sentencepiece.git \n",
        "%cd sentencepiece\n",
        "!mkdir build"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sWUXkgLlCN2"
      },
      "source": [
        "%cd build\n",
        "!cmake ..\n",
        "!make\n",
        "!make install\n",
        "!ldconfig -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsQ_uF1pgjEq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from tqdm import tqdm_notebook\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeNXxZWYDRQa"
      },
      "source": [
        "# Loading and splitting data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8IiarwxhNs2"
      },
      "source": [
        "# ! gdown https://drive.google.com/uc?id=1--flbLLXbMC0_pPnmPAem9pnYwIhOjjF\n",
        "# ! gunzip -c /content/paracrawl-release1.en-ru.zipporah0-dedup-clean.tgz | tar xvf -\n",
        "# with open('/content/paracrawl-release1.en-ru.zipporah0-dedup-clean.en') as f:\n",
        "#     eng_lines = [i.strip() for i in f.readlines()]\n",
        "\n",
        "# with open('/content/paracrawl-release1.en-ru.zipporah0-dedup-clean.ru') as f:\n",
        "#     ru_lines = [i.strip() for i in f.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkNVSeifWNWc"
      },
      "source": [
        "YANDEX data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di6TTltG1oiD"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlXlpypFWPbh"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1-6VfQwe6I3t8utkGkqDiyuyrqc35Xg6c\n",
        "! unzip /content/1mcorpus.zip\n",
        "# ! unzip /content/drive/MyDrive/MT_sentence_simpl/1mcorpus.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBj8iHqISYht"
      },
      "source": [
        "with open('/content/corpus.en_ru.1m.en') as f:\n",
        "    eng_lines = [i.strip() for i in f.readlines()]\n",
        "\n",
        "with open('/content/corpus.en_ru.1m.ru') as f:\n",
        "    ru_lines = [i.strip() for i in f.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxBP5fc5PZEW"
      },
      "source": [
        "data_test = pd.DataFrame(list(zip(eng_lines, ru_lines)), columns=['src', 'dst'])\n",
        "# data_test[30000:33000].to_csv('/content/drive/MyDrive/MT_sentence_simpl/translation_test_new_sample.csv', index=False)\n",
        "# data_test_new.to_csv('/content/drive/MyDrive/MT_sentence_simpl/translation_test_new.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBie3XYngjEq"
      },
      "source": [
        "ru_train, ru_val, eng_train, eng_val = train_test_split(ru_lines[:30000], eng_lines[:30000], test_size=.1)\n",
        "# ru_test, eng_test = ru_train[30000:33000], eng_train[30000:33000]\n",
        "# test_data = pd.DataFrame(list(zip(eng_test, ru_test)), columns = ['src', 'dst'])\n",
        "# test_data.to_csv('/content/drive/MyDrive/MT_sentence_simpl/translation_test.csv', index=False)\n",
        "# ru_train, ru_val, eng_train, eng_val = ru_train[:30000], ru_val[:5000],\\\n",
        "#                                         eng_train[:30000], eng_val[:5000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6pniaxk18Qr"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1-paJt-Q077ZoQ3l_kDQGTbusRkun70PR\n",
        "test_data = pd.read_csv('/content/data_test_sample_google.csv')\n",
        "test_data.google_API = test_data.google_API.apply(lambda x: x.replace(\"&quot;\", \" \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW7vvkpsZGEh"
      },
      "source": [
        "# test_data = pd.read_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzwt_lzjgjEn"
      },
      "source": [
        "# Finetuning Mariam MT from Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywHlfmswgjEp"
      },
      "source": [
        "# Freeze encoder weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wwitIfsgjEo"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ru\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-ru\")\n",
        "model.to(device)\n",
        "\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = True #False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaqSWLpMgjEr"
      },
      "source": [
        "train_encodings = tokenizer.prepare_seq2seq_batch(eng_train, \n",
        "                                                  ru_train, \n",
        "                                                  truncation=True, \n",
        "                                                  padding=True,\n",
        "                                                  max_length=100)\n",
        "val_encodings = tokenizer.prepare_seq2seq_batch(eng_val, \n",
        "                                                ru_val, \n",
        "                                                truncation=True, \n",
        "                                                padding=True,\n",
        "                                                max_length=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDici8-R_uun"
      },
      "source": [
        "# model = AutoModelForSeq2SeqLM.from_pretrained('/content/drive/MyDrive/MT_sentence_simpl/models/marian_model_8_epochs_30k_samples_no_max_length')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAQtkCVHgjEs"
      },
      "source": [
        "class Seq2seqDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"labels\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dX-b9vjgjEs"
      },
      "source": [
        "train_dataset = Seq2seqDataset(train_encodings)\n",
        "eval_dataset = Seq2seqDataset(val_encodings)\n",
        "model.train()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)#64\n",
        "optim = AdamW(model.lm_head.parameters(), lr=5e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yxPeGlsVgjEv"
      },
      "source": [
        "for epoch in range(8):\n",
        "    epoch_loss = []\n",
        "    for batch in tqdm(train_loader):\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "#         embeddings = model.base_model(input_ids,\\\n",
        "#                                       decoder_input_ids=labels,\\\n",
        "#                                       attention_mask=attention_mask)/\n",
        "#                                       .requires_grad(True)\n",
        "#         outputs = model.lm_head(embeddings)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        epoch_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "    print(f\"Epoch {epoch} finished; Loss : {np.mean(epoch_loss)}\")\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhqBuNZ2n1yQ"
      },
      "source": [
        "import os\n",
        "! mkdir /content/drive/MyDrive/MT_sentence_simpl/models\n",
        "experiment_name = \"marian_model_8_epochs_30k_samples_no_max_length\"\n",
        "model.save_pretrained(os.path.join(\"/content/drive/MyDrive/MT_sentence_simpl/models\", experiment_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QMKwhb_E1yf"
      },
      "source": [
        "# MARIAM MT Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv--8VPfE5Ks"
      },
      "source": [
        "# helper functions\n",
        "\n",
        "def batch_generator(\n",
        "        list_of_sentences,\n",
        "        size=32\n",
        "):\n",
        "    num_batch = len(list_of_sentences)//size\n",
        "    for index in range(num_batch):\n",
        "        yield list_of_sentences[index*size:(index+1)*size]\n",
        "    yield list_of_sentences[num_batch*size:]\n",
        "\n",
        "\n",
        "def translate_to_russin(model, tok, src):\n",
        "\n",
        "  translations_src = []\n",
        "  for i in tqdm_notebook(batch_generator(src)):\n",
        "    l = tok(i, return_tensors=\"pt\", padding=True, max_length=512, truncation=True).to(device)\n",
        "    translated = model.generate(**l)\n",
        "    translations_src.extend([tok.decode(t, skip_special_tokens=True) for t in translated])\n",
        "\n",
        "  return translations_src\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn7lg3WhZgLP"
      },
      "source": [
        "## Original version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEwTnxH-Zio4"
      },
      "source": [
        "# import en-ru model from transformers\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "b14e024889564d65a1ff29c57f70f9af",
            "3a46d65568204ad7baaa193ed7a47914",
            "e36bb1f90907483eaf7a8ee3836b9a82",
            "7405ecbc3a4d47f08de8bc8aab453b40",
            "27f497fb8a7d42958b9b12c8c5dccd00",
            "ef20d2aa105d4539a34b73ac42c04107",
            "cd04eed7550246f5950e35cad38045d9",
            "e8db1c11f54548f0b69eb9eb85f5a08c"
          ]
        },
        "id": "Xlrib-ZFZqUt",
        "outputId": "6e9910b7-bb7f-4cf4-dde5-3ccb554ab8cf"
      },
      "source": [
        "# test--------------------------------------------------\n",
        "sys  = translate_to_russin(model, tokenizer, list(test_data.src.values))\n",
        "for i, obj  in enumerate(sys):\n",
        "  sys[i] = sys[i].replace('&gt;', '')\n",
        "  #src[i] = re.sub(r'[&gt;{1,}]', \" \", src[i])\n",
        "  sys[i] = sys[i].replace('&lt;', '')\n",
        "  sys[i] = sys[i].replace('()', '')\n",
        "  sys[i] = sys[i].replace('&quot;', '')\n",
        "test_data['mariam_sys'] = sys\n",
        "test_data.to_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b14e024889564d65a1ff29c57f70f9af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oddwKgW-Zd41"
      },
      "source": [
        "## Tuned version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "X7IVIMb2bhg-",
        "outputId": "cae8e76c-43be-408f-b717-9cb3c32d0e89"
      },
      "source": [
        "test_data.sample(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>google_API</th>\n",
              "      <th>mariam_sys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2833</th>\n",
              "      <td>You should ignore them.</td>\n",
              "      <td>Вам следует пренебрегать ими.</td>\n",
              "      <td>Вы должны игнорировать их.</td>\n",
              "      <td>Ты должен игнорировать их.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1821</th>\n",
              "      <td>It seems to me there are three candidates.</td>\n",
              "      <td>Мне кажется, уже есть три 'кандидата'.</td>\n",
              "      <td>Мне кажется, есть три кандидата.</td>\n",
              "      <td>Мне кажется, что есть три кандидата.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>Foreign workers account for barely one third o...</td>\n",
              "      <td>Едва лишь одну треть от общей численности труд...</td>\n",
              "      <td>Иностранные работники составляют едва ли треть...</td>\n",
              "      <td>Иностранные рабочие составляют лишь одну треть...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1142</th>\n",
              "      <td>It was no coincidence that the Kimberley Proce...</td>\n",
              "      <td>Не было случайностью, что Кимберлийский процес...</td>\n",
              "      <td>Кимберлийский процесс зародился в Южной Африке...</td>\n",
              "      <td>Не случайно Кимберлийский процесс родился в Юж...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    src  ...                                         mariam_sys\n",
              "2833                            You should ignore them.  ...                         Ты должен игнорировать их.\n",
              "1821         It seems to me there are three candidates.  ...               Мне кажется, что есть три кандидата.\n",
              "361   Foreign workers account for barely one third o...  ...  Иностранные рабочие составляют лишь одну треть...\n",
              "1142  It was no coincidence that the Kimberley Proce...  ...  Не случайно Кимберлийский процесс родился в Юж...\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNy5yj1bJdd_"
      },
      "source": [
        "# import en-ru model from transformers\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model_name = '/content/drive/MyDrive/MT_sentence_simpl/models/marian_model_8_epochs_30k_samples_no_max_length'\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hmY7dUL0n63",
        "outputId": "41309cc1-ed30-4ff4-ee88-923333b7908e"
      },
      "source": [
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(62518, 512, padding_idx=62517)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "c9fc1a4bdb0145a08980bb06f7a22ead",
            "c73c3601aab14dbf89b4a0af9486dfc7",
            "33c8242881d244b7a844530a87be0de1",
            "d8ba8eebe19f492dbf6435ab3c2ac20e",
            "d18b284dc49d4ca9b04d920d068c3e5e",
            "cbd1dd46b6cb4fc9bd9417861df39b0a",
            "afd6cbad432d4df18bb5d0f4452ea845",
            "a1976bad45d14421b1d766ad38756fe0"
          ]
        },
        "id": "7yEbnYRNKBRW",
        "outputId": "965b2c21-d81c-460a-a37d-073c4eef6c9b"
      },
      "source": [
        "sys  = translate_to_russin(model, tokenizer, list(test_data.src.values))\n",
        "for i, obj  in enumerate(sys):\n",
        "  sys[i] = sys[i].replace('&gt;', '')\n",
        "  #src[i] = re.sub(r'[&gt;{1,}]', \" \", src[i])\n",
        "  sys[i] = sys[i].replace('&lt;', '')\n",
        "  sys[i] = sys[i].replace('()', '')\n",
        "  sys[i] = sys[i].replace('&quot;', '')\n",
        "test_data['mariam_tuned_sys'] = sys\n",
        "test_data.to_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9fc1a4bdb0145a08980bb06f7a22ead",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "pG-uzso-vgTZ",
        "outputId": "c17cbecc-1df8-4dca-b16c-7d6074f584c9"
      },
      "source": [
        "test_data.sample(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>google_API</th>\n",
              "      <th>mariam_sys</th>\n",
              "      <th>mariam_tuned_sys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>When these application are started via Gpass, ...</td>\n",
              "      <td>Когда это приложение запускается через TGPasst...</td>\n",
              "      <td>Когда эти приложения запускаются через Gpass, ...</td>\n",
              "      <td>Когда это приложение запускается через Gpass, ...</td>\n",
              "      <td>Когда приложение запускается через Gpass, они ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>5th International Conference on Advanced Techn...</td>\n",
              "      <td>и разработкам в целлюлозно-бумажной промышленн...</td>\n",
              "      <td>5-я Международная конференция по передовым тех...</td>\n",
              "      <td>Пятая Международная конференция по передовым т...</td>\n",
              "      <td>Пятая международная конференция по современным...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2982</th>\n",
              "      <td>(While provincial reconstruction teams are led...</td>\n",
              "      <td>(В то время как провинциальные команды реконст...</td>\n",
              "      <td>(Хотя провинциальные группы по восстановлению ...</td>\n",
              "      <td>(В то время как провинциальные группы по восст...</td>\n",
              "      <td>(Хотя провинциальные группы по восстановлению ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>This is all having a direct negative impact on...</td>\n",
              "      <td>Все это оказывает негативное воздействие на по...</td>\n",
              "      <td>Все это оказывает прямое негативное воздействи...</td>\n",
              "      <td>Все это оказывает непосредственное негативное ...</td>\n",
              "      <td>Все это оказывает непосредственное негативное ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    src  ...                                   mariam_tuned_sys\n",
              "522   When these application are started via Gpass, ...  ...  Когда приложение запускается через Gpass, они ...\n",
              "823   5th International Conference on Advanced Techn...  ...  Пятая международная конференция по современным...\n",
              "2982  (While provincial reconstruction teams are led...  ...  (Хотя провинциальные группы по восстановлению ...\n",
              "532   This is all having a direct negative impact on...  ...  Все это оказывает непосредственное негативное ...\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGhq-F0FS-Gd"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq6cQxiGVWtd"
      },
      "source": [
        "! pip3 install sacrebleu\n",
        "! pip install -U nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SkON1L-S-g4"
      },
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GVZpRQuavRZ"
      },
      "source": [
        "### MARIAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yT5Wep8aplJ"
      },
      "source": [
        "### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8liDRMZaxuv",
        "outputId": "368d6a5f-fc1d-4f41-9bf9-6f072ea7eb95"
      },
      "source": [
        "import sacrebleu\n",
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['mariam_sys'].values)\n",
        "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
        "print(bleu.score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21.934412821022754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiQkkc4QVCVG",
        "outputId": "76b7878a-3148-4374-fe18-46e0c3ff1b43"
      },
      "source": [
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['mariam_sys'].values)\n",
        "np.mean([sacrebleu.sentence_bleu(i,j).score for i, j in list(zip(sys, refs))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.78787818101128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy-RFAjJn04c",
        "outputId": "7bf38884-a71d-42c5-88b1-9ee7ef99921e"
      },
      "source": [
        "# refs = []\n",
        "# for i, j in data_dict.items():\n",
        "#   refs.append(j)\n",
        "\n",
        "nltk.translate.bleu_score.corpus_bleu(refs, sys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16893612092623872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1TVCEsuh5k0"
      },
      "source": [
        "##### NIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng8Xo-lVhARe",
        "outputId": "a9a86256-a9f6-4a3f-9e1d-b4afd563f2ac"
      },
      "source": [
        "from nltk.translate.nist_score import corpus_nist\n",
        "refs = [[i.split()] for i in test_data['dst'].values]\n",
        "sys = [i.split() for i in test_data['mariam_sys'].values]\n",
        "corpus_nist(refs,sys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.630190713636598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuT7czBvd9Av"
      },
      "source": [
        "#### METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYG8TTh_fSWy"
      },
      "source": [
        "meteor_mt = sum(meteor_score(row['dst'], row['mariam_sys']) for i, row in test_data.iterrows())/test_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7qOU3NPgdDU",
        "outputId": "cea6d1bf-71b5-451f-fff5-54ed4ce62ff9"
      },
      "source": [
        "meteor_mt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1541136436844775"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9mKt-Barfy"
      },
      "source": [
        "### MARIAM Tuned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "131eUIICgyEp"
      },
      "source": [
        "### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B88kP8FHXsYY",
        "outputId": "07773926-7087-43d3-a211-f811733fa2d3"
      },
      "source": [
        "import sacrebleu\n",
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['mariam_tuned_sys'].values)\n",
        "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
        "print(bleu.score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21.411719265727832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNm4v-5IXrT8",
        "outputId": "09c6b78f-43e5-46b4-972f-ee01e596c337"
      },
      "source": [
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['mariam_tuned_sys'].values)\n",
        "np.mean([sacrebleu.sentence_bleu(i,j).score for i, j in list(zip(sys, refs))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46.825687910244035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd8gYAO-obL3",
        "outputId": "bafc2a50-4072-4bc1-ee13-d23111576ab3"
      },
      "source": [
        "nltk.translate.bleu_score.corpus_bleu(refs, sys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16258154057153446"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj_hiE2Fh9BF"
      },
      "source": [
        "##### NIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozBbh0Gtg5bA",
        "outputId": "e5025281-bd27-4d46-bc8f-47660f1e947a"
      },
      "source": [
        "from nltk.translate.nist_score import corpus_nist\n",
        "refs = [[i.split()] for i in test_data['dst'].values]\n",
        "sys = [i.split() for i in test_data['mariam_tuned_sys'].values]\n",
        "corpus_nist(refs,sys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.543044277381849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKco_cNFgWJ_"
      },
      "source": [
        "##### METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro1OJeSTgbeN"
      },
      "source": [
        "meteor_mt = sum(meteor_score(row['dst'], row['mariam_tuned_sys']) for i, row in test_data.iterrows())/test_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv1MExX9hCKr",
        "outputId": "7102a01a-2391-428b-f83b-e608123957e8"
      },
      "source": [
        "meteor_mt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15623524899165783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSdwaYsEhJz8"
      },
      "source": [
        "### GOOGLE API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ0u_CAEnDpE"
      },
      "source": [
        "##### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZyPeTpHm-lc",
        "outputId": "1124332b-6f04-4f59-9837-e481ddb0d76a"
      },
      "source": [
        "import sacrebleu\n",
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['google_API'].values)\n",
        "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
        "print(bleu.score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26.129453989406834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlyO7ObwX2kt",
        "outputId": "7aadfa98-8e4a-4c16-aba5-66a68e381ff3"
      },
      "source": [
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['google_API'].values)\n",
        "np.mean([sacrebleu.sentence_bleu(i,j).score for i, j in list(zip(sys, refs))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54.45178846139407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzN1GkUogOi",
        "outputId": "86b9acea-8423-4276-9b96-914ee4023837"
      },
      "source": [
        "nltk.translate.bleu_score.corpus_bleu(refs, sys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20723400512274096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjA9MbwYiAZ_"
      },
      "source": [
        "##### NIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gdF0pIYgzKP",
        "outputId": "d3bf0ffc-7621-4eec-d7d6-84eaad8c2953"
      },
      "source": [
        "from nltk.translate.nist_score import corpus_nist\n",
        "refs = [[i.split()] for i in test_data['dst'].values]\n",
        "sys = [i.split() for i in test_data['google_API'].values]\n",
        "corpus_nist(refs,sys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.405032515651133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbWulYy0nGSF"
      },
      "source": [
        "##### METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyH7Hl9inGaM"
      },
      "source": [
        "meteor_mt = sum(meteor_score(row['dst'], row['google_API']) for i, row in test_data.iterrows())/test_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT-WMf0ZnPZD",
        "outputId": "2c589e97-480e-4197-98d5-cd4a1b05509f"
      },
      "source": [
        "meteor_mt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15040614041259198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0KsPzdt3yNq"
      },
      "source": [
        "# Fairseq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHsgn3E731zP",
        "outputId": "eb73165b-055d-4b59-c7c6-74c7845cb733"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWXSwXec5S3_"
      },
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fairseq/models/mbart/mbart.cc25.v2.tar.gz\n",
        "! tar -xzvf /content/mbart.cc25.v2.tar.gz\n",
        "! apt-get install cmake build-essential pkg-config libgoogle-perftools-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_-_vv4C5TAp"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd /content/fairseq/\n",
        "!python -m pip install --editable .\n",
        "%cd /content\n",
        "\n",
        "! echo $PYTHONPATH\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
        "\n",
        "! echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8wuOvwG54D-"
      },
      "source": [
        "# Process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzMC6KZh5TFI"
      },
      "source": [
        "! rm -r /content/fairseq/data\n",
        "! mkdir /content/fairseq/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysM3AKVN6i2g"
      },
      "source": [
        "ru_train, ru_val, eng_train, eng_val \n",
        "data_train = pd.DataFrame(list(zip(eng_train, ru_train)), columns=['src', 'dst'])\n",
        "data_dev = pd.DataFrame(list(zip(eng_val, ru_val)), columns=['src', 'dst'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2QB-bwG5TG0"
      },
      "source": [
        "### process WikiLarge\n",
        "\n",
        "with open('/content/fairseq/data/test.en', \"a\") as f:\n",
        "  for i, row in test_data.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.en', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.en', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.ru', \"a\") as f:\n",
        "  for i, row in test_data.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.ru', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.ru', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['dst']+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h54eA5i5TKL"
      },
      "source": [
        "SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "DATA_DIR=\"/content/fairseq/data\"\n",
        "SRC=\"en\"\n",
        "TGT=\"ru\" #en\n",
        "\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$SRC > $DATA_DIR/train.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$TGT > $DATA_DIR/train.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$SRC > $DATA_DIR/dev.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$TGT > $DATA_DIR/dev.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$SRC > $DATA_DIR/test.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$TGT > $DATA_DIR/test.spm.$TGT &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh8Zy0d05TMM",
        "outputId": "c19696fb-70f9-4dfb-ce3f-83c7c38ea200"
      },
      "source": [
        "PREPROCESSED_DATA_DIR=\"/content/fairseq/data\"\n",
        "DICT=\"/content/mbart.cc25.v2/dict.txt\"\n",
        "!fairseq-preprocess \\\n",
        "  --source-lang en \\\n",
        "  --target-lang ru \\\n",
        "  --trainpref /content/fairseq/data/train.spm \\\n",
        "  --validpref /content/fairseq/data/dev.spm \\\n",
        "  --testpref /content/fairseq/data/test.spm \\\n",
        "  --destdir /content/fairseq/data \\\n",
        "  --thresholdtgt 0 \\\n",
        "  --thresholdsrc 0 \\\n",
        "  --srcdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --tgtdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --workers 70"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-29 00:15:29 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/content/fairseq/data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='en', srcdict='/content/mbart.cc25.v2/dict.txt', suppress_crashes=False, target_lang='ru', task='translation', tensorboard_logdir=None, testpref='/content/fairseq/data/test.spm', tgtdict='/content/mbart.cc25.v2/dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/fairseq/data/train.spm', use_plasma_view=False, user_dir=None, validpref='/content/fairseq/data/dev.spm', wandb_project=None, workers=70)\n",
            "2021-04-29 00:15:30 | INFO | fairseq_cli.preprocess | [en] Dictionary: 250001 types\n",
            "2021-04-29 00:15:41 | INFO | fairseq_cli.preprocess | [en] /content/fairseq/data/train.spm.en: 27000 sents, 817692 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:15:41 | INFO | fairseq_cli.preprocess | [en] Dictionary: 250001 types\n",
            "2021-04-29 00:15:50 | INFO | fairseq_cli.preprocess | [en] /content/fairseq/data/dev.spm.en: 3000 sents, 89011 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:15:50 | INFO | fairseq_cli.preprocess | [en] Dictionary: 250001 types\n",
            "2021-04-29 00:16:00 | INFO | fairseq_cli.preprocess | [en] /content/fairseq/data/test.spm.en: 3000 sents, 91695 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:16:00 | INFO | fairseq_cli.preprocess | [ru] Dictionary: 250001 types\n",
            "2021-04-29 00:16:11 | INFO | fairseq_cli.preprocess | [ru] /content/fairseq/data/train.spm.ru: 27000 sents, 906556 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:16:11 | INFO | fairseq_cli.preprocess | [ru] Dictionary: 250001 types\n",
            "2021-04-29 00:16:20 | INFO | fairseq_cli.preprocess | [ru] /content/fairseq/data/dev.spm.ru: 3000 sents, 98575 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:16:20 | INFO | fairseq_cli.preprocess | [ru] Dictionary: 250001 types\n",
            "2021-04-29 00:16:30 | INFO | fairseq_cli.preprocess | [ru] /content/fairseq/data/test.spm.ru: 3000 sents, 101425 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:16:30 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/fairseq/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGZbKR3i_Gwk"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Afw5hNEw_MGG"
      },
      "source": [
        "Also, it is necessary to make the following change in /content/fairseq/fairseq/tasks/translation_from_pretrained_bart.py:\n",
        "\n",
        "```\n",
        "def __init__(self, args, src_dict, tgt_dict):\n",
        "        super().__init__(args, src_dict, tgt_dict)\n",
        "        self.args = args                  # add this line !!!!!\n",
        "        self.langs = args.langs.split(\",\")\n",
        "        for d in [src_dict, tgt_dict]:\n",
        "            for l in self.langs:\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp603T6y_cp6"
      },
      "source": [
        "# mkdir to put the checkpoints\n",
        "! mkdir /content/drive/MyDrive/checkpoints_mt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_TRW_xq-tTi",
        "outputId": "be30a777-0c53-40cc-bd8b-68c801cf7b97"
      },
      "source": [
        "!fairseq-train /content/fairseq/data \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --arch mbart_large --layernorm-embedding \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
        "  --optimizer adam --adam-eps 1e-06 --adam-betas '(0.9, 0.98)' \\\n",
        "  --lr-scheduler polynomial_decay --lr 3e-05 --warmup-updates 2500 --total-num-update 54725  \\\n",
        "  --dropout 0.3 --attention-dropout 0.1 --weight-decay 0.0 \\\n",
        "  --max-tokens 1024 --update-freq 5 \\\n",
        "  --source-lang en --target-lang ru \\\n",
        "  --batch-size 16 \\\n",
        "  --memory-efficient-fp16 \\\n",
        "  --validate-interval 1 \\\n",
        "  --patience 3 \\\n",
        "  --max-epoch 5 \\\n",
        "  --save-interval 5 --keep-last-epochs 10 --keep-best-checkpoints 2 \\\n",
        "  --ddp-backend no_c10d \\\n",
        "  --seed 42 --log-format simple --log-interval 500 \\\n",
        "  --restore-file /content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt \\\n",
        "  --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler \\\n",
        "  --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN \\\n",
        "  --scoring bleu \\\n",
        "  --save-dir /content/drive/MyDrive/checkpoints_mt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-29 01:09:32 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 500, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1024, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [5], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints_mt', 'restore_file': '/content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 10, 'keep_best_checkpoints': 2, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='mbart_large', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt', save_dir='/content/drive/MyDrive/checkpoints_mt', save_interval=5, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='ru', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': Namespace(_name='translation_from_pretrained_bart', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt', save_dir='/content/drive/MyDrive/checkpoints_mt', save_interval=5, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='ru', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 2500, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 54725.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}\n",
            "2021-04-29 01:09:33 | INFO | fairseq.tasks.translation | [en] dictionary: 250001 types\n",
            "2021-04-29 01:09:33 | INFO | fairseq.tasks.translation | [ru] dictionary: 250001 types\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | BARTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=1024, out_features=250027, bias=False)\n",
            "  )\n",
            "  (classification_heads): ModuleDict()\n",
            ")\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | task: TranslationFromPretrainedBARTTask\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | model: BARTModel\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | num. shared model params: 610,851,840 (num. trained: 610,851,840)\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-04-29 01:09:58 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: /content/fairseq/data/valid.en-ru.en\n",
            "2021-04-29 01:09:58 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: /content/fairseq/data/valid.en-ru.ru\n",
            "2021-04-29 01:09:58 | INFO | fairseq.tasks.translation | /content/fairseq/data valid en-ru 3000 examples\n",
            "2021-04-29 01:10:03 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2021-04-29 01:10:03 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2021-04-29 01:10:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-04-29 01:10:03 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    \n",
            "2021-04-29 01:10:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-04-29 01:10:03 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-04-29 01:10:03 | INFO | fairseq_cli.train | max tokens per device = 1024 and max sentences per device = 16\n",
            "2021-04-29 01:10:03 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt\n",
            "2021-04-29 01:12:51 | INFO | fairseq.trainer | Loaded checkpoint /content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt (epoch 6 @ 0 updates)\n",
            "2021-04-29 01:13:05 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-04-29 01:13:06 | INFO | fairseq.data.data_utils | loaded 27,000 examples from: /content/fairseq/data/train.en-ru.en\n",
            "2021-04-29 01:13:06 | INFO | fairseq.data.data_utils | loaded 27,000 examples from: /content/fairseq/data/train.en-ru.ru\n",
            "2021-04-29 01:13:06 | INFO | fairseq.tasks.translation | /content/fairseq/data train en-ru 27000 examples\n",
            "2021-04-29 01:13:06 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-04-29 01:13:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/fairseq/fairseq/utils.py:364: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "2021-04-29 01:13:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "2021-04-29 01:13:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "2021-04-29 01:13:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "2021-04-29 01:13:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "2021-04-29 01:13:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "2021-04-29 01:13:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0\n",
            "2021-04-29 01:13:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0\n",
            "2021-04-29 01:13:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5\n",
            "2021-04-29 01:15:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25\n",
            "2021-04-29 01:16:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125\n",
            "2021-04-29 01:18:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:18:45 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.501 | nll_loss 4.165 | ppl 17.94 | wps 7321.1 | wpb 459.6 | bsz 13.6 | num_updates 360\n",
            "2021-04-29 01:18:45 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-04-29 01:18:45 | INFO | train | epoch 001 | loss 9.677 | nll_loss 5.789 | ppl 55.3 | wps 2744.3 | ups 1.09 | wpb 2518.4 | bsz 72.9 | num_updates 360 | lr 4.32e-06 | gnorm 16.715 | loss_scale 0.125 | train_wall 321 | gb_free 4.3 | wall 521\n",
            "2021-04-29 01:18:45 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-04-29 01:18:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-29 01:20:47 | INFO | train_inner | epoch 002:    140 / 370 loss=9.622, nll_loss=5.755, ppl=54.01, wps=2779.2, ups=1.1, wpb=2515.1, bsz=73.1, num_updates=500, lr=6e-06, gnorm=15.697, loss_scale=0.125, train_wall=442, gb_free=5.1, wall=644\n",
            "2021-04-29 01:24:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:24:18 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.131 | nll_loss 4.006 | ppl 16.06 | wps 7180.3 | wpb 459.6 | bsz 13.6 | num_updates 730\n",
            "2021-04-29 01:24:18 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-04-29 01:24:18 | INFO | train | epoch 002 | loss 9.386 | nll_loss 5.638 | ppl 49.8 | wps 2800.4 | ups 1.11 | wpb 2523.1 | bsz 73 | num_updates 730 | lr 8.76e-06 | gnorm 16.216 | loss_scale 0.125 | train_wall 317 | gb_free 4.7 | wall 855\n",
            "2021-04-29 01:24:18 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-04-29 01:24:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-29 01:28:09 | INFO | train_inner | epoch 003:    270 / 370 loss=9.178, nll_loss=5.526, ppl=46.08, wps=2854.1, ups=1.13, wpb=2522.3, bsz=72.9, num_updates=1000, lr=1.2e-05, gnorm=14.512, loss_scale=0.125, train_wall=425, gb_free=5.7, wall=1085\n",
            "2021-04-29 01:29:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:29:51 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.767 | nll_loss 3.795 | ppl 13.88 | wps 7665.2 | wpb 459.6 | bsz 13.6 | num_updates 1100\n",
            "2021-04-29 01:29:51 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-04-29 01:29:51 | INFO | train | epoch 003 | loss 8.997 | nll_loss 5.412 | ppl 42.57 | wps 2806.1 | ups 1.11 | wpb 2523.1 | bsz 73 | num_updates 1100 | lr 1.32e-05 | gnorm 9.841 | loss_scale 0.125 | train_wall 317 | gb_free 6 | wall 1187\n",
            "2021-04-29 01:29:51 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2021-04-29 01:29:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-29 01:35:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:35:21 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.534 | nll_loss 3.605 | ppl 12.17 | wps 7992.7 | wpb 459.6 | bsz 13.6 | num_updates 1470\n",
            "2021-04-29 01:35:21 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2021-04-29 01:35:21 | INFO | train | epoch 004 | loss 8.646 | nll_loss 5.133 | ppl 35.08 | wps 2830.3 | ups 1.12 | wpb 2523.1 | bsz 73 | num_updates 1470 | lr 1.764e-05 | gnorm 10.809 | loss_scale 0.125 | train_wall 315 | gb_free 5.8 | wall 1517\n",
            "2021-04-29 01:35:21 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2021-04-29 01:35:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-29 01:35:46 | INFO | train_inner | epoch 005:     30 / 370 loss=8.677, nll_loss=5.158, ppl=35.7, wps=2765.8, ups=1.09, wpb=2527.6, bsz=72.8, num_updates=1500, lr=1.8e-05, gnorm=9.501, loss_scale=0.125, train_wall=428, gb_free=5.7, wall=1542\n",
            "2021-04-29 01:40:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:40:49 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.354 | nll_loss 3.452 | ppl 10.95 | wps 7984.5 | wpb 459.6 | bsz 13.6 | num_updates 1840\n",
            "2021-04-29 01:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 1840 updates\n",
            "2021-04-29 01:40:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_mt/checkpoint5.pt\n",
            "2021-04-29 01:42:39 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_mt/checkpoint5.pt\n",
            "2021-04-29 01:52:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_mt/checkpoint5.pt (epoch 5 @ 1840 updates, score 7.354) (writing took 709.9956223490008 seconds)\n",
            "2021-04-29 01:52:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2021-04-29 01:52:39 | INFO | train | epoch 005 | loss 8.359 | nll_loss 4.844 | ppl 28.73 | wps 898.9 | ups 0.36 | wpb 2523.1 | bsz 73 | num_updates 1840 | lr 2.208e-05 | gnorm 9.648 | loss_scale 0.125 | train_wall 313 | gb_free 5.7 | wall 2556\n",
            "2021-04-29 01:52:40 | INFO | fairseq_cli.train | done training in 2373.4 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0nEf2_M-td-",
        "outputId": "e8f6dad6-7657-4d84-ad27-227307c9e9d5"
      },
      "source": [
        "!fairseq-generate /content/fairseq/data \\\n",
        "  --path  /content/drive/MyDrive/checkpoints_mt/checkpoint_best.pt \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --gen-subset test \\\n",
        "  --source-lang en --target-lang ru \\\n",
        "  --bpe 'sentencepiece' --sentencepiece-model /content/mbart.cc25.v2/sentence.bpe.model \\\n",
        "  --sacrebleu --remove-bpe 'sentencepiece' \\\n",
        "  --batch-size 32 --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN > model_prediction.txt & \n",
        "!cat model_prediction.txt | grep -P \"^H\" |sort -V |cut -f 3- > model_prediction_mt.hyp\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q4PbHpn5TPO"
      },
      "source": [
        "!cp /content/model_prediction_en_ru_ru_filtered.hyp /content/drive/MyDrive/MT_sentence_simpl/predictions/model_prediction_en_ru_ru_filtered.hyp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdU8r4bMXFMO"
      },
      "source": [
        "with open('/content/model_prediction_mt.hyp') as f:\n",
        "  lines = [i.strip() for i in f.readlines()]\n",
        "\n",
        "\n",
        "test_data['fairseq_mbart'] = lines\n",
        "test_data.to_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSxzOT0DXuru"
      },
      "source": [
        "# Fairseq mBART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlDtwPI7Xy9L"
      },
      "source": [
        "##### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0r4bM2GXZY-",
        "outputId": "a99bccef-101e-43b8-946f-3f3e6f65951d"
      },
      "source": [
        "import sacrebleu\n",
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['fairseq_mbart'].values)\n",
        "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
        "print(bleu.score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.315905780266137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtJPXBqbYSbf",
        "outputId": "40bf3ab3-5efc-4483-d097-fb0c2df57572"
      },
      "source": [
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['fairseq_mbart'].values)\n",
        "np.mean([sacrebleu.sentence_bleu(i,j).score for i, j in list(zip(sys, refs))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34.35599238920265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoSCd4XpcA7y"
      },
      "source": [
        "# from nltk.translate.bleu_score import corpus_bleu\n",
        "# refs = [[i.split()] for i in test_data['dst'].values]\n",
        "# sys = [i.split() for i in test_data['fairseq_mbart'].values]\n",
        "# corpus_bleu(refs,sys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6f_o25hrCIA",
        "outputId": "da188708-9c4a-4085-a2fa-baba71df81c3"
      },
      "source": [
        "nltk.translate.bleu_score.corpus_bleu(refs, sys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0832559310080964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srvv5s7diElH"
      },
      "source": [
        "##### NIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIT_p2MSZyYp",
        "outputId": "b582395f-2568-412f-a008-5ea24e5e1afa"
      },
      "source": [
        "from nltk.translate.nist_score import corpus_nist\n",
        "refs = [[i.split()] for i in data_test['dst'].values]\n",
        "sys = [i.split() for i in data_test['fairseq_mbart'].values]\n",
        "corpus_nist(refs,sys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.6946908482302644e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjqSEykGX2ok"
      },
      "source": [
        "#### METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMdb2sxIZCpX",
        "outputId": "bda48420-ebf0-4457-bb00-868159f661bf"
      },
      "source": [
        "! pip3 install sacrebleu\n",
        "! pip install -U nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2.0.0)\n",
            "Requirement already up-to-date: nltk in /usr/local/lib/python3.7/dist-packages (3.6.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNgj8n8wXbSI",
        "outputId": "b213ac6b-5e90-451a-df97-e40d026d00bb"
      },
      "source": [
        "meteor_mt = sum(meteor_score(row['dst'], row['google_API']) for i, row in test_data.iterrows())/test_data.shape[0]\n",
        "meteor_mt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15064013355701317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zyy3yxo5VhX"
      },
      "source": [
        "# Ultimate translation set and Cos Sim Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vUSIVyQCy-h"
      },
      "source": [
        "! pip install googletrans\n",
        "! pip install transformers\n",
        "! pip install laserembeddings\n",
        "! pip install sentence_transformers\n",
        "! pip install language_tool_python\n",
        "! pip install textstat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkOJ2ZhbCzNd",
        "outputId": "0108e13a-8b3c-47ee-fc39-4e6d208fece5"
      },
      "source": [
        "! python -m laserembeddings download-models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading models into /usr/local/lib/python3.7/dist-packages/laserembeddings/data\n",
            "\n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n",
            "\n",
            "✨ You're all set!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-5_r_DRC2to"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import language_tool_python\n",
        "import re\n",
        "import textstat\n",
        "from laserembeddings import Laser\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from transformers.hf_api import HfApi\n",
        "from googletrans import Translator\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X9VX_uGJC_Wf",
        "outputId": "d88e2134-42fc-4c88-b2dc-a87aa477aea0"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>google_API</th>\n",
              "      <th>mariam_sys</th>\n",
              "      <th>mariam_tuned_sys</th>\n",
              "      <th>fairseq_mbart</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>And there is no need to generalize, good relations with Armenians from abroad are being built here as well.</td>\n",
              "      <td>И не надо обобщать, здесь тоже по-разному строятся отношения с армянами из-за рубежа.</td>\n",
              "      <td>И не надо обобщать, здесь также строятся хорошие отношения с армянами из-за границы.</td>\n",
              "      <td>И нет необходимости обобщать, здесь также строятся хорошие отношения с армянами из-за границы.</td>\n",
              "      <td>И нет необходимости обобщать, здесь также строятся хорошие отношения с армянами из-за рубежа.</td>\n",
              "      <td>И не нужно говорить о том, что хорошие отношения с армянами из-за внешнего мира будут построены здесь.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Silva, YSU: I myself am from Javakheti and I live among Armenians, the communication there is only in Armenian and schools are also in Armenian.</td>\n",
              "      <td>Сильва, студентка ЕГУ, будущий фармацевт: Я сама из Джавахети и живу там среди армян и общение там только на армянском и школы армянские.</td>\n",
              "      <td>Сильва, ЕГУ: Я сам из Джавахети и живу среди армян, общение там только на армянском, школы тоже на армянском.</td>\n",
              "      <td>Сильва, ЙСУ (говорит по-английски): Я сам из Явахети и я живу среди армян, связь существует только на армянском языке, а школы также на армянском языке.</td>\n",
              "      <td>Silva, YSU: Я сам из Javakheti и я живу среди армян, коммуникация есть только в армянском, и школы тоже на армянском.</td>\n",
              "      <td>Silva, YSU: Я сам из Javakheti и живу среди Армянцев, коммуникации есть только в Армяне и школы также в Армяне.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Laura Khanamiryan: I want to say that regretfully the only well preserved Armenian churches are in Iran.</td>\n",
              "      <td>Лаура Ханамирян: Хочу сказать, что, к сожалению, самыми сохраненными являются армянские церкви в Иране.</td>\n",
              "      <td>Лаура Ханамирян: Я хочу сказать, что, к сожалению, единственные хорошо сохранившиеся армянские церкви находятся в Иране.</td>\n",
              "      <td>Лора Ханамирян (говорит по-английски): Я хочу сказать, что, к сожалению, единственные хорошо сохранившиеся армянские церкви находятся в Иране.</td>\n",
              "      <td>Лора Ханамирян: к сожалению, единственные хорошо сохранившиеся армянские церкви находятся в Иране.</td>\n",
              "      <td>Laura Khanamiryan: Я хочу сказать, что единственные хорошо сохраненные армийские церкви в Иране.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Packages are the different groups of files that make up a particular piece of software, along with the instructions Ubuntu needs to install and remove the software, dependency information, and so on.</td>\n",
              "      <td>В состав пакетов входят различные файлы, которые представляют собой конкретные части программного обеспечения, а также инструкции для Ubuntu, необходимые для установки и удаления программного обеспечения, информацию о зависимостях, и так далее.</td>\n",
              "      <td>Пакеты - это различные группы файлов, которые составляют определенную часть программного обеспечения, а также инструкции, необходимые Ubuntu для установки и удаления программного обеспечения, информацию о зависимостях и т. Д.</td>\n",
              "      <td>Пакеты представляют собой различные группы файлов, которые составляют конкретный элемент программного обеспечения, вместе с инструкциями Ubuntu, необходимыми для установки и удаления программного обеспечения, информации о зависимости и т.д.</td>\n",
              "      <td>Пакеты представляют собой различные группы файлов, составляющих определенный элемент программного обеспечения, наряду с инструкциями Убунту, необходимыми для установки и удаления программного обеспечения, информации о зависимости и т.д.</td>\n",
              "      <td>Packages являются различными группами файлов, которые составляют определенную часть программного обеспечения, вместе с указаниями Ubuntu необходимо установить и удалить программное обеспечение, зависимость и так далее.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Ubuntu is based on the Debian Linux distribution but contains only a subset of Debian's software due to the amount of testing required to support each package. universe is a subcategory that contains software that the community has packaged and supports for Ubuntu.</td>\n",
              "      <td>Система Ubuntu базируется на дистрибутиве Debian Linux, но в ней содержится только часть программного обеспечения Debian из-за того, что для поддержки каждого пакета требуется выполнение большого количества тестов. universe является подкатегорией, к которой относятся пакеты, собранные и поддерживаемые сообществом Ubuntu.</td>\n",
              "      <td>Ubuntu основан на дистрибутиве Debian Linux, но содержит только подмножество программного обеспечения Debian из-за количества тестов, необходимых для поддержки каждого пакета. Universe - это подкатегория, содержащая программное обеспечение, которое сообщество разработало и поддерживает для Ubuntu.</td>\n",
              "      <td>Ubuntu основан на дистрибьюции Debian Linux, но содержит только подмножество программного обеспечения Дебиана из-за количества тестов, необходимых для поддержки каждой упаковки. Вселенная является подкатегорией, которая содержит программное обеспечение, которое сообщество упаковало и поддерживало Ubuntu.</td>\n",
              "      <td>Ubuntu основан на дистрибутиве Debian Linux, но содержит только подмножество программного обеспечения Debian из-за количества тестов, необходимых для поддержки каждой упаковки. Вселенная - это подкатегория, содержащая программное обеспечение, которое было собрано и поддержано сообществом для Ubuntu.</td>\n",
              "      <td>Ubuntu основана на дистрибуции Debian Linux, но содержит только часть дистрибуции Debian, потому что требуется большое количество тестирования для поддержки каждого пакета.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                                                                                                                                                                                                                                                        src                                                                                                                                                                                                                                                                                                                                 dst                                                                                                                                                                                                                                                                                                  google_API  \\\n",
              "0           0                                                                                                                                                                And there is no need to generalize, good relations with Armenians from abroad are being built here as well.                                                                                                                                                                                                                                               И не надо обобщать, здесь тоже по-разному строятся отношения с армянами из-за рубежа.                                                                                                                                                                                                                        И не надо обобщать, здесь также строятся хорошие отношения с армянами из-за границы.   \n",
              "1           1                                                                                                                           Silva, YSU: I myself am from Javakheti and I live among Armenians, the communication there is only in Armenian and schools are also in Armenian.                                                                                                                                                                                           Сильва, студентка ЕГУ, будущий фармацевт: Я сама из Джавахети и живу там среди армян и общение там только на армянском и школы армянские.                                                                                                                                                                                               Сильва, ЕГУ: Я сам из Джавахети и живу среди армян, общение там только на армянском, школы тоже на армянском.   \n",
              "2           2                                                                                                                                                                   Laura Khanamiryan: I want to say that regretfully the only well preserved Armenian churches are in Iran.                                                                                                                                                                                                                             Лаура Ханамирян: Хочу сказать, что, к сожалению, самыми сохраненными являются армянские церкви в Иране.                                                                                                                                                                                    Лаура Ханамирян: Я хочу сказать, что, к сожалению, единственные хорошо сохранившиеся армянские церкви находятся в Иране.   \n",
              "3           3                                                                    Packages are the different groups of files that make up a particular piece of software, along with the instructions Ubuntu needs to install and remove the software, dependency information, and so on.                                                                                В состав пакетов входят различные файлы, которые представляют собой конкретные части программного обеспечения, а также инструкции для Ubuntu, необходимые для установки и удаления программного обеспечения, информацию о зависимостях, и так далее.                                                                           Пакеты - это различные группы файлов, которые составляют определенную часть программного обеспечения, а также инструкции, необходимые Ubuntu для установки и удаления программного обеспечения, информацию о зависимостях и т. Д.   \n",
              "4           4  Ubuntu is based on the Debian Linux distribution but contains only a subset of Debian's software due to the amount of testing required to support each package. universe is a subcategory that contains software that the community has packaged and supports for Ubuntu.  Система Ubuntu базируется на дистрибутиве Debian Linux, но в ней содержится только часть программного обеспечения Debian из-за того, что для поддержки каждого пакета требуется выполнение большого количества тестов. universe является подкатегорией, к которой относятся пакеты, собранные и поддерживаемые сообществом Ubuntu.  Ubuntu основан на дистрибутиве Debian Linux, но содержит только подмножество программного обеспечения Debian из-за количества тестов, необходимых для поддержки каждого пакета. Universe - это подкатегория, содержащая программное обеспечение, которое сообщество разработало и поддерживает для Ubuntu.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                          mariam_sys                                                                                                                                                                                                                                                                                              mariam_tuned_sys                                                                                                                                                                                                               fairseq_mbart  \n",
              "0                                                                                                                                                                                                                     И нет необходимости обобщать, здесь также строятся хорошие отношения с армянами из-за границы.                                                                                                                                                                                                                 И нет необходимости обобщать, здесь также строятся хорошие отношения с армянами из-за рубежа.                                                                                                                      И не нужно говорить о том, что хорошие отношения с армянами из-за внешнего мира будут построены здесь.  \n",
              "1                                                                                                                                                           Сильва, ЙСУ (говорит по-английски): Я сам из Явахети и я живу среди армян, связь существует только на армянском языке, а школы также на армянском языке.                                                                                                                                                                                         Silva, YSU: Я сам из Javakheti и я живу среди армян, коммуникация есть только в армянском, и школы тоже на армянском.                                                                                                             Silva, YSU: Я сам из Javakheti и живу среди Армянцев, коммуникации есть только в Армяне и школы также в Армяне.  \n",
              "2                                                                                                                                                                     Лора Ханамирян (говорит по-английски): Я хочу сказать, что, к сожалению, единственные хорошо сохранившиеся армянские церкви находятся в Иране.                                                                                                                                                                                                            Лора Ханамирян: к сожалению, единственные хорошо сохранившиеся армянские церкви находятся в Иране.                                                                                                                            Laura Khanamiryan: Я хочу сказать, что единственные хорошо сохраненные армийские церкви в Иране.  \n",
              "3                                                                   Пакеты представляют собой различные группы файлов, которые составляют конкретный элемент программного обеспечения, вместе с инструкциями Ubuntu, необходимыми для установки и удаления программного обеспечения, информации о зависимости и т.д.                                                                  Пакеты представляют собой различные группы файлов, составляющих определенный элемент программного обеспечения, наряду с инструкциями Убунту, необходимыми для установки и удаления программного обеспечения, информации о зависимости и т.д.  Packages являются различными группами файлов, которые составляют определенную часть программного обеспечения, вместе с указаниями Ubuntu необходимо установить и удалить программное обеспечение, зависимость и так далее.  \n",
              "4  Ubuntu основан на дистрибьюции Debian Linux, но содержит только подмножество программного обеспечения Дебиана из-за количества тестов, необходимых для поддержки каждой упаковки. Вселенная является подкатегорией, которая содержит программное обеспечение, которое сообщество упаковало и поддерживало Ubuntu.  Ubuntu основан на дистрибутиве Debian Linux, но содержит только подмножество программного обеспечения Debian из-за количества тестов, необходимых для поддержки каждой упаковки. Вселенная - это подкатегория, содержащая программное обеспечение, которое было собрано и поддержано сообществом для Ubuntu.                                                Ubuntu основана на дистрибуции Debian Linux, но содержит только часть дистрибуции Debian, потому что требуется большое количество тестирования для поддержки каждого пакета.  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "dc4340ebf74f401ea4334bd6e4bea1f5",
            "9e1fc0707fd243a29eb44e47b1523034",
            "68b9ef5cdd014d3a957507a6419f275e",
            "670a15fbc6f7469fad77f28c1040e443",
            "14f0f95d247f42a88f64c2951209c870",
            "573846234d9545c1b2e0a34c0d905172",
            "8c164779ad014966b7822fd670ab4e44",
            "335a599b6d0e4106829fab272b9ce931"
          ]
        },
        "id": "VGCt-gwPDm32",
        "outputId": "2c081b22-5426-40bd-d832-020f910e4a67"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SentenceTransformer('LaBSE')\n",
        "model.to(device)\n",
        "\n",
        "def calc_cos_sim_(df, model, src, dst, column_name):\n",
        "    LABSE = []\n",
        "   \n",
        "    for index, row in df.iterrows():\n",
        "\n",
        "        # original\n",
        "          emb_source = model.encode(row[src])\n",
        "          emb_target = model.encode(row[dst])\n",
        "\n",
        "          cos_val = cosine_similarity(emb_source.reshape(-1, emb_source.shape[0]), emb_target.reshape(-1, emb_target.shape[0]))[0][0]\n",
        "          LABSE.append(cos_val)\n",
        "\n",
        "    df[column_name] = LABSE\n",
        "\n",
        "\n",
        "calc_cos_sim_(data, model, 'src', 'google_API', 'cos_sim_google')\n",
        "calc_cos_sim_(data, model, 'src', 'mariam_sys', 'cos_sim_mariam')\n",
        "calc_cos_sim_(data, model, 'src', 'mariam_tuned_sys', 'cos_sim_mariam_tuned')\n",
        "calc_cos_sim_(data, model, 'src', 'fairseq_mbart', 'cos_sim_mbart')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc4340ebf74f401ea4334bd6e4bea1f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1754318854.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7Pj4DO6Ejnn",
        "outputId": "6f635a2b-8a2a-44f2-d375-f4bca5a9ce1f"
      },
      "source": [
        "data.cos_sim_google.mean(), data.cos_sim_mariam.mean(), data.cos_sim_mariam_tuned.mean(), data.cos_sim_mbart.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8811880518396695, 0.873996279189984, 0.8745776765048504, 0.8442612900535266)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}