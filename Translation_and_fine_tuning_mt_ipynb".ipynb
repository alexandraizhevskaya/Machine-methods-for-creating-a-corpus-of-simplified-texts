{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Translation_and_fine_tuning_mt.ipynb\"",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b14e024889564d65a1ff29c57f70f9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a46d65568204ad7baaa193ed7a47914",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e36bb1f90907483eaf7a8ee3836b9a82",
              "IPY_MODEL_7405ecbc3a4d47f08de8bc8aab453b40"
            ]
          }
        },
        "3a46d65568204ad7baaa193ed7a47914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e36bb1f90907483eaf7a8ee3836b9a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27f497fb8a7d42958b9b12c8c5dccd00",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef20d2aa105d4539a34b73ac42c04107"
          }
        },
        "7405ecbc3a4d47f08de8bc8aab453b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cd04eed7550246f5950e35cad38045d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 94/? [05:37&lt;00:00,  3.60s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8db1c11f54548f0b69eb9eb85f5a08c"
          }
        },
        "27f497fb8a7d42958b9b12c8c5dccd00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef20d2aa105d4539a34b73ac42c04107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd04eed7550246f5950e35cad38045d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8db1c11f54548f0b69eb9eb85f5a08c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9fc1a4bdb0145a08980bb06f7a22ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c73c3601aab14dbf89b4a0af9486dfc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33c8242881d244b7a844530a87be0de1",
              "IPY_MODEL_d8ba8eebe19f492dbf6435ab3c2ac20e"
            ]
          }
        },
        "c73c3601aab14dbf89b4a0af9486dfc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33c8242881d244b7a844530a87be0de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d18b284dc49d4ca9b04d920d068c3e5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbd1dd46b6cb4fc9bd9417861df39b0a"
          }
        },
        "d8ba8eebe19f492dbf6435ab3c2ac20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_afd6cbad432d4df18bb5d0f4452ea845",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 94/? [04:48&lt;00:00,  3.07s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1976bad45d14421b1d766ad38756fe0"
          }
        },
        "d18b284dc49d4ca9b04d920d068c3e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbd1dd46b6cb4fc9bd9417861df39b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afd6cbad432d4df18bb5d0f4452ea845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1976bad45d14421b1d766ad38756fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmjwvjsanxgE",
        "outputId": "8274bf16-6c5b-4613-cdfa-e83c8b5d5ca1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GpSq_usCcoW"
      },
      "source": [
        "Here I will finetune MT models and then evaluate quality of translation with BLEU and METEOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ihEp_Yv3Im8"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2m_-8lIkEpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf827067-00bf-492d-efcd-99281c36a4e0"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.1MB 14.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3MB 54.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 901kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2MB 14.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s1A1UtJk9-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1420a1eb-7d19-400f-94a3-9c3a38219fa6"
      },
      "source": [
        "!git clone https://github.com/google/sentencepiece.git \n",
        "%cd sentencepiece\n",
        "!mkdir build"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sentencepiece'...\n",
            "remote: Enumerating objects: 3690, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 3690 (delta 2), reused 1 (delta 0), pack-reused 3680\u001b[K\n",
            "Receiving objects: 100% (3690/3690), 28.58 MiB | 24.53 MiB/s, done.\n",
            "Resolving deltas: 100% (2585/2585), done.\n",
            "/content/sentencepiece\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sWUXkgLlCN2"
      },
      "source": [
        "%cd build\n",
        "!cmake ..\n",
        "!make\n",
        "!make install\n",
        "!ldconfig -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsQ_uF1pgjEq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from tqdm import tqdm_notebook\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeNXxZWYDRQa"
      },
      "source": [
        "# Loading and splitting data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8IiarwxhNs2"
      },
      "source": [
        "# ! gdown https://drive.google.com/uc?id=1--flbLLXbMC0_pPnmPAem9pnYwIhOjjF\n",
        "# ! gunzip -c /content/paracrawl-release1.en-ru.zipporah0-dedup-clean.tgz | tar xvf -\n",
        "# with open('/content/paracrawl-release1.en-ru.zipporah0-dedup-clean.en') as f:\n",
        "#     eng_lines = [i.strip() for i in f.readlines()]\n",
        "\n",
        "# with open('/content/paracrawl-release1.en-ru.zipporah0-dedup-clean.ru') as f:\n",
        "#     ru_lines = [i.strip() for i in f.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkNVSeifWNWc"
      },
      "source": [
        "YANDEX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di6TTltG1oiD",
        "outputId": "94a7000d-c7e2-427b-ee6e-0d7277e85748"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlXlpypFWPbh",
        "outputId": "5671fdbf-892e-418b-946b-0cea0e401bd8"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1-6VfQwe6I3t8utkGkqDiyuyrqc35Xg6c\n",
        "! unzip /content/1mcorpus.zip\n",
        "# ! unzip /content/drive/MyDrive/MT_sentence_simpl/1mcorpus.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-6VfQwe6I3t8utkGkqDiyuyrqc35Xg6c\n",
            "To: /content/1mcorpus.zip\n",
            "129MB [00:01, 87.6MB/s]\n",
            "Archive:  /content/1mcorpus.zip\n",
            "  inflating: corpus.en_ru.1m.en      \n",
            "  inflating: corpus.en_ru.1m.ru      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBj8iHqISYht"
      },
      "source": [
        "with open('/content/corpus.en_ru.1m.en') as f:\n",
        "    eng_lines = [i.strip() for i in f.readlines()]\n",
        "\n",
        "with open('/content/corpus.en_ru.1m.ru') as f:\n",
        "    ru_lines = [i.strip() for i in f.readlines()]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxBP5fc5PZEW"
      },
      "source": [
        "data_test = pd.DataFrame(list(zip(eng_lines, ru_lines)), columns=['src', 'dst'])\n",
        "# data_test[30000:33000].to_csv('/content/drive/MyDrive/MT_sentence_simpl/translation_test_new_sample.csv', index=False)\n",
        "# data_test_new.to_csv('/content/drive/MyDrive/MT_sentence_simpl/translation_test_new.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBie3XYngjEq"
      },
      "source": [
        "ru_train, ru_val, eng_train, eng_val = train_test_split(ru_lines[:30000], eng_lines[:30000], test_size=.1)\n",
        "# ru_test, eng_test = ru_train[30000:33000], eng_train[30000:33000]\n",
        "# test_data = pd.DataFrame(list(zip(eng_test, ru_test)), columns = ['src', 'dst'])\n",
        "# test_data.to_csv('/content/drive/MyDrive/MT_sentence_simpl/translation_test.csv', index=False)\n",
        "# ru_train, ru_val, eng_train, eng_val = ru_train[:30000], ru_val[:5000],\\\n",
        "#                                         eng_train[:30000], eng_val[:5000]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6pniaxk18Qr",
        "outputId": "13958ccf-4d09-4256-bf94-0541b2a3e11e"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1-paJt-Q077ZoQ3l_kDQGTbusRkun70PR\n",
        "test_data = pd.read_csv('/content/data_test_sample_google.csv')\n",
        "test_data.google_API = test_data.google_API.apply(lambda x: x.replace(\"&quot;\", \" \"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-paJt-Q077ZoQ3l_kDQGTbusRkun70PR\n",
            "To: /content/data_test_sample_google.csv\n",
            "\r0.00B [00:00, ?B/s]\r3.37MB [00:00, 108MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW7vvkpsZGEh"
      },
      "source": [
        "# test_data = pd.read_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzwt_lzjgjEn"
      },
      "source": [
        "# Finetuning Mariam MT from Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywHlfmswgjEp"
      },
      "source": [
        "# Freeze encoder weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wwitIfsgjEo"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ru\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-ru\")\n",
        "model.to(device)\n",
        "\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = True #False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaqSWLpMgjEr",
        "outputId": "f3d1d70b-2f5d-4598-87a4-2b8f98797645"
      },
      "source": [
        "train_encodings = tokenizer.prepare_seq2seq_batch(eng_train, \n",
        "                                                  ru_train, \n",
        "                                                  truncation=True, \n",
        "                                                  padding=True,\n",
        "                                                  max_length=100)\n",
        "val_encodings = tokenizer.prepare_seq2seq_batch(eng_val, \n",
        "                                                ru_val, \n",
        "                                                truncation=True, \n",
        "                                                padding=True,\n",
        "                                                max_length=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3226: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ü§ó Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDici8-R_uun"
      },
      "source": [
        "# model = AutoModelForSeq2SeqLM.from_pretrained('/content/drive/MyDrive/MT_sentence_simpl/models/marian_model_8_epochs_30k_samples_no_max_length')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAQtkCVHgjEs"
      },
      "source": [
        "class Seq2seqDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"labels\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dX-b9vjgjEs"
      },
      "source": [
        "train_dataset = Seq2seqDataset(train_encodings)\n",
        "eval_dataset = Seq2seqDataset(val_encodings)\n",
        "model.train()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)#64\n",
        "optim = AdamW(model.lm_head.parameters(), lr=5e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yxPeGlsVgjEv"
      },
      "source": [
        "for epoch in range(8):\n",
        "    epoch_loss = []\n",
        "    for batch in tqdm(train_loader):\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "#         embeddings = model.base_model(input_ids,\\\n",
        "#                                       decoder_input_ids=labels,\\\n",
        "#                                       attention_mask=attention_mask)/\n",
        "#                                       .requires_grad(True)\n",
        "#         outputs = model.lm_head(embeddings)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        epoch_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "    print(f\"Epoch {epoch} finished; Loss : {np.mean(epoch_loss)}\")\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhqBuNZ2n1yQ",
        "outputId": "ffb6a59c-9ca6-4d7b-e50b-b77268605d7a"
      },
      "source": [
        "import os\n",
        "! mkdir /content/drive/MyDrive/MT_sentence_simpl/models\n",
        "experiment_name = \"marian_model_8_epochs_30k_samples_no_max_length\"\n",
        "model.save_pretrained(os.path.join(\"/content/drive/MyDrive/MT_sentence_simpl/models\", experiment_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‚Äò/content/drive/MyDrive/MT_sentence_simpl/models‚Äô: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QMKwhb_E1yf"
      },
      "source": [
        "# MARIAM MT Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv--8VPfE5Ks"
      },
      "source": [
        "# helper functions\n",
        "\n",
        "def batch_generator(\n",
        "        list_of_sentences,\n",
        "        size=32\n",
        "):\n",
        "    num_batch = len(list_of_sentences)//size\n",
        "    for index in range(num_batch):\n",
        "        yield list_of_sentences[index*size:(index+1)*size]\n",
        "    yield list_of_sentences[num_batch*size:]\n",
        "\n",
        "\n",
        "def translate_to_russin(model, tok, src):\n",
        "\n",
        "  translations_src = []\n",
        "  for i in tqdm_notebook(batch_generator(src)):\n",
        "    l = tok(i, return_tensors=\"pt\", padding=True, max_length=512, truncation=True).to(device)\n",
        "    translated = model.generate(**l)\n",
        "    translations_src.extend([tok.decode(t, skip_special_tokens=True) for t in translated])\n",
        "\n",
        "  return translations_src\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn7lg3WhZgLP"
      },
      "source": [
        "## Original version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEwTnxH-Zio4"
      },
      "source": [
        "# import en-ru model from transformers\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "b14e024889564d65a1ff29c57f70f9af",
            "3a46d65568204ad7baaa193ed7a47914",
            "e36bb1f90907483eaf7a8ee3836b9a82",
            "7405ecbc3a4d47f08de8bc8aab453b40",
            "27f497fb8a7d42958b9b12c8c5dccd00",
            "ef20d2aa105d4539a34b73ac42c04107",
            "cd04eed7550246f5950e35cad38045d9",
            "e8db1c11f54548f0b69eb9eb85f5a08c"
          ]
        },
        "id": "Xlrib-ZFZqUt",
        "outputId": "6e9910b7-bb7f-4cf4-dde5-3ccb554ab8cf"
      },
      "source": [
        "# test--------------------------------------------------\n",
        "sys  = translate_to_russin(model, tokenizer, list(test_data.src.values))\n",
        "for i, obj  in enumerate(sys):\n",
        "  sys[i] = sys[i].replace('&gt;', '')\n",
        "  #src[i] = re.sub(r'[&gt;{1,}]', \" \", src[i])\n",
        "  sys[i] = sys[i].replace('&lt;', '')\n",
        "  sys[i] = sys[i].replace('()', '')\n",
        "  sys[i] = sys[i].replace('&quot;', '')\n",
        "test_data['mariam_sys'] = sys\n",
        "test_data.to_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b14e024889564d65a1ff29c57f70f9af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oddwKgW-Zd41"
      },
      "source": [
        "## Tuned version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "X7IVIMb2bhg-",
        "outputId": "cae8e76c-43be-408f-b717-9cb3c32d0e89"
      },
      "source": [
        "test_data.sample(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>google_API</th>\n",
              "      <th>mariam_sys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2833</th>\n",
              "      <td>You should ignore them.</td>\n",
              "      <td>–í–∞–º —Å–ª–µ–¥—É–µ—Ç –ø—Ä–µ–Ω–µ–±—Ä–µ–≥–∞—Ç—å –∏–º–∏.</td>\n",
              "      <td>–í—ã –¥–æ–ª–∂–Ω—ã –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏—Ö.</td>\n",
              "      <td>–¢—ã –¥–æ–ª–∂–µ–Ω –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏—Ö.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1821</th>\n",
              "      <td>It seems to me there are three candidates.</td>\n",
              "      <td>–ú–Ω–µ –∫–∞–∂–µ—Ç—Å—è, —É–∂–µ –µ—Å—Ç—å —Ç—Ä–∏ '–∫–∞–Ω–¥–∏–¥–∞—Ç–∞'.</td>\n",
              "      <td>–ú–Ω–µ –∫–∞–∂–µ—Ç—Å—è, –µ—Å—Ç—å —Ç—Ä–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.</td>\n",
              "      <td>–ú–Ω–µ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –µ—Å—Ç—å —Ç—Ä–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>Foreign workers account for barely one third o...</td>\n",
              "      <td>–ï–¥–≤–∞ –ª–∏—à—å –æ–¥–Ω—É —Ç—Ä–µ—Ç—å –æ—Ç –æ–±—â–µ–π —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ —Ç—Ä—É–¥...</td>\n",
              "      <td>–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç–Ω–∏–∫–∏ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç –µ–¥–≤–∞ –ª–∏ —Ç—Ä–µ—Ç—å...</td>\n",
              "      <td>–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç –ª–∏—à—å –æ–¥–Ω—É —Ç—Ä–µ—Ç—å...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1142</th>\n",
              "      <td>It was no coincidence that the Kimberley Proce...</td>\n",
              "      <td>–ù–µ –±—ã–ª–æ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å—é, —á—Ç–æ –ö–∏–º–±–µ—Ä–ª–∏–π—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å...</td>\n",
              "      <td>–ö–∏–º–±–µ—Ä–ª–∏–π—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å –∑–∞—Ä–æ–¥–∏–ª—Å—è –≤ –Æ–∂–Ω–æ–π –ê—Ñ—Ä–∏–∫–µ...</td>\n",
              "      <td>–ù–µ —Å–ª—É—á–∞–π–Ω–æ –ö–∏–º–±–µ—Ä–ª–∏–π—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–æ–¥–∏–ª—Å—è –≤ –Æ–∂...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    src  ...                                         mariam_sys\n",
              "2833                            You should ignore them.  ...                         –¢—ã –¥–æ–ª–∂–µ–Ω –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏—Ö.\n",
              "1821         It seems to me there are three candidates.  ...               –ú–Ω–µ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –µ—Å—Ç—å —Ç—Ä–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.\n",
              "361   Foreign workers account for barely one third o...  ...  –ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç –ª–∏—à—å –æ–¥–Ω—É —Ç—Ä–µ—Ç—å...\n",
              "1142  It was no coincidence that the Kimberley Proce...  ...  –ù–µ —Å–ª—É—á–∞–π–Ω–æ –ö–∏–º–±–µ—Ä–ª–∏–π—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–æ–¥–∏–ª—Å—è –≤ –Æ–∂...\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNy5yj1bJdd_"
      },
      "source": [
        "# import en-ru model from transformers\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model_name = '/content/drive/MyDrive/MT_sentence_simpl/models/marian_model_8_epochs_30k_samples_no_max_length'\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hmY7dUL0n63",
        "outputId": "41309cc1-ed30-4ff4-ee88-923333b7908e"
      },
      "source": [
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(62518, 512, padding_idx=62517)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "c9fc1a4bdb0145a08980bb06f7a22ead",
            "c73c3601aab14dbf89b4a0af9486dfc7",
            "33c8242881d244b7a844530a87be0de1",
            "d8ba8eebe19f492dbf6435ab3c2ac20e",
            "d18b284dc49d4ca9b04d920d068c3e5e",
            "cbd1dd46b6cb4fc9bd9417861df39b0a",
            "afd6cbad432d4df18bb5d0f4452ea845",
            "a1976bad45d14421b1d766ad38756fe0"
          ]
        },
        "id": "7yEbnYRNKBRW",
        "outputId": "965b2c21-d81c-460a-a37d-073c4eef6c9b"
      },
      "source": [
        "sys  = translate_to_russin(model, tokenizer, list(test_data.src.values))\n",
        "for i, obj  in enumerate(sys):\n",
        "  sys[i] = sys[i].replace('&gt;', '')\n",
        "  #src[i] = re.sub(r'[&gt;{1,}]', \" \", src[i])\n",
        "  sys[i] = sys[i].replace('&lt;', '')\n",
        "  sys[i] = sys[i].replace('()', '')\n",
        "  sys[i] = sys[i].replace('&quot;', '')\n",
        "test_data['mariam_tuned_sys'] = sys\n",
        "test_data.to_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9fc1a4bdb0145a08980bb06f7a22ead",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "pG-uzso-vgTZ",
        "outputId": "c17cbecc-1df8-4dca-b16c-7d6074f584c9"
      },
      "source": [
        "test_data.sample(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>google_API</th>\n",
              "      <th>mariam_sys</th>\n",
              "      <th>mariam_tuned_sys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>When these application are started via Gpass, ...</td>\n",
              "      <td>–ö–æ–≥–¥–∞ —ç—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ TGPasst...</td>\n",
              "      <td>–ö–æ–≥–¥–∞ —ç—Ç–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ Gpass, ...</td>\n",
              "      <td>–ö–æ–≥–¥–∞ —ç—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ Gpass, ...</td>\n",
              "      <td>–ö–æ–≥–¥–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ Gpass, –æ–Ω–∏ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>5th International Conference on Advanced Techn...</td>\n",
              "      <td>–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞–º –≤ —Ü–µ–ª–ª—é–ª–æ–∑–Ω–æ-–±—É–º–∞–∂–Ω–æ–π –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω...</td>\n",
              "      <td>5-—è –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è –ø–æ –ø–µ—Ä–µ–¥–æ–≤—ã–º —Ç–µ—Ö...</td>\n",
              "      <td>–ü—è—Ç–∞—è –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è –ø–æ –ø–µ—Ä–µ–¥–æ–≤—ã–º —Ç...</td>\n",
              "      <td>–ü—è—Ç–∞—è –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è –ø–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2982</th>\n",
              "      <td>(While provincial reconstruction teams are led...</td>\n",
              "      <td>(–í —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –ø—Ä–æ–≤–∏–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã —Ä–µ–∫–æ–Ω—Å—Ç...</td>\n",
              "      <td>(–•–æ—Ç—è –ø—Ä–æ–≤–∏–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –ø–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é ...</td>\n",
              "      <td>(–í —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –ø—Ä–æ–≤–∏–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –ø–æ –≤–æ—Å—Å—Ç...</td>\n",
              "      <td>(–•–æ—Ç—è –ø—Ä–æ–≤–∏–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –ø–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>This is all having a direct negative impact on...</td>\n",
              "      <td>–í—Å–µ —ç—Ç–æ –æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞ –ø–æ...</td>\n",
              "      <td>–í—Å–µ —ç—Ç–æ –æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä—è–º–æ–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏...</td>\n",
              "      <td>–í—Å–µ —ç—Ç–æ –æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ ...</td>\n",
              "      <td>–í—Å–µ —ç—Ç–æ –æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    src  ...                                   mariam_tuned_sys\n",
              "522   When these application are started via Gpass, ...  ...  –ö–æ–≥–¥–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ Gpass, –æ–Ω–∏ ...\n",
              "823   5th International Conference on Advanced Techn...  ...  –ü—è—Ç–∞—è –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è –ø–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º...\n",
              "2982  (While provincial reconstruction teams are led...  ...  (–•–æ—Ç—è –ø—Ä–æ–≤–∏–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –ø–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é ...\n",
              "532   This is all having a direct negative impact on...  ...  –í—Å–µ —ç—Ç–æ –æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ ...\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGhq-F0FS-Gd"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq6cQxiGVWtd"
      },
      "source": [
        "! pip3 install sacrebleu\n",
        "! pip install -U nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SkON1L-S-g4"
      },
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GVZpRQuavRZ"
      },
      "source": [
        "### MARIAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yT5Wep8aplJ"
      },
      "source": [
        "### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8liDRMZaxuv",
        "outputId": "a0663b61-161c-4edf-97cf-3e339f9e736d"
      },
      "source": [
        "import sacrebleu\n",
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['mariam_sys'].values)\n",
        "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
        "print(bleu.score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21.934412821022754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuT7czBvd9Av"
      },
      "source": [
        "#### METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYG8TTh_fSWy"
      },
      "source": [
        "meteor_mt = sum(meteor_score(row['dst'], row['mariam_sys']) for i, row in test_data.iterrows())/test_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7qOU3NPgdDU",
        "outputId": "cea6d1bf-71b5-451f-fff5-54ed4ce62ff9"
      },
      "source": [
        "meteor_mt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1541136436844775"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9mKt-Barfy"
      },
      "source": [
        "### MARIAM Tuned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "131eUIICgyEp"
      },
      "source": [
        "### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B88kP8FHXsYY",
        "outputId": "07773926-7087-43d3-a211-f811733fa2d3"
      },
      "source": [
        "import sacrebleu\n",
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['mariam_tuned_sys'].values)\n",
        "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
        "print(bleu.score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21.411719265727832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKco_cNFgWJ_"
      },
      "source": [
        "##### METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro1OJeSTgbeN"
      },
      "source": [
        "meteor_mt = sum(meteor_score(row['dst'], row['mariam_tuned_sys']) for i, row in test_data.iterrows())/test_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv1MExX9hCKr",
        "outputId": "7102a01a-2391-428b-f83b-e608123957e8"
      },
      "source": [
        "meteor_mt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15623524899165783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSdwaYsEhJz8"
      },
      "source": [
        "### GOOGLE API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ0u_CAEnDpE"
      },
      "source": [
        "##### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZyPeTpHm-lc",
        "outputId": "1124332b-6f04-4f59-9837-e481ddb0d76a"
      },
      "source": [
        "import sacrebleu\n",
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['google_API'].values)\n",
        "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
        "print(bleu.score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26.129453989406834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbWulYy0nGSF"
      },
      "source": [
        "##### METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyH7Hl9inGaM"
      },
      "source": [
        "meteor_mt = sum(meteor_score(row['dst'], row['google_API']) for i, row in test_data.iterrows())/test_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT-WMf0ZnPZD",
        "outputId": "2c589e97-480e-4197-98d5-cd4a1b05509f"
      },
      "source": [
        "meteor_mt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15040614041259198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0KsPzdt3yNq"
      },
      "source": [
        "# Fairseq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHsgn3E731zP",
        "outputId": "eb73165b-055d-4b59-c7c6-74c7845cb733"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWXSwXec5S3_"
      },
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fairseq/models/mbart/mbart.cc25.v2.tar.gz\n",
        "! tar -xzvf /content/mbart.cc25.v2.tar.gz\n",
        "! apt-get install cmake build-essential pkg-config libgoogle-perftools-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_-_vv4C5TAp"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd /content/fairseq/\n",
        "!python -m pip install --editable .\n",
        "%cd /content\n",
        "\n",
        "! echo $PYTHONPATH\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
        "\n",
        "! echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8wuOvwG54D-"
      },
      "source": [
        "# Process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzMC6KZh5TFI"
      },
      "source": [
        "! rm -r /content/fairseq/data\n",
        "! mkdir /content/fairseq/data"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmLvFh-M9uSe",
        "outputId": "12d1470d-ab23-4992-e629-ce2b1f96d672"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysM3AKVN6i2g"
      },
      "source": [
        "ru_train, ru_val, eng_train, eng_val \n",
        "data_train = pd.DataFrame(list(zip(eng_train, ru_train)), columns=['src', 'dst'])\n",
        "data_dev = pd.DataFrame(list(zip(eng_val, ru_val)), columns=['src', 'dst'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2QB-bwG5TG0"
      },
      "source": [
        "### process WikiLarge\n",
        "\n",
        "with open('/content/fairseq/data/test.en', \"a\") as f:\n",
        "  for i, row in test_data.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.en', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.en', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['src']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/test.ru', \"a\") as f:\n",
        "  for i, row in test_data.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/train.ru', \"a\") as f:\n",
        "  for i, row in data_train.iterrows():\n",
        "    f.write(row['dst']+'\\n')\n",
        "\n",
        "with open('/content/fairseq/data/dev.ru', \"a\") as f:\n",
        "  for i, row in data_dev.iterrows():\n",
        "    f.write(row['dst']+'\\n')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h54eA5i5TKL"
      },
      "source": [
        "SPM=\"/content/sentencepiece/build/src/spm_encode\"\n",
        "BPE_MODEL=\"/content/mbart.cc25.v2/sentence.bpe.model\"\n",
        "DATA_DIR=\"/content/fairseq/data\"\n",
        "SRC=\"en\"\n",
        "TGT=\"ru\" #en\n",
        "\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$SRC > $DATA_DIR/train.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/train.$TGT > $DATA_DIR/train.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$SRC > $DATA_DIR/dev.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/dev.$TGT > $DATA_DIR/dev.spm.$TGT &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$SRC > $DATA_DIR/test.spm.$SRC &\n",
        "!$SPM --model=$BPE_MODEL < $DATA_DIR/test.$TGT > $DATA_DIR/test.spm.$TGT &"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh8Zy0d05TMM",
        "outputId": "c19696fb-70f9-4dfb-ce3f-83c7c38ea200"
      },
      "source": [
        "PREPROCESSED_DATA_DIR=\"/content/fairseq/data\"\n",
        "DICT=\"/content/mbart.cc25.v2/dict.txt\"\n",
        "!fairseq-preprocess \\\n",
        "  --source-lang en \\\n",
        "  --target-lang ru \\\n",
        "  --trainpref /content/fairseq/data/train.spm \\\n",
        "  --validpref /content/fairseq/data/dev.spm \\\n",
        "  --testpref /content/fairseq/data/test.spm \\\n",
        "  --destdir /content/fairseq/data \\\n",
        "  --thresholdtgt 0 \\\n",
        "  --thresholdsrc 0 \\\n",
        "  --srcdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --tgtdict /content/mbart.cc25.v2/dict.txt \\\n",
        "  --workers 70"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-29 00:15:29 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/content/fairseq/data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='en', srcdict='/content/mbart.cc25.v2/dict.txt', suppress_crashes=False, target_lang='ru', task='translation', tensorboard_logdir=None, testpref='/content/fairseq/data/test.spm', tgtdict='/content/mbart.cc25.v2/dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/fairseq/data/train.spm', use_plasma_view=False, user_dir=None, validpref='/content/fairseq/data/dev.spm', wandb_project=None, workers=70)\n",
            "2021-04-29 00:15:30 | INFO | fairseq_cli.preprocess | [en] Dictionary: 250001 types\n",
            "2021-04-29 00:15:41 | INFO | fairseq_cli.preprocess | [en] /content/fairseq/data/train.spm.en: 27000 sents, 817692 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:15:41 | INFO | fairseq_cli.preprocess | [en] Dictionary: 250001 types\n",
            "2021-04-29 00:15:50 | INFO | fairseq_cli.preprocess | [en] /content/fairseq/data/dev.spm.en: 3000 sents, 89011 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:15:50 | INFO | fairseq_cli.preprocess | [en] Dictionary: 250001 types\n",
            "2021-04-29 00:16:00 | INFO | fairseq_cli.preprocess | [en] /content/fairseq/data/test.spm.en: 3000 sents, 91695 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:16:00 | INFO | fairseq_cli.preprocess | [ru] Dictionary: 250001 types\n",
            "2021-04-29 00:16:11 | INFO | fairseq_cli.preprocess | [ru] /content/fairseq/data/train.spm.ru: 27000 sents, 906556 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:16:11 | INFO | fairseq_cli.preprocess | [ru] Dictionary: 250001 types\n",
            "2021-04-29 00:16:20 | INFO | fairseq_cli.preprocess | [ru] /content/fairseq/data/dev.spm.ru: 3000 sents, 98575 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:16:20 | INFO | fairseq_cli.preprocess | [ru] Dictionary: 250001 types\n",
            "2021-04-29 00:16:30 | INFO | fairseq_cli.preprocess | [ru] /content/fairseq/data/test.spm.ru: 3000 sents, 101425 tokens, 0.0% replaced by <unk>\n",
            "2021-04-29 00:16:30 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/fairseq/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGZbKR3i_Gwk"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Afw5hNEw_MGG"
      },
      "source": [
        "Also, it is necessary to make the following change in /content/fairseq/fairseq/tasks/translation_from_pretrained_bart.py:\n",
        "\n",
        "```\n",
        "def __init__(self, args, src_dict, tgt_dict):\n",
        "        super().__init__(args, src_dict, tgt_dict)\n",
        "        self.args = args                  # add this line !!!!!\n",
        "        self.langs = args.langs.split(\",\")\n",
        "        for d in [src_dict, tgt_dict]:\n",
        "            for l in self.langs:\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp603T6y_cp6"
      },
      "source": [
        "# mkdir to put the checkpoints\n",
        "! mkdir /content/drive/MyDrive/checkpoints_mt"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_TRW_xq-tTi",
        "outputId": "be30a777-0c53-40cc-bd8b-68c801cf7b97"
      },
      "source": [
        "!fairseq-train /content/fairseq/data \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --arch mbart_large --layernorm-embedding \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
        "  --optimizer adam --adam-eps 1e-06 --adam-betas '(0.9, 0.98)' \\\n",
        "  --lr-scheduler polynomial_decay --lr 3e-05 --warmup-updates 2500 --total-num-update 54725  \\\n",
        "  --dropout 0.3 --attention-dropout 0.1 --weight-decay 0.0 \\\n",
        "  --max-tokens 1024 --update-freq 5 \\\n",
        "  --source-lang en --target-lang ru \\\n",
        "  --batch-size 16 \\\n",
        "  --memory-efficient-fp16 \\\n",
        "  --validate-interval 1 \\\n",
        "  --patience 3 \\\n",
        "  --max-epoch 5 \\\n",
        "  --save-interval 5 --keep-last-epochs 10 --keep-best-checkpoints 2 \\\n",
        "  --ddp-backend no_c10d \\\n",
        "  --seed 42 --log-format simple --log-interval 500 \\\n",
        "  --restore-file /content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt \\\n",
        "  --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler \\\n",
        "  --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN \\\n",
        "  --scoring bleu \\\n",
        "  --save-dir /content/drive/MyDrive/checkpoints_mt"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-29 01:09:32 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 500, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1024, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [5], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints_mt', 'restore_file': '/content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 10, 'keep_best_checkpoints': 2, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='mbart_large', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt', save_dir='/content/drive/MyDrive/checkpoints_mt', save_interval=5, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='ru', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': Namespace(_name='translation_from_pretrained_bart', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/fairseq/data', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=2, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.2, langs='ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN', layernorm_embedding=True, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=500, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt', save_dir='/content/drive/MyDrive/checkpoints_mt', save_interval=5, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='ru', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='54725', tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[5], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=2500, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 2500, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 54725.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}\n",
            "2021-04-29 01:09:33 | INFO | fairseq.tasks.translation | [en] dictionary: 250001 types\n",
            "2021-04-29 01:09:33 | INFO | fairseq.tasks.translation | [ru] dictionary: 250001 types\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | BARTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=1024, out_features=250027, bias=False)\n",
            "  )\n",
            "  (classification_heads): ModuleDict()\n",
            ")\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | task: TranslationFromPretrainedBARTTask\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | model: BARTModel\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | num. shared model params: 610,851,840 (num. trained: 610,851,840)\n",
            "2021-04-29 01:09:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-04-29 01:09:58 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: /content/fairseq/data/valid.en-ru.en\n",
            "2021-04-29 01:09:58 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: /content/fairseq/data/valid.en-ru.ru\n",
            "2021-04-29 01:09:58 | INFO | fairseq.tasks.translation | /content/fairseq/data valid en-ru 3000 examples\n",
            "2021-04-29 01:10:03 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2021-04-29 01:10:03 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2021-04-29 01:10:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-04-29 01:10:03 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    \n",
            "2021-04-29 01:10:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-04-29 01:10:03 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-04-29 01:10:03 | INFO | fairseq_cli.train | max tokens per device = 1024 and max sentences per device = 16\n",
            "2021-04-29 01:10:03 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt\n",
            "2021-04-29 01:12:51 | INFO | fairseq.trainer | Loaded checkpoint /content/drive/MyDrive/checkpoints_mt/checkpoint_last.pt (epoch 6 @ 0 updates)\n",
            "2021-04-29 01:13:05 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-04-29 01:13:06 | INFO | fairseq.data.data_utils | loaded 27,000 examples from: /content/fairseq/data/train.en-ru.en\n",
            "2021-04-29 01:13:06 | INFO | fairseq.data.data_utils | loaded 27,000 examples from: /content/fairseq/data/train.en-ru.ru\n",
            "2021-04-29 01:13:06 | INFO | fairseq.tasks.translation | /content/fairseq/data train en-ru 27000 examples\n",
            "2021-04-29 01:13:06 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-04-29 01:13:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/fairseq/fairseq/utils.py:364: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "2021-04-29 01:13:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "2021-04-29 01:13:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "2021-04-29 01:13:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "2021-04-29 01:13:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "2021-04-29 01:13:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "2021-04-29 01:13:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0\n",
            "2021-04-29 01:13:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0\n",
            "2021-04-29 01:13:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5\n",
            "2021-04-29 01:15:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25\n",
            "2021-04-29 01:16:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125\n",
            "2021-04-29 01:18:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:18:45 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.501 | nll_loss 4.165 | ppl 17.94 | wps 7321.1 | wpb 459.6 | bsz 13.6 | num_updates 360\n",
            "2021-04-29 01:18:45 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-04-29 01:18:45 | INFO | train | epoch 001 | loss 9.677 | nll_loss 5.789 | ppl 55.3 | wps 2744.3 | ups 1.09 | wpb 2518.4 | bsz 72.9 | num_updates 360 | lr 4.32e-06 | gnorm 16.715 | loss_scale 0.125 | train_wall 321 | gb_free 4.3 | wall 521\n",
            "2021-04-29 01:18:45 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-04-29 01:18:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-29 01:20:47 | INFO | train_inner | epoch 002:    140 / 370 loss=9.622, nll_loss=5.755, ppl=54.01, wps=2779.2, ups=1.1, wpb=2515.1, bsz=73.1, num_updates=500, lr=6e-06, gnorm=15.697, loss_scale=0.125, train_wall=442, gb_free=5.1, wall=644\n",
            "2021-04-29 01:24:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:24:18 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.131 | nll_loss 4.006 | ppl 16.06 | wps 7180.3 | wpb 459.6 | bsz 13.6 | num_updates 730\n",
            "2021-04-29 01:24:18 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-04-29 01:24:18 | INFO | train | epoch 002 | loss 9.386 | nll_loss 5.638 | ppl 49.8 | wps 2800.4 | ups 1.11 | wpb 2523.1 | bsz 73 | num_updates 730 | lr 8.76e-06 | gnorm 16.216 | loss_scale 0.125 | train_wall 317 | gb_free 4.7 | wall 855\n",
            "2021-04-29 01:24:18 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-04-29 01:24:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-29 01:28:09 | INFO | train_inner | epoch 003:    270 / 370 loss=9.178, nll_loss=5.526, ppl=46.08, wps=2854.1, ups=1.13, wpb=2522.3, bsz=72.9, num_updates=1000, lr=1.2e-05, gnorm=14.512, loss_scale=0.125, train_wall=425, gb_free=5.7, wall=1085\n",
            "2021-04-29 01:29:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:29:51 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.767 | nll_loss 3.795 | ppl 13.88 | wps 7665.2 | wpb 459.6 | bsz 13.6 | num_updates 1100\n",
            "2021-04-29 01:29:51 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-04-29 01:29:51 | INFO | train | epoch 003 | loss 8.997 | nll_loss 5.412 | ppl 42.57 | wps 2806.1 | ups 1.11 | wpb 2523.1 | bsz 73 | num_updates 1100 | lr 1.32e-05 | gnorm 9.841 | loss_scale 0.125 | train_wall 317 | gb_free 6 | wall 1187\n",
            "2021-04-29 01:29:51 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2021-04-29 01:29:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-29 01:35:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:35:21 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.534 | nll_loss 3.605 | ppl 12.17 | wps 7992.7 | wpb 459.6 | bsz 13.6 | num_updates 1470\n",
            "2021-04-29 01:35:21 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2021-04-29 01:35:21 | INFO | train | epoch 004 | loss 8.646 | nll_loss 5.133 | ppl 35.08 | wps 2830.3 | ups 1.12 | wpb 2523.1 | bsz 73 | num_updates 1470 | lr 1.764e-05 | gnorm 10.809 | loss_scale 0.125 | train_wall 315 | gb_free 5.8 | wall 1517\n",
            "2021-04-29 01:35:21 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2021-04-29 01:35:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-04-29 01:35:46 | INFO | train_inner | epoch 005:     30 / 370 loss=8.677, nll_loss=5.158, ppl=35.7, wps=2765.8, ups=1.09, wpb=2527.6, bsz=72.8, num_updates=1500, lr=1.8e-05, gnorm=9.501, loss_scale=0.125, train_wall=428, gb_free=5.7, wall=1542\n",
            "2021-04-29 01:40:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-04-29 01:40:49 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.354 | nll_loss 3.452 | ppl 10.95 | wps 7984.5 | wpb 459.6 | bsz 13.6 | num_updates 1840\n",
            "2021-04-29 01:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 1840 updates\n",
            "2021-04-29 01:40:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints_mt/checkpoint5.pt\n",
            "2021-04-29 01:42:39 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints_mt/checkpoint5.pt\n",
            "2021-04-29 01:52:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints_mt/checkpoint5.pt (epoch 5 @ 1840 updates, score 7.354) (writing took 709.9956223490008 seconds)\n",
            "2021-04-29 01:52:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2021-04-29 01:52:39 | INFO | train | epoch 005 | loss 8.359 | nll_loss 4.844 | ppl 28.73 | wps 898.9 | ups 0.36 | wpb 2523.1 | bsz 73 | num_updates 1840 | lr 2.208e-05 | gnorm 9.648 | loss_scale 0.125 | train_wall 313 | gb_free 5.7 | wall 2556\n",
            "2021-04-29 01:52:40 | INFO | fairseq_cli.train | done training in 2373.4 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0nEf2_M-td-",
        "outputId": "e8f6dad6-7657-4d84-ad27-227307c9e9d5"
      },
      "source": [
        "!fairseq-generate /content/fairseq/data \\\n",
        "  --path  /content/drive/MyDrive/checkpoints_mt/checkpoint_best.pt \\\n",
        "  --task translation_from_pretrained_bart \\\n",
        "  --gen-subset test \\\n",
        "  --source-lang en --target-lang ru \\\n",
        "  --bpe 'sentencepiece' --sentencepiece-model /content/mbart.cc25.v2/sentence.bpe.model \\\n",
        "  --sacrebleu --remove-bpe 'sentencepiece' \\\n",
        "  --batch-size 32 --langs ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN > model_prediction.txt & \n",
        "!cat model_prediction.txt | grep -P \"^H\" |sort -V |cut -f 3- > model_prediction_mt.hyp\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q4PbHpn5TPO"
      },
      "source": [
        "!cp /content/model_prediction_en_ru_ru_filtered.hyp /content/drive/MyDrive/MT_sentence_simpl/predictions/model_prediction_en_ru_ru_filtered.hyp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdU8r4bMXFMO"
      },
      "source": [
        "with open('/content/model_prediction_mt.hyp') as f:\n",
        "  lines = [i.strip() for i in f.readlines()]\n",
        "\n",
        "\n",
        "test_data['fairseq_mbart'] = lines\n",
        "test_data.to_csv('/content/drive/MyDrive/MT_sentence_simpl/data_test_sample_google.csv', index=False)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSxzOT0DXuru"
      },
      "source": [
        "# Fairseq mBART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlDtwPI7Xy9L"
      },
      "source": [
        "##### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0r4bM2GXZY-",
        "outputId": "a99bccef-101e-43b8-946f-3f3e6f65951d"
      },
      "source": [
        "import sacrebleu\n",
        "refs = [list(test_data['dst'].values)]\n",
        "sys = list(test_data['fairseq_mbart'].values)\n",
        "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
        "print(bleu.score)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.315905780266137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjqSEykGX2ok"
      },
      "source": [
        "#### METEOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMdb2sxIZCpX",
        "outputId": "bda48420-ebf0-4457-bb00-868159f661bf"
      },
      "source": [
        "! pip3 install sacrebleu\n",
        "! pip install -U nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2.0.0)\n",
            "Requirement already up-to-date: nltk in /usr/local/lib/python3.7/dist-packages (3.6.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNgj8n8wXbSI",
        "outputId": "b213ac6b-5e90-451a-df97-e40d026d00bb"
      },
      "source": [
        "meteor_mt = sum(meteor_score(row['dst'], row['google_API']) for i, row in test_data.iterrows())/test_data.shape[0]\n",
        "meteor_mt"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15064013355701317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xlbxh0AYXgo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}